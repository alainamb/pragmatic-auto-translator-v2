{
  "metadata": {
    "model": "jinaai/jina-embeddings-v3",
    "dimension": 1024,
    "task": "retrieval.passage",
    "normalization": true,
    "created": "2025-07-06T05:58:11.996121",
    "model_parameters": {
      "trust_remote_code": true,
      "normalize_embeddings": true
    }
  },
  "vectors": [
    {
      "id": "gai-eng_corpus-item001",
      "count": 1,
      "created": "2025-07-06T04:23:39.402544",
      "text": "Attention is All You Need The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data. Introduction Recurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks in particular, have been firmly established as state of the art approaches in sequence modeling and transduction problems such as language modeling and machine translation [35, 2, 5]. Numerous efforts have since continued to push the boundaries of recurrent language models and encoder-decoder architectures [38, 24, 15]. Recurrent models typically factor computation along the symbol positions of the input and output sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden states ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples. Recent work has achieved significant improvements in computational efficiency through factorization tricks [21] and conditional computation [32], while also improving model performance in case of the latter. The fundamental constraint of sequential computation, however, remains. [Equation: ht = h_t] [Equation: ht−1 = h_{t-1}] [Equation: t = t] Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms are used in conjunction with a recurrent network. In this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs. Background The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU [16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building block, computing hidden representations in parallel for all input and output positions. In these models, the number of operations required to relate signals from two arbitrary input or output positions grows in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes it more difficult to learn dependencies between distant positions [12]. In the Transformer this is reduced to a constant number of operations, albeit at the cost of reduced effective resolution due to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as described in section 3.2. Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations [4, 27, 28, 22]. End-to-end memory networks are based on a recurrent attention mechanism instead of sequence-aligned recurrence and have been shown to perform well on simple-language question answering and language modeling tasks [34]. To the best of our knowledge, however, the Transformer is the first transduction model relying entirely on self-attention to compute representations of its input and output without using sequence-aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate self-attention and discuss its advantages over models such as [17, 18] and [9]. Model Architecture Most competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35]. Here, the encoder maps an input sequence of symbol representations (x1,...,xn) to a sequence of continuous representations z = (z1,...,zn). Given z, the decoder then generates an output sequence (y1,...,ym) of symbols one element at a time. At each step the model is auto-regressive [10], consuming the previously generated symbols as additional input when generating the next. [Equation: (x1,...,xn) = (x_1,...,x_n)] [Equation: z = (z1,...,zn) = z = (z_1,...,z_n)] [Equation: z = z] [Equation: (y1,...,ym) = (y_1,...,y_m)] The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively. Encoder and Decoder Stacks Encoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-wise fully connected feed-forward network. We employ a residual connection [11] around each of the two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension dmodel = 512. [Equation: N = 6 = N = 6] [Equation: LayerNorm(x + Sublayer(x)) = \\text{LayerNorm}(x + \\text{Sublayer}(x))] [Equation: Sublayer(x) = \\text{Sublayer}(x)] [Equation: dmodel = 512 = d_{\\text{model}} = 512] Decoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization. We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i. [Equation: N = 6 = N = 6] [Equation: i = i] Attention An attention function can be described as mapping a query and a set of key-value pairs to an output, where the query, keys, values, and output are all vectors. The output is computed as a weighted sum of the values, where the weight assigned to each value is computed by a compatibility function of the query with the corresponding key. Scaled Dot-Product Attention We call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of queries and keys of dimension dk, and values of dimension dv. We compute the dot products of the query with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the values. [Equation: dk = d_k] [Equation: dv = d_v] [Equation: √dk = \\sqrt{d_k}] In practice, we compute the attention function on a set of queries simultaneously, packed together into a matrix Q. The keys and values are also packed together into matrices K and V. We compute the matrix of outputs as: [Equation: Q = Q] [Equation: K = K] [Equation: V = V] Attention(Q,K,V) = softmax(QKT/√dk)V (1) [Equation: Attention(Q,K,V) = softmax(QKT/√dk)V = \\text{Attention}(Q,K,V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V] The two most commonly used attention functions are additive attention [2], and dot-product (multiplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor of 1/√dk. Additive attention computes the compatibility function using a feed-forward network with a single hidden layer. While the two are similar in theoretical complexity, dot-product attention is much faster and more space-efficient in practice, since it can be implemented using highly optimized matrix multiplication code. [Equation: 1/√dk = \\frac{1}{\\sqrt{d_k}}] While for small values of dk the two mechanisms perform similarly, additive attention outperforms dot product attention without scaling for larger values of dk [3]. We suspect that for large values of dk, the dot products grow large in magnitude, pushing the softmax function into regions where it has extremely small gradients[^4]. To counteract this effect, we scale the dot products by 1/√dk. [Equation: dk = d_k] [Equation: 1/√dk = \\frac{1}{\\sqrt{d_k}}] Multi-Head Attention Instead of performing a single attention function with dmodel-dimensional keys, values and queries, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of queries, keys and values we then perform the attention function in parallel, yielding dv-dimensional output values. These are concatenated and once again projected, resulting in the final values, as depicted in Figure 2. [Equation: dmodel = d_{\\text{model}}] [Equation: h = h] [Equation: dk = d_k] [Equation: dv = d_v] Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions. With a single attention head, averaging inhibits this. MultiHead(Q,K,V) = Concat(head1,...,headh)WO where headi = Attention(QWQi,KWKi,VWVi) [Equation: MultiHead(Q,K,V) = Concat(head1,...,headh)WO where headi = Attention(QWQi,KWKi,VWVi) = \\text{MultiHead}(Q,K,V) = \\text{Concat}(\\text{head}_1,...,\\text{head}_h)W^O \\text{ where } \\text{head}_i = \\text{Attention}(QW^Q_i,KW^K_i,VW^V_i)] Where the projections are parameter matrices WQi ∈Rdmodel×dk, WKi ∈Rdmodel×dk, WVi ∈Rdmodel×dv and WO ∈Rhdv×dmodel. [Equation: WQi ∈Rdmodel×dk = W^Q_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}] [Equation: WKi ∈Rdmodel×dk = W^K_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}] [Equation: WVi ∈Rdmodel×dv = W^V_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}] [Equation: WO ∈Rhdv×dmodel = W^O \\in \\mathbb{R}^{h \\cdot d_v \\times d_{\\text{model}}}] In this work we employ h = 8 parallel attention layers, or heads. For each of these we use dk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost is similar to that of single-head attention with full dimensionality [Equation: h = 8 = h = 8] [Equation: dk = dv = dmodel/h = 64 = d_k = d_v = d_{\\text{model}}/h = 64] Applications of Attention in our Model The Transformer uses multi-head attention in three different ways: In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence. This mimics the typical encoder-decoder attention mechanisms in sequence-to-sequence models such as [38, 2, 9]. The encoder contains self-attention layers. In a self-attention layer all of the keys, values and queries come from the same place, in this case, the output of the previous layer in the encoder. Each position in the encoder can attend to all positions in the previous layer of the encoder. Similarly, self-attention layers in the decoder allow each position in the decoder to attend to all positions in the decoder up to and including that position. We need to prevent leftward information flow in the decoder to preserve the auto-regressive property. We implement this inside of scaled dot-product attention by masking out (setting to −∞) all values in the input of the softmax which correspond to illegal connections. See Figure 2. [Equation: −∞ = -\\infty] Position-wise Feed-Forward Networks In addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully connected feed-forward network, which is applied to each position separately and identically. This consists of two linear transformations with a ReLU activation in between. FFN(x) = max(0, xW1 + b1)W2 + b2 (2) [Equation: FFN(x) = max(0, xW1 + b1)W2 + b2 = \\text{FFN}(x) = \\max(0, xW_1 + b_1)W_2 + b_2] While the linear transformations are the same across different positions, they use different parameters from layer to layer. Another way of describing this is as two convolutions with kernel size 1. The dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality dff = 2048. [Equation: dmodel = 512 = d_{\\text{model}} = 512] [Equation: dff = 2048 = d_{ff} = 2048] Embeddings and Softmax Similarly to other sequence transduction models, we use learned embeddings to convert the input tokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transformation and softmax function to convert the decoder output to predicted next-token probabilities. In our model, we share the same weight matrix between the two embedding layers and the pre-softmax linear transformation, similar to [30]. In the embedding layers, we multiply those weights by √dmodel. [Equation: dmodel = d_{\\text{model}}] [Equation: √dmodel = \\sqrt{d_{\\text{model}}}] Positional Encoding Since our model contains no recurrence and no convolution, in order for the model to make use of the order of the sequence, we must inject some information about the relative or absolute position of the tokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the bottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel as the embeddings, so that the two can be summed. There are many choices of positional encodings, learned and fixed [9]. [Equation: dmodel = d_{\\text{model}}] In this work, we use sine and cosine functions of different frequencies: PE(pos,2i) = sin(pos/100002i/dmodel) [Equation: PE(pos,2i) = sin(pos/100002i/dmodel) = PE_{(pos,2i)} = \\sin(pos/10000^{2i/d_{\\text{model}}})] PE(pos,2i+1) = cos(pos/100002i/dmodel) [Equation: PE(pos,2i+1) = cos(pos/100002i/dmodel) = PE_{(pos,2i+1)} = \\cos(pos/10000^{2i/d_{\\text{model}}})] where pos is the position and i is the dimension. That is, each dimension of the positional encoding corresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We chose this function because we hypothesized it would allow the model to easily learn to attend by relative positions, since for any fixed offset k, PEpos+k can be represented as a linear function of PEpos. [Equation: pos = pos] [Equation: i = i] [Equation: 2π = 2\\pi] [Equation: 10000 · 2π = 10000 \\cdot 2\\pi] [Equation: k = k] [Equation: PEpos+k = PE_{pos+k}] [Equation: PEpos = PE_{pos}] We also experimented with using learned positional embeddings [9] instead, and found that the two versions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version because it may allow the model to extrapolate to sequence lengths longer than the ones encountered during training. 4 Why Self-Attention In this section we compare various aspects of self-attention layers to the recurrent and convolutional layers commonly used for mapping one variable-length sequence of symbol representations (x1,...,xn) to another sequence of equal length (z1,...,zn), with xi,zi ∈ Rd, such as a hidden layer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we consider three desiderata. [Equation: (x1,...,xn) = (x_1,...,x_n)] [Equation: (z1,...,zn) = (z_1,...,z_n)] [Equation: xi,zi ∈ Rd = x_i,z_i \\in \\mathbb{R}^d] One is the total computational complexity per layer. Another is the amount of computation that can be parallelized, as measured by the minimum number of sequential operations required. The third is the path length between long-range dependencies in the network. Learning long-range dependencies is a key challenge in many sequence transduction tasks. One key factor affecting the ability to learn such dependencies is the length of the paths forward and backward signals have to traverse in the network. The shorter these paths between any combination of positions in the input and output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare the maximum path length between any two input and output positions in networks composed of the different layer types. As noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially executed operations, whereas a recurrent layer requires O(n) sequential operations. In terms of computational complexity, self-attention layers are faster than recurrent layers when the sequence length n is smaller than the representation dimensionality d, which is most often the case with sentence representations used by state-of-the-art models in machine translations, such as word-piece [38] and byte-pair [31] representations. To improve computational performance for tasks involving very long sequences, self-attention could be restricted to considering only a neighborhood of size r in the input sequence centered around the respective output position. This would increase the maximum path length to O(n/r). We plan to investigate this approach further in future work. [Equation: O(n) = O(n)] [Equation: n = n] [Equation: d = d] [Equation: r = r] [Equation: O(n/r) = O(n/r)] A single convolutional layer with kernel width k < n does not connect all pairs of input and output positions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels, or O(logk(n)) in the case of dilated convolutions [18], increasing the length of the longest paths between any two positions in the network. Convolutional layers are generally more expensive than recurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity considerably, to O(k ·n ·d + n ·d2). Even with k = n, however, the complexity of a separable convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer, the approach we take in our model. [Equation: k < n = k < n] [Equation: O(n/k) = O(n/k)] [Equation: O(logk(n)) = O(\\log_k(n))] [Equation: k = k] [Equation: O(k ·n ·d + n ·d2) = O(k \\cdot n \\cdot d + n \\cdot d^2)] [Equation: k = n = k = n] As side benefit, self-attention could yield more interpretable models. We inspect attention distributions from our models and present and discuss examples in the appendix. Not only do individual attention heads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic and semantic structure of the sentences. Training This section describes the training regime for our models. Training Data and Batching We trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million sentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-target vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT 2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece vocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training batch contained a set of sentence pairs containing approximately 25000 source tokens and 25000 target tokens. Hardware and Schedule We trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using the hyperparameters described throughout the paper, each training step took about 0.4 seconds. We trained the base models for a total of 100,000 steps or 12 hours. For our big models, (described on the bottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps (3.5 days). Optimizer We used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ε = 10−9. We varied the learning rate over the course of training, according to the formula: [Equation: β1 = 0.9 = \\beta_1 = 0.9] [Equation: β2 = 0.98 = \\beta_2 = 0.98] [Equation: ε = 10−9 = \\epsilon = 10^{-9}] lrate = d−0.5model · min(step_num−0.5, step_num · warmup_steps−1.5) (3) [Equation: lrate = d−0.5model · min(step_num−0.5, step_num · warmup_steps−1.5) = \\text{lrate} = d_{\\text{model}}^{-0.5} \\cdot \\min(\\text{step\\_num}^{-0.5}, \\text{step\\_num} \\cdot \\text{warmup\\_steps}^{-1.5})] This corresponds to increasing the learning rate linearly for the first warmup_steps training steps, and decreasing it thereafter proportionally to the inverse square root of the step number. We used warmup_steps = 4000. [Equation: warmup_steps = \\text{warmup\\_steps}] [Equation: warmup_steps = 4000 = \\text{warmup\\_steps} = 4000] Regularization We employ three types of regularization during training: Residual Dropout: We apply dropout [33] to the output of each sub-layer, before it is added to the sub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the positional encodings in both the encoder and decoder stacks. For the base model, we use a rate of Pdrop = 0.1. [Equation: Pdrop = 0.1 = P_{drop} = 0.1] Label Smoothing: During training, we employed label smoothing of value εls = 0.1 [36]. This hurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score. [Equation: εls = 0.1 = \\epsilon_{ls} = 0.1] Results Machine Translation On the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big) in Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0 BLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is listed in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model surpasses all previously published models and ensembles, at a fraction of the training cost of any of the competitive models. On the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0, outperforming all of the previously published single models, at less than 1/4 the training cost of the previous state-of-the-art model. The Transformer (big) model trained for English-to-French used dropout rate Pdrop = 0.1, instead of 0.3. [Equation: Pdrop = 0.1 = P_{drop} = 0.1] For the base models, we used a single model obtained by averaging the last 5 checkpoints, which were written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We used beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameters were chosen after experimentation on the development set. We set the maximum output length during inference to input length + 50, but terminate early when possible [38]. [Equation: α = 0.6 = \\alpha = 0.6] Table 2 summarizes our results and compares our translation quality and training costs to other model architectures from the literature. We estimate the number of floating point operations used to train a model by multiplying the training time, the number of GPUs used, and an estimate of the sustained single-precision floating-point capacity of each GPU [^5]. Model Variations To evaluate the importance of different components of the Transformer, we varied our base model in different ways, measuring the change in performance on English-to-German translation on the development set, newstest2013. We used beam search as described in the previous section, but no checkpoint averaging. We present these results in Table 3. In Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions, keeping the amount of computation constant, as described in Section 3.2.2. While single-head attention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads. In Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This suggests that determining compatibility is not easy and that a more sophisticated compatibility function than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected, bigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our sinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical results to the base model. [Equation: dk = d_k] English Constituency Parsing To evaluate if the Transformer can generalize to other tasks we performed experiments on English constituency parsing. This task presents specific challenges: the output is subject to strong structural constraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence models have not been able to attain state-of-the-art results in small-data regimes [37]. We trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the Penn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting, using the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences [37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens for the semi-supervised setting. [Equation: dmodel = 1024 = d_{\\text{model}} = 1024] We performed only a small number of experiments to select the dropout, both attention and residual (section 5.4), learning rates and beam size on the Section 22 development set, all other parameters remained unchanged from the English-to-German base translation model. During inference, we increased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3 for both WSJ only and the semi-supervised setting. [Equation: α = 0.3 = \\alpha = 0.3] Our results in Table 4 show that despite the lack of task-specific tuning our model performs surprisingly well, yielding better results than all previously reported models with the exception of the Recurrent Neural Network Grammar [8]. In contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the BerkeleyParser [29] even when training only on the WSJ training set of 40K sentences. 7 Conclusion In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles. We are excited about the future of attention-based models and plan to apply them to other tasks. We plan to extend the Transformer to problems involving input and output modalities other than text and to investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs such as images, audio and video. Making generation less sequential is another research goals of ours. The code we used to train and evaluate our models is available at https://github.com/tensorflow/tensor2tensor. Figure figure_1: The Transformer - model architecture. Figure figure_2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several attention layers running in parallel. Figure figure_3: An example of the attention mechanism following long-distance dependencies in the encoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of the verb 'making', completing the phrase 'making...more difficult'. Attentions here shown only for the word 'making'. Different colors represent different heads. Figure figure_4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top: Full attentions for head 5. Bottom: Isolated attentions from just the word 'its' for attention heads 5 and 6. Note that the attentions are very sharp for this word. Figure figure_5: Many of the attention heads exhibit behaviour that seems related to the structure of the sentence. We give two such examples above, from two different heads from the encoder self-attention at layer 5 of 6. The heads clearly learned to perform different tasks. Table table_1: Maximum path lengths, per-layer complexity and minimum number of sequential operations for different layer types. n is the sequence length, d is the representation dimension, k is the kernel size of convolutions and r the size of the neighborhood in restricted self-attention. Table table_2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the English-to-German and English-to-French newstest2014 tests at a fraction of the training cost. Table table_3: Variations on the Transformer architecture. Unlisted values are identical to those of the base model. All metrics are on the English-to-German translation development set, newstest2013. Listed perplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to per-word perplexities. Table table_4: The Transformer generalizes well to English constituency parsing (Results are on Section 23 of WSJ)",
      "word_count": 4592,
      "character_count": 30307,
      "vector": [
        0.17891666293144226,
        -0.0792744904756546,
        -0.002635600510984659,
        0.039328861981630325,
        0.06315569579601288,
        0.0882498174905777,
        -0.09320767968893051,
        0.033994343131780624,
        0.0076331184245646,
        -0.1491549015045166,
        -0.09830685704946518,
        0.05053155869245529,
        -0.035765375941991806,
        -0.005774719640612602,
        -0.00920159462839365,
        0.12847387790679932,
        -0.08681012690067291,
        -0.025177378207445145,
        -0.05627922713756561,
        -0.03461343050003052,
        -0.06553075462579727,
        0.015674013644456863,
        -0.027296297252178192,
        0.08943328261375427,
        -0.06951679289340973,
        0.06891792267560959,
        -0.028717081993818283,
        -0.08109018951654434,
        -0.05720114707946777,
        0.002976583084091544,
        0.09853147715330124,
        -0.03746040537953377,
        -0.0031506484374403954,
        -0.0417909137904644,
        0.044274285435676575,
        -0.0134699372574687,
        0.07120019197463989,
        -0.03493376076221466,
        -0.04164281114935875,
        -0.03778262063860893,
        0.0014194321120157838,
        0.001322293421253562,
        -0.0518476665019989,
        -0.028510643169283867,
        0.1074657291173935,
        0.09996363520622253,
        0.011291316710412502,
        -0.061902109533548355,
        0.0536358617246151,
        0.005470385774970055,
        0.014784430153667927,
        0.09909568727016449,
        -0.09226450324058533,
        0.011113439686596394,
        0.012931169010698795,
        0.002733116038143635,
        -0.0399109311401844,
        0.042928822338581085,
        0.056372713297605515,
        0.013709439896047115,
        -0.02034853771328926,
        0.04944203048944473,
        0.07742039859294891,
        -0.012328128330409527,
        -0.020367417484521866,
        0.05231564864516258,
        0.05918674170970917,
        -0.08637528121471405,
        0.013701127842068672,
        -0.010498546995222569,
        0.00488022668287158,
        -0.010755525901913643,
        -0.037962816655635834,
        0.020557314157485962,
        -0.05538316071033478,
        0.007173724472522736,
        -0.02289835922420025,
        -0.0344725139439106,
        0.04105812683701515,
        -0.014883137308061123,
        0.13336719572544098,
        -0.033999305218458176,
        0.05424412712454796,
        -0.009603962302207947,
        0.028788849711418152,
        -0.02860858663916588,
        -0.0025541940703988075,
        -0.03132045269012451,
        0.019460970535874367,
        0.01656089536845684,
        -0.02372489683330059,
        -0.04398692771792412,
        -0.006076869089156389,
        -0.06394147127866745,
        0.04275093600153923,
        -0.054072268307209015,
        -0.04307353124022484,
        0.058339521288871765,
        -0.02205280214548111,
        -0.019292201846837997,
        0.038413289934396744,
        0.001852520857937634,
        -0.05365905538201332,
        0.05361974239349365,
        0.009933206252753735,
        -0.018684521317481995,
        0.033987682312726974,
        -0.03518438711762428,
        -0.07341089844703674,
        0.02974507212638855,
        -0.04953676462173462,
        0.041466567665338516,
        0.011579513549804688,
        0.03293530270457268,
        -0.0036995718255639076,
        0.00786422099918127,
        -0.0052677602507174015,
        0.04590597748756409,
        0.04906938970088959,
        -0.009947744198143482,
        -0.07582086324691772,
        -0.022253280505537987,
        -0.0005002253456041217,
        0.0686306580901146,
        -0.03913811221718788,
        -0.05634089931845665,
        -0.04176702722907066,
        0.042564138770103455,
        -0.024913784116506577,
        -0.044322386384010315,
        -0.039532437920570374,
        0.01745283231139183,
        0.013798831030726433,
        0.04417252913117409,
        -0.0498778261244297,
        -0.03610600158572197,
        0.00836869329214096,
        0.04182961583137512,
        0.03851458430290222,
        0.049549080431461334,
        0.05229935795068741,
        0.05307002738118172,
        0.020116427913308144,
        -0.0029171232599765062,
        -0.010523823089897633,
        -0.015001526102423668,
        -0.025601724162697792,
        0.006920579355210066,
        0.027776552364230156,
        -0.042441949248313904,
        0.0015779974637553096,
        -0.004528405144810677,
        -0.004150607623159885,
        0.026709292083978653,
        -0.022632794454693794,
        -0.03279727324843407,
        0.014731711708009243,
        -0.023122243583202362,
        -0.030566729605197906,
        0.03220139443874359,
        -0.023415762931108475,
        0.01922145113348961,
        -0.0011516378726810217,
        -0.006173756904900074,
        -0.027271591126918793,
        0.01866418495774269,
        -0.049872878938913345,
        0.048495400696992874,
        0.0580161027610302,
        0.014012262225151062,
        -0.032434750348329544,
        0.025838343426585197,
        0.0579509474337101,
        -0.06907423585653305,
        -0.0029102459084242582,
        -0.06056547537446022,
        0.004730224609375,
        0.05638241395354271,
        -0.005127867683768272,
        0.02895408682525158,
        0.042961589992046356,
        0.011314674280583858,
        -0.012419995851814747,
        -0.008633948862552643,
        -0.06254391372203827,
        0.043540798127651215,
        0.009959879331290722,
        -0.029143160209059715,
        0.01464033592492342,
        0.008697282522916794,
        0.006206077057868242,
        0.03000861406326294,
        0.09356198459863663,
        0.01625487208366394,
        0.025745244696736336,
        0.03678526356816292,
        -0.058972086757421494,
        0.018274497240781784,
        0.02319488674402237,
        0.0005438601365312934,
        0.0028073275461792946,
        -0.01505302358418703,
        -0.005177170038223267,
        -0.035782720893621445,
        0.002591285854578018,
        0.01321527361869812,
        -0.03008713759481907,
        -0.042912643402814865,
        -0.02408415637910366,
        0.0656156837940216,
        0.02081340365111828,
        0.003593452973291278,
        0.032041996717453,
        0.050469301640987396,
        -0.05356908589601517,
        -0.026808135211467743,
        0.0489644892513752,
        0.02988484315574169,
        0.07376862317323685,
        0.0020927251316607,
        0.0460716150701046,
        0.016115637496113777,
        -0.03306246176362038,
        -0.06749827414751053,
        -0.026378581300377846,
        0.018361683934926987,
        -0.00481856893748045,
        0.0714465007185936,
        0.017730966210365295,
        -0.01764027215540409,
        -0.02047842927277088,
        5.5851691286079586e-05,
        -0.005610543303191662,
        0.014958551153540611,
        0.04462049528956413,
        0.001956563675776124,
        -0.061737868934869766,
        0.02465801127254963,
        0.01451321691274643,
        0.027326079085469246,
        0.03609774634242058,
        0.04172961041331291,
        -0.005414647050201893,
        -0.013936403207480907,
        -0.05605540797114372,
        -0.06092946231365204,
        -0.03874712064862251,
        -0.05287647247314453,
        -0.007682905066758394,
        0.059963345527648926,
        -0.005380920600146055,
        0.01498112827539444,
        -0.040073979645967484,
        0.008601395413279533,
        0.020131127908825874,
        0.03613917529582977,
        0.04092184081673622,
        -0.002850481541827321,
        0.012744655832648277,
        0.0061003174632787704,
        -0.007995866239070892,
        0.07885227352380753,
        0.0037987453397363424,
        0.04551474377512932,
        -0.06623561680316925,
        0.023421507328748703,
        -0.006498066242784262,
        -0.013683760538697243,
        0.0014378268970176578,
        -0.03545349836349487,
        -0.05521044507622719,
        -0.016223501414060593,
        0.005536235868930817,
        0.011264265514910221,
        -0.011047529987990856,
        -0.016849789768457413,
        -0.019299130886793137,
        0.05048435181379318,
        -0.027581848204135895,
        -0.0392444021999836,
        -0.025233976542949677,
        -0.03399243578314781,
        -0.002757598413154483,
        -0.011326772160828114,
        -0.009322449564933777,
        -0.017971165478229523,
        0.01169414073228836,
        0.039201561361551285,
        -0.0032056323252618313,
        -0.007492539007216692,
        0.006400348152965307,
        0.003510573646053672,
        -0.0005136718391440809,
        -0.020068340003490448,
        0.000487717887153849,
        0.03566960617899895,
        -0.07050296664237976,
        -0.002056403551250696,
        0.039091311395168304,
        0.005512704141438007,
        -0.0016314939130097628,
        0.03753498196601868,
        0.0007209153263829648,
        -0.02544330433011055,
        0.01732935756444931,
        0.00592120410874486,
        -0.03365033492445946,
        -0.041144080460071564,
        -0.0224301740527153,
        -0.0045182532630860806,
        0.013973772525787354,
        -0.04752908647060394,
        -0.012111101299524307,
        0.03534675016999245,
        0.005081251263618469,
        0.03920012339949608,
        0.004466325975954533,
        0.031534213572740555,
        -0.008805100806057453,
        -0.02413228712975979,
        0.0153953330591321,
        -0.0025562471710145473,
        0.04433485120534897,
        -0.050606463104486465,
        -0.02209768071770668,
        -0.057634565979242325,
        0.011820838786661625,
        -0.0023813729640096426,
        -0.008908405900001526,
        -0.02198660373687744,
        -0.02135179005563259,
        0.0038939956575632095,
        0.008992273360490799,
        0.02041090838611126,
        0.018810808658599854,
        0.011430085636675358,
        -0.003088213736191392,
        -0.014924458228051662,
        0.04390155151486397,
        -0.005656678229570389,
        0.03416823223233223,
        -0.008952253498136997,
        -0.03555956482887268,
        -0.005089631769806147,
        0.023410355672240257,
        0.03746102750301361,
        0.013998480513691902,
        -0.01782037876546383,
        -0.010607864707708359,
        0.023150518536567688,
        0.010850896127521992,
        0.05211447924375534,
        -0.010030033998191357,
        -0.013121264986693859,
        0.010720856487751007,
        0.03939689323306084,
        -0.031293127685785294,
        0.003415711224079132,
        0.05620633438229561,
        -0.03785041347146034,
        -0.022954048588871956,
        -0.03866294398903847,
        0.0018062895396724343,
        0.035499364137649536,
        -0.008703493513166904,
        0.020472504198551178,
        -0.030619226396083832,
        0.06507120281457901,
        0.0030429211910814047,
        -0.019627699628472328,
        -0.019692562520503998,
        -0.036105018109083176,
        -0.0056934296153485775,
        -0.019915904849767685,
        -0.003569026943296194,
        0.0084634218364954,
        0.0035347803495824337,
        0.010091503150761127,
        0.08533801138401031,
        0.005868562497198582,
        -0.030553413555026054,
        -0.023237379267811775,
        0.046648960560560226,
        0.010271658189594746,
        0.03197017312049866,
        0.016660485416650772,
        0.09250259399414062,
        0.003077638102695346,
        -0.054270997643470764,
        0.004300419706851244,
        -0.003137419233098626,
        0.027704503387212753,
        0.009227907285094261,
        0.025132939219474792,
        -0.038628678768873215,
        -0.0037890844978392124,
        -0.003138079307973385,
        0.049282681196928024,
        0.04133835807442665,
        -0.0003163931251037866,
        0.011659816838800907,
        0.02597842551767826,
        -0.03406728804111481,
        -0.018415432423353195,
        0.035268738865852356,
        -0.006200689822435379,
        0.000700835429597646,
        0.006511505227535963,
        -0.06531842797994614,
        -0.017057690769433975,
        -0.014044596813619137,
        -0.02590644359588623,
        -0.03544706478714943,
        0.026046734303236008,
        -0.009052444249391556,
        -0.025820188224315643,
        -0.013093574903905392,
        0.01552833802998066,
        0.008826679550111294,
        -0.002937941811978817,
        0.021550724282860756,
        0.02408469468355179,
        0.007250012829899788,
        0.009493962861597538,
        0.019949913024902344,
        -0.018311291933059692,
        -0.05067780241370201,
        -0.029767418280243874,
        0.028188709169626236,
        0.017434872686862946,
        -0.03357989341020584,
        -0.028999874368309975,
        0.011061498895287514,
        0.04914778098464012,
        -0.03651120886206627,
        -0.002209393074735999,
        -0.008321061730384827,
        0.0007470337441191077,
        -0.0013576227938756347,
        -0.0007221430423669517,
        0.028647439554333687,
        0.0061311982572078705,
        -0.019493281841278076,
        -0.0035300152376294136,
        -0.022572675719857216,
        0.010349225252866745,
        0.03138461336493492,
        -0.007134550716727972,
        0.01287072990089655,
        -0.028018604964017868,
        -0.015760423615574837,
        0.03351469337940216,
        -0.05412774533033371,
        -0.007325298152863979,
        -0.026636073365807533,
        0.0009405994787812233,
        0.05101148411631584,
        -0.04644840583205223,
        0.0009487830684520304,
        -0.0038644850719720125,
        0.017923487350344658,
        0.009662439115345478,
        0.023137230426073074,
        -0.04405539482831955,
        0.051783282309770584,
        0.009361352771520615,
        0.04210614040493965,
        0.006124269217252731,
        0.025763342157006264,
        -0.014289370737969875,
        0.01801448129117489,
        0.038745153695344925,
        -0.004462931305170059,
        -0.006776221562176943,
        -0.04125161096453667,
        -0.013153881765902042,
        -0.0047687264159321785,
        -0.01581459678709507,
        -0.009166419506072998,
        -0.014395026490092278,
        -0.052078597247600555,
        -0.05189186707139015,
        0.021771900355815887,
        0.02489962987601757,
        0.04426836967468262,
        -0.01643877476453781,
        0.037743743509054184,
        -0.0667860209941864,
        0.05517981946468353,
        0.016032498329877853,
        0.019837595522403717,
        -0.030119117349386215,
        -0.0016453413991257548,
        0.003864708822220564,
        -0.045364268124103546,
        -0.03065347671508789,
        -0.03165928274393082,
        -0.04119109734892845,
        -0.028501922264695168,
        -0.05111527815461159,
        -0.02127518132328987,
        0.012078759260475636,
        -0.029686784371733665,
        -0.009540078230202198,
        -0.0007026819512248039,
        -0.04803991690278053,
        -0.003920105751603842,
        0.0067488704808056355,
        -0.020310403779149055,
        -0.02478959411382675,
        -0.012263033539056778,
        0.030661456286907196,
        -0.0029135842341929674,
        0.01029369980096817,
        -0.007314916700124741,
        0.003081693546846509,
        0.018703561276197433,
        -0.032697610557079315,
        0.00023383329971693456,
        -0.013492518104612827,
        0.012573229148983955,
        -0.010406538844108582,
        -0.012061859481036663,
        -0.03397076576948166,
        0.010322337038815022,
        0.017937691882252693,
        -0.023613041266798973,
        -0.026788171380758286,
        0.031826332211494446,
        0.029413122683763504,
        0.02978290058672428,
        0.030434325337409973,
        0.02370567061007023,
        -0.02478581853210926,
        0.007278452627360821,
        0.009802138432860374,
        -0.01330509502440691,
        -0.01863282360136509,
        -0.013812938705086708,
        -0.004417257849127054,
        0.011169933713972569,
        0.01803712360560894,
        -0.0053485543467104435,
        -0.005598518531769514,
        -0.05258956924080849,
        0.0037522451020777225,
        0.03649172559380531,
        0.009163910523056984,
        0.02669081836938858,
        0.03138161450624466,
        -0.033555977046489716,
        0.011408376507461071,
        -0.02868512272834778,
        -0.023575369268655777,
        -0.01259289775043726,
        -0.02159389667212963,
        0.026520682498812675,
        0.002664579777047038,
        -0.008259613066911697,
        0.0013839900493621826,
        0.0010999025544151664,
        -0.016759490594267845,
        -0.0056607844308018684,
        -0.06178027018904686,
        -0.021093733608722687,
        -0.016951249912381172,
        0.011895679868757725,
        -0.02273293025791645,
        -0.04288662597537041,
        0.0260803010314703,
        -0.0007799357990734279,
        0.018864059820771217,
        -0.003962543793022633,
        0.02149670571088791,
        -0.017569443210959435,
        -0.025054996833205223,
        -0.022435374557971954,
        0.07289796322584152,
        0.0003616466710809618,
        0.010231425054371357,
        -0.008745421655476093,
        -0.02322646975517273,
        -0.02007795311510563,
        0.0336197093129158,
        -0.0006231616134755313,
        -0.013095938600599766,
        0.02238091453909874,
        0.019392630085349083,
        0.004525754135102034,
        0.004675776697695255,
        0.0001589409075677395,
        -0.01686090975999832,
        0.012492752633988857,
        -0.0007997524226084352,
        0.05004845932126045,
        0.0007782592438161373,
        -0.019960414618253708,
        -0.0496993362903595,
        0.028308669105172157,
        -0.038579199463129044,
        -0.05674251914024353,
        -0.02815132401883602,
        0.040182460099458694,
        -0.01772475801408291,
        0.01962418667972088,
        0.02510812319815159,
        0.01838362030684948,
        0.022040626034140587,
        -0.010579665191471577,
        -0.03593587502837181,
        -0.004837913904339075,
        0.0047213067300617695,
        0.010037679225206375,
        0.01109155360609293,
        0.06006915867328644,
        0.022412795573472977,
        -0.012418702244758606,
        0.000776127097196877,
        -0.04207512363791466,
        0.0033120247535407543,
        -0.000519462046213448,
        0.0015601421473547816,
        0.0021698286291211843,
        -0.01264381967484951,
        -0.008635049685835838,
        -0.0015498775755986571,
        0.020193129777908325,
        0.04307735338807106,
        -0.015780236572027206,
        0.01616549678146839,
        -0.010396669618785381,
        0.02623969502747059,
        -0.001777277677319944,
        -0.02957761473953724,
        -0.034352730959653854,
        0.02326214499771595,
        0.03499405086040497,
        0.026860304176807404,
        0.04532463848590851,
        0.04266893118619919,
        0.014257420785725117,
        -0.017643185332417488,
        0.014942298643290997,
        0.03722910210490227,
        0.0018076605629175901,
        -0.02451011911034584,
        -0.0021105785854160786,
        0.025219207629561424,
        0.00473628006875515,
        -0.009818663820624352,
        -0.046702392399311066,
        -0.013098432682454586,
        -0.02204645425081253,
        0.006940103601664305,
        -0.011609167791903019,
        -0.00920716393738985,
        0.015599549748003483,
        0.005803602281957865,
        0.009127668105065823,
        -0.016108417883515358,
        0.0003869300417136401,
        -0.027936642989516258,
        0.07703430950641632,
        -0.03970460593700409,
        -0.020912928506731987,
        0.020914560183882713,
        0.008211773820221424,
        0.03239023685455322,
        0.019796159118413925,
        -0.010624617338180542,
        -0.04052843526005745,
        -0.001275559770874679,
        0.027852443978190422,
        -0.01285157073289156,
        0.0008251232793554664,
        0.0012332802871242166,
        0.01214794721454382,
        0.0018764797132462263,
        0.011845561675727367,
        0.002448274288326502,
        0.0015125948702916503,
        -0.017313510179519653,
        0.041069403290748596,
        -0.03139563649892807,
        0.015363458544015884,
        -0.008926775306463242,
        -0.04377341270446777,
        0.02822474017739296,
        -0.012108474969863892,
        0.035597074776887894,
        -0.0068446877412498,
        0.0012322418624535203,
        -0.02906581200659275,
        0.016201529651880264,
        0.0045961178839206696,
        -0.015842385590076447,
        0.012346147559583187,
        0.011481020599603653,
        0.012678318656980991,
        -0.005456092301756144,
        -0.0009742403635755181,
        0.010891352780163288,
        0.030058685690164566,
        -0.03248832747340202,
        -0.01451313216239214,
        0.004660513252019882,
        -0.013926461338996887,
        0.023463500663638115,
        -0.007222388405352831,
        0.05754408240318298,
        -0.024878624826669693,
        -0.041519418358802795,
        0.031368985772132874,
        -0.004910193849354982,
        -0.0070581985637545586,
        -0.056326206773519516,
        0.004811461083590984,
        -0.037668485194444656,
        0.027583075687289238,
        0.016664212569594383,
        -0.018184294924139977,
        -0.029471421614289284,
        0.04181690141558647,
        0.005683631636202335,
        0.00440527917817235,
        0.004522805102169514,
        0.03123258426785469,
        0.015611124224960804,
        -0.002228229306638241,
        0.020016726106405258,
        -0.008658066391944885,
        0.012806549668312073,
        0.0049039036966860294,
        -0.029915418475866318,
        -0.016257448121905327,
        -0.003106893738731742,
        0.020808806642889977,
        0.015666775405406952,
        -0.038923054933547974,
        -0.005360117182135582,
        0.014446812681853771,
        0.004105656873434782,
        -0.026073550805449486,
        0.01373197603970766,
        0.023407720029354095,
        -0.018419021740555763,
        0.004081460181623697,
        0.0229291170835495,
        0.003440703498199582,
        -0.04085231199860573,
        0.021630579605698586,
        0.03125237673521042,
        -0.019714659079909325,
        -0.013436500914394855,
        -0.0027843022253364325,
        -0.03393956273794174,
        -0.028100095689296722,
        0.01088223047554493,
        0.03558729961514473,
        -0.026973722502589226,
        -0.00807987805455923,
        0.062389474362134933,
        0.0021751048043370247,
        0.04628104716539383,
        -0.0411735363304615,
        0.049312740564346313,
        -0.016014710068702698,
        -0.007855216972529888,
        -0.028808601200580597,
        0.012549747712910175,
        0.028184713795781136,
        -0.020513281226158142,
        0.009246759116649628,
        0.013318910263478756,
        0.002735817339271307,
        0.0035614510998129845,
        -0.0026298731099814177,
        -0.006721871439367533,
        -0.010654971934854984,
        -0.001776246353983879,
        -0.030226372182369232,
        -0.01972266286611557,
        -0.04364306107163429,
        0.030126746743917465,
        0.00553325517103076,
        0.00962601788341999,
        0.016264041885733604,
        0.0049616615287959576,
        -0.01639777049422264,
        -0.00041905074613168836,
        -0.005441101733595133,
        -0.015364572405815125,
        -0.02575846016407013,
        -0.005292314570397139,
        -0.02634800784289837,
        0.012345788069069386,
        -0.018391301855444908,
        0.04807266965508461,
        0.01020091399550438,
        0.0011704210191965103,
        0.0008450836758129299,
        0.03396005555987358,
        0.01007839385420084,
        -0.0024931884836405516,
        0.007407935801893473,
        0.0072680008597671986,
        -0.023074716329574585,
        -0.00481075095012784,
        0.011190343648195267,
        -0.005647518206387758,
        0.01729304902255535,
        -0.002900840248912573,
        0.007442228030413389,
        -0.04619114473462105,
        -0.025654874742031097,
        0.010386836715042591,
        -0.006425842177122831,
        0.0413011871278286,
        -0.0015135117573663592,
        -0.016777662560343742,
        -0.02021508291363716,
        -0.004919861443340778,
        -0.008651620708405972,
        -0.005127145908772945,
        -0.04086372256278992,
        0.02055276930332184,
        -0.013844883069396019,
        0.0008379062637686729,
        -0.02774318866431713,
        0.0193529911339283,
        0.021840384230017662,
        0.030464788898825645,
        -0.010486052371561527,
        -0.0025420505553483963,
        -0.0009654555469751358,
        -0.04086025804281235,
        -0.025841251015663147,
        0.013585538603365421,
        -0.013912207446992397,
        0.005965850781649351,
        -0.020361514762043953,
        -0.025518009439110756,
        0.004225884098559618,
        -0.003919797949492931,
        -0.011978059075772762,
        0.028007693588733673,
        -0.01711774617433548,
        0.0030376985669136047,
        0.029970206320285797,
        0.011795340105891228,
        -0.01096663810312748,
        -0.018099619075655937,
        0.01116607990115881,
        0.0065582687966525555,
        -0.02002827450633049,
        -0.011208861134946346,
        0.01503638457506895,
        -0.017264772206544876,
        -0.021551117300987244,
        -0.0036020532716065645,
        -0.03311964124441147,
        -0.008790114894509315,
        -0.018924053758382797,
        -0.00813524704426527,
        -0.02914750762283802,
        -0.006604012567549944,
        -0.041941363364458084,
        0.0038998189847916365,
        0.00045539854909293354,
        -0.0007551944581791759,
        0.012995893135666847,
        -0.00728093134239316,
        0.031422700732946396,
        -0.0001530869776615873,
        -0.024460511282086372,
        -0.05076124146580696,
        -0.013933447189629078,
        0.022597331553697586,
        0.00883457250893116,
        0.016697054728865623,
        -0.016033202409744263,
        0.02875964157283306,
        -0.0175376757979393,
        0.02176259458065033,
        0.015621221624314785,
        -0.008436133153736591,
        0.03292567655444145,
        -0.007050438318401575,
        -0.025933887809515,
        0.010994586162269115,
        0.01337091438472271,
        -0.005859262775629759,
        -0.02671845629811287,
        0.017649207264184952,
        -0.023623935878276825,
        -0.0045906612649559975,
        -0.01602400466799736,
        0.015523846261203289,
        0.01904441975057125,
        -0.03166797012090683,
        -0.04737931862473488,
        0.025960545986890793,
        -0.012196003459393978,
        -0.0037024542689323425,
        0.019015701487660408,
        0.005255235359072685,
        0.026709098368883133,
        -0.03931727260351181,
        0.020794380456209183,
        -0.020305214449763298,
        0.032829660922288895,
        0.015049147419631481,
        0.02782147005200386,
        0.05588557571172714,
        -0.020917778834700584,
        0.033276863396167755,
        0.009714503772556782,
        0.031271252781152725,
        -0.03468939661979675,
        0.017271356657147408,
        0.002253565238788724,
        -0.00039454331272281706,
        -0.016858691349625587,
        -0.07196464389562607,
        -0.01780776120722294,
        -0.04396558180451393,
        0.024814322590827942,
        -0.01648947410285473,
        0.005901101510971785,
        -0.0038262424059212208,
        0.03101164847612381,
        -0.01155778206884861,
        0.041726771742105484,
        -0.006016249302774668,
        -0.02376866154372692,
        -0.0033387800212949514,
        0.0165433157235384,
        0.013904263265430927,
        -0.00958377867937088,
        0.02100902423262596,
        -0.02611655928194523,
        0.019260220229625702,
        0.007105228956788778,
        0.054757725447416306,
        0.04085230827331543,
        -0.03746134787797928,
        0.0008450846653431654,
        -0.0029353199061006308,
        -0.009649541229009628,
        -0.009099206887185574,
        -0.034616220742464066,
        0.013660237193107605,
        -0.008351343683898449,
        -0.01053303387016058,
        -0.019855311140418053,
        -0.012355700135231018,
        0.052970919758081436,
        0.02000359632074833,
        -2.385750849498436e-05,
        -0.014016188681125641,
        0.010792015120387077,
        -0.011532709002494812,
        -0.05366494879126549,
        0.006595349870622158,
        -0.020507752895355225,
        0.009691398590803146,
        0.023719031363725662,
        0.01311434991657734,
        -0.017676571384072304,
        0.03487664833664894,
        -0.012037606909871101,
        -0.011302432976663113,
        0.004351296927779913,
        0.018905410543084145,
        -0.006960897706449032,
        -0.015230301767587662,
        0.029554961249232292,
        0.02944241091609001,
        -0.003117677289992571,
        0.04865884780883789,
        0.02354520931839943,
        -0.031227758154273033,
        0.022657303139567375,
        0.009375941939651966,
        0.004819350782781839,
        0.032405540347099304,
        0.0007834580028429627,
        0.011472083628177643,
        0.008323587477207184,
        0.019507404416799545,
        0.03182769939303398,
        -0.012498104944825172,
        -0.043517082929611206,
        -0.015102270059287548,
        0.018079964444041252,
        -0.010402313433587551,
        0.010438036173582077,
        5.734781734645367e-05,
        0.02124680206179619,
        -0.019642595201730728,
        -0.023252474144101143,
        -0.015250143595039845,
        0.01480832789093256,
        0.02327459119260311,
        0.007325407583266497,
        0.017119819298386574,
        -0.01833641715347767,
        0.015405995771288872,
        -0.03896680474281311,
        0.01619449257850647,
        0.03489889204502106,
        0.02525397203862667,
        0.020257318392395973,
        0.009538710117340088,
        -0.004373894073069096,
        -0.010039527900516987,
        0.0007187672890722752,
        0.0036241840571165085,
        0.005726313684135675,
        -0.049789126962423325,
        -0.0031940306071192026,
        0.03974277153611183,
        -0.007804955821484327,
        0.0316409096121788
      ],
      "title": "Attention is All You Need"
    },
    {
      "id": "gai-eng_corpus-item002",
      "count": 2,
      "created": "2025-07-06T04:31:22.074992",
      "text": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models. INTRODUCTION One of the biggest trends in natural language processing (NLP) has been the increasing size of language models (LMs) as measured by the number of parameters and size of training data. Since 2018 alone, we have seen the emergence of BERT and its variants [39, 70, 74, 113, 146], GPT-2 [106], T-NLG [112], GPT-3 [25], and most recently Switch-C [43], with institutions seemingly competing to produce ever larger LMs. While investigating properties of LMs and how they change with size holds scientific interest, and large LMs have shown improvements on various tasks (§2), we ask whether enough thought has been put into the potential risks associated with developing them and strategies to mitigate these risks. We first consider environmental risks. Echoing a line of recent work outlining the environmental and financial costs of deep learning systems [129], we encourage the research community to prioritize these impacts. One way this can be done is by reporting costs and evaluating works based on the amount of resources they consume [57]. As we outline in §3, increasing the environmental and financial costs of these models doubly punishes marginalized communities that are least likely to benefit from the progress achieved by large LMs and most likely to be harmed by negative environmental consequences of its resource consumption. At the scale we are discussing (outlined in §2), the first consideration should be the environmental cost. Just as environmental impact scales with model size, so does the difficulty of understanding what is in the training data. In §4, we discuss how large datasets based on texts from the Internet overrepresent hegemonic viewpoints and encode biases potentially damaging to marginalized populations. In collecting ever larger datasets we risk incurring documentation debt. We recommend mitigating these risks by budgeting for curation and documentation at the start of a project and only creating datasets as large as can be sufficiently documented. As argued by Bender and Koller [14], it is important to understand the limitations of LMs and put their success in context. This not only helps reduce hype which can mislead the public and researchers themselves regarding the capabilities of these LMs, but might encourage new research directions that do not necessarily depend on having larger LMs. As we discuss in §5, LMs are not performing natural language understanding (NLU), and only have success in tasks that can be approached by manipulating linguistic form [14]. Focusing on state-of-the-art results on leaderboards without encouraging deeper understanding of the mechanism by which they are achieved can cause misleading results as shown in [21, 93] and direct resources away from efforts that would facilitate long-term progress towards natural language understanding, without using unfathomable training data. Furthermore, the tendency of human interlocutors to impute meaning where there is none can mislead both NLP researchers and the general public into taking synthetic text as meaningful. Combined with the ability of LMs to pick up on both subtle biases and overtly abusive language patterns in training data, this leads to risks of harms, including encountering derogatory language and experiencing discrimination at the hands of others who reproduce racist, sexist, ableist, extremist or other harmful ideologies reinforced through interactions with synthetic language. We explore these potential harms in §6 and potential paths forward in §7. We hope that a critical overview of the risks of relying on ever-increasing size of LMs as the primary driver of increased performance of language technology can facilitate a reallocation of efforts towards approaches that avoid some of these risks while still reaping the benefits of improvements to language technology. BACKGROUND Similar to [14], we understand the term language model (LM) to refer to systems which are trained on string prediction tasks: that is, predicting the likelihood of a token (character, word or string) given either its preceding context or (in bidirectional and masked LMs) its surrounding context. Such systems are unsupervised and when deployed, take a text as input, commonly outputting scores or string predictions. Initially proposed by Shannon in 1949 [117], some of the earliest implemented LMs date to the early 1980s and were used as components in systems for automatic speech recognition (ASR), machine translation (MT), document classification, and more [111]. In this section, we provide a brief overview of the general trend of language modeling in recent years. For a more in-depth survey of pretrained LMs, see [105]. Before neural models, n-gram models also used large amounts of data [20, 87]. In addition to ASR, these large n-gram models of English were developed in the context of machine translation from another source language with far fewer direct translation examples. For example, [20] developed an n-gram model for English with a total of 1.8T n-grams and noted steady improvements in BLEU score on the test set of 1797 Arabic translations as the training data was increased from 13M tokens. The next big step was the move towards using pretrained representations of the distribution of words (called word embeddings) in other (supervised) NLP tasks. These word vectors came from systems such as word2vec [85] and GloVe [98] and later LSTM models such as context2vec [82] and ELMo [99] and supported state of the art performance on question answering, textual entailment, semantic role labeling (SRL), coreference resolution, named entity recognition (NER), and sentiment analysis, at first in English and later for other languages as well. While training the word embeddings required a (relatively) large amount of data, it reduced the amount of labeled data necessary for training on the various supervised tasks. For example, [99] showed that a model trained with ELMo reduced the necessary amount of training data needed to achieve similar results on SRL compared to models without, as shown in one instance where a model trained with ELMo reached the maximum development F1 score in 10 epochs as opposed to 486 without ELMo. This model furthermore achieved the same F1 score with 1% of the data as the baseline model achieved with 10% of the training data. Increasing the number of model parameters, however, did not yield noticeable increases for LSTMs [e.g. 82]. Transformer models, on the other hand, have been able to continuously benefit from larger architectures and larger quantities of data. Devlin et al. [39] in particular noted that training on a large dataset and fine-tuning for specific tasks leads to strictly increasing results on the GLUE tasks [138] for English as the hyperparameters of the model were increased. Initially developed as Chinese LMs, the ERNIE family [130, 131, 145] produced ERNIE-Gen, which was also trained on the original (English) BERT dataset, joining the ranks of very large LMs. NVIDIA released the MegatronLM which has 8.3B parameters and was trained on 174GB of text from the English Wikipedia, OpenWebText, RealNews and CC-Stories datasets [122]. Trained on the same dataset, Microsoft released T-NLG[^1], an LM with 17B parameters. OpenAI's GPT-3 [25] and Google's GShard [73] and Switch-C [43] have increased the definition of large LM by orders of magnitude in terms of parameters at 175B, 600B, and 1.6T parameters, respectively. Table 1 summarizes a selection of these LMs in terms of training data size and parameters. As increasingly large amounts of text are collected from the web in datasets such as the Colossal Clean Crawled Corpus [107] and the Pile [51], this trend of increasingly large LMs can be expected to continue as long as they correlate with an increase in performance. A number of these models also have multilingual variants such as mBERT [39] and mT5 [148] or are trained with some amount of multilingual data such as GPT-3 where 7% of the training data was not in English [25]. The performance of these multilingual models across languages is an active area of research. Wu and Drezde [144] found that while mBERT does not perform equally well across all 104 languages in its training data, it performed better at NER, POS tagging, and dependency parsing than monolingual models trained with comparable amounts of data for four low-resource languages. Conversely, [95] surveyed monolingual BERT models developed with more specific architecture considerations or additional monolingual data and found that they generally outperform mBERT across 29 tasks. Either way, these models do not address the inclusion problems raised by [65], who note that over 90% of the world's languages used by more than a billion people currently have little to no support in terms of language technology. Alongside work investigating what information the models retain from the data, we see a trend in reducing the size of these models using various techniques such as knowledge distillation [26, 58], quantization [118, 153], factorized embedding parameterization and cross-layer parameter sharing [70], and progressive module replacing [146]. Rogers et al. [110] provide a comprehensive comparison of models derived from BERT using these techniques, such as DistilBERT [113] and ALBERT [70]. While these models maintain and sometimes exceed the performance of the original BERT model, despite their much smaller size, they ultimately still rely on large quantities of data and significant processing and storage capabilities to both hold and reduce the model. We note that the change from n-gram LMs to word vectors distilled from neural LMs to pretrained Transformer LMs is paralleled by an expansion and change in the types of tasks they are useful for: n-gram LMs were initially typically deployed in selecting among the outputs of e.g. acoustical or translation models; the LSTM-derived word vectors were quickly picked up as more effective representations of words (in place of bag of words features) in a variety of NLP tasks involving labeling and classification; and the pretrained Transformer models can be retrained on very small datasets (few-shot, one-shot or even zero-shot learning) to perform apparently meaning-manipulating tasks such as summarization, question answering and the like. Nonetheless, all of these systems share the property of being LMs in the sense we give above, that is, systems trained to predict sequences of words (or characters or sentences). Where they differ is in the size of the training datasets they leverage and the spheres of influence they can possibly affect. By scaling up in these two ways, modern very large LMs incur new kinds of risk, which we turn to in the following sections. ENVIRONMENTAL AND FINANCIAL COST Strubell et al. recently benchmarked model training and development costs in terms of dollars and estimated CO₂ emissions [129]. While the average human is responsible for an estimated 5t CO₂e per year,[^2] the authors trained a Transformer (big) model [136] with neural architecture search and estimated that the training procedure emitted 284t of *CO₂*. Training a single BERT base model (without hyperparameter tuning) on GPUs was estimated to require as much energy as a trans-American flight. While some of this energy comes from renewable sources, or cloud compute companies' use of carbon credit-offset sources, the authors note that the majority of cloud compute providers' energy is not sourced from renewable sources and many energy sources in the world are not carbon neutral. In addition, renewable energy sources are still costly to the environment,[^3] and data centers with increasing computation requirements take away from other potential uses of green energy,[^4] underscoring the need for energy efficient model architectures and training paradigms. Strubell et al. also examine the cost of these models vs. their accuracy gains. For the task of machine translation where large LMs have resulted in performance gains, they estimate that an increase in 0.1 BLEU score using neural architecture search for English to German translation results in an increase of $150,000 compute cost in addition to the carbon emissions. To encourage more equitable access to NLP research and reduce carbon footprint, the authors give recommendations to report training time and sensitivity to hyperparameters when the released model is meant to be re-trained for downstream use. They also urge governments to invest in compute clouds to provide equitable access to researchers. Initiatives such as the SustainNLP workshop[^5] have since taken up the goal of prioritizing computationally efficient hardware and algorithms. Schwartz et al. [115] also call for the development of green AI, similar to other environmentally friendly scientific developments such as green chemistry or sustainable computing. As shown in [5], the amount of compute used to train the largest deep learning models (for NLP and other applications) has increased 300,000x in 6 years, increasing at a far higher pace than Moore's Law. To promote green AI, Schwartz et al. argue for promoting efficiency as an evaluation metric and show that most sampled papers from ACL 2018, NeurIPS 2018, and CVPR 2019 claim accuracy improvements alone as primary contributions to the field, and none focused on measures of efficiency as primary contributions. Since then, works such as [57, 75] have released online tools to help researchers benchmark their energy usage. Among their recommendations are to run experiments in carbon friendly regions, consistently report energy and carbon metrics, and consider energy-performance trade-offs before deploying energy hungry models. In addition to these calls for documentation and technical fixes, Bietti and Vatanparast underscore the need for social and political engagement in shaping a future where data driven systems have minimal negative impact on the environment [16]. While [129] benchmarks the training process in a research setting, many LMs are deployed in industrial or other settings where the cost of inference might greatly outweigh that of training in the long run. In this scenario, it may be more appropriate to deploy models with lower energy costs during inference even if their training costs are high. In addition to benchmarking tools, works estimating the cost increase associated with the introduction of LMs for particular applications, and how they compare to alternative NLP methods, will be important for understanding the trade-offs. When we perform risk/benefit analyses of language technology, we must keep in mind how the risks and benefits are distributed, because they do not accrue to the same people. On the one hand, it is well documented in the literature on environmental racism that the negative effects of climate change are reaching and impacting the world's most marginalized communities first [1, 27].[^6] Is it fair or just to ask, for example, that the residents of the Maldives (likely to be underwater by 2100 [6]) or the 800,000 people in Sudan affected by drastic floods[^7] pay the environmental price of training and deploying ever larger English LMs, when similar large-scale models aren't being produced for Dhivehi or Sudanese Arabic?[^8] And, while some language technology is genuinely designed to benefit marginalized communities [17, 101], most language technology is built to serve the needs of those who already have the most privilege in society. Consider, for example, who is likely to both have the financial resources to purchase a Google Home, Amazon Alexa or an Apple device with Siri installed and comfortably speak a variety of a language which they are prepared to handle. Furthermore, when large LMs encode and reinforce hegemonic biases (see §§4 and 6), the harms that follow are most likely to fall on marginalized populations who, even in rich nations, are most likely to experience environmental racism [10, 104]. These models are being developed at a time when unprecedented environmental changes are being witnessed around the world. From monsoons caused by changes in rainfall patterns due to climate change affecting more than 8 million people in India,[^9] to the worst fire season on record in Australia killing or displacing nearly three billion animals and at least 400 people,[^10] the effect of climate change continues to set new records every year. It is past time for researchers to prioritize energy efficiency and cost to reduce negative environmental impact and inequitable access to resources — both of which disproportionately affect people who are already in marginalized positions. UNFATHOMABLE TRAINING DATA The size of data available on the web has enabled deep learning models to achieve high accuracy on specific benchmarks in NLP and computer vision applications. However, in both application areas, the training data has been shown to have problematic characteristics [18, 38, 42, 47, 61] resulting in models that encode stereotypical and derogatory associations along gender, race, ethnicity, and disability status [11, 12, 69, 69, 132, 132, 157]. In this section, we discuss how large, uncurated, Internet-based datasets encode the dominant/hegemonic view, which further harms people at the margins, and recommend significant resource allocation towards dataset curation and documentation practices. Size Doesn't Guarantee Diversity The Internet is a large and diverse virtual space, and accordingly, it is easy to imagine that very large datasets, such as Common Crawl (\"petabytes of data collected over 8 years of web crawling\",[^11] a filtered version of which is included in the GPT-3 training data) must therefore be broadly representative of the ways in which different people view the world. However, on closer examination, we find that there are several factors which narrow Internet participation, the discussions which will be included via the crawling methodology, and finally the texts likely to be contained after the crawled data are filtered. In all cases, the voices of people most likely to hew to a hegemonic viewpoint are also more likely to be retained. In the case of US and UK English, this means that white supremacist and misogynistic, ageist, etc. views are overrepresented in the training data, not only exceeding their prevalence in the general population but also setting up models trained on these datasets to further amplify biases and harms. Starting with who is contributing to these Internet text collections, we see that Internet access itself is not evenly distributed, resulting in Internet data overrepresenting younger users and those from developed countries [100, 143].[^12] However, it's not just the Internet as a whole that is in question, but rather specific subsamples of it. For instance, GPT-2's training data is sourced by scraping outbound links from Reddit, and Pew Internet Research's 2016 survey reveals 67% of Reddit users in the United States are men, and 64% between ages 18 and 29.[^13] Similarly, recent surveys of Wikipedians find that only 8.8–15% are women or girls [9]. Furthermore, while user-generated content sites like Reddit, Twitter, and Wikipedia present themselves as open and accessible to anyone, there are structural factors including moderation practices which make them less welcoming to marginalized populations. Jones [64] documents (using digital ethnography techniques [63]) multiple cases where people on the receiving end of death threats on Twitter have had their accounts suspended while the accounts issuing the death threats persist. She further reports that harassment on Twitter is experienced by \"a wide range of overlapping groups including domestic abuse victims, sex workers, trans people, queer people, immigrants, medical patients (by their providers), neurodivergent people, and visibly or vocally disabled people.\" The net result is that a limited set of subpopulations can continue to easily add data, sharing their thoughts and developing platforms that are inclusive of their worldviews; this systemic pattern in turn worsens diversity and inclusion within Internet-based communication, creating a feedback loop that lessens the impact of data from underrepresented populations. Even if populations who feel unwelcome in mainstream sites set up different fora for communication, these may be less likely to be included in training data for language models. Take, for example, older adults in the US and UK. Lazar et al. outline how they both individually and collectively articulate anti-ageist frames specifically through blogging [71], which some older adults prefer over more popular social media sites for discussing sensitive topics [24]. These fora contain rich discussions about what constitutes age discrimination and the impacts thereof. However, a blogging community such as the one described by Lazar et al. is less likely to be found than other blogs that have more incoming and outgoing links. Finally, the current practice of filtering datasets can further attenuate the voices of people from marginalized identities. The training set for GPT-3 was a filtered version of the Common Crawl dataset, developed by training a classifier to pick out those documents most similar to the ones used in GPT-2's training data, i.e. documents linked to from Reddit [25], plus Wikipedia and a collection of books. While this was reportedly effective at filtering out documents that previous work characterized as \"unintelligible\" [134], what is unmeasured (and thus unknown) is what else it filtered out. The Colossal Clean Crawled Corpus [107], used to train a trillion parameter LM in [43], is cleaned, inter alia, by discarding any page containing one of a list of about 400 \"Dirty, Naughty, Obscene or Otherwise Bad Words\" [p.6].[^14] This list is overwhelmingly words related to sex, with a handful of racial slurs and words related to white supremacy (e.g. swastika, white power) included. While possibly effective at removing documents containing pornography (and the associated problematic stereotypes encoded in the language of such sites [125]) and certain kinds of hate speech, this approach will also undoubtedly attenuate, by suppressing such words as twink, the influence of online spaces built by and for LGBTQ people.[^15] If we filter out the discourse of marginalized populations, we fail to provide training data that reclaims slurs and otherwise describes marginalized identities in a positive light. Thus at each step, from initial participation in Internet fora, to continued presence there, to the collection and finally the filtering of training data, current practice privileges the hegemonic viewpoint. In accepting large amounts of web text as 'representative' of 'all' of humanity we risk perpetuating dominant viewpoints, increasing power imbalances, and further reifying inequality. We instead propose practices that actively seek to include communities underrepresented on the Internet. For instance, one can take inspiration from movements to decolonize education by moving towards oral histories due to the overrepresentation of colonial views in text [35, 76, 127], and curate training datasets through a thoughtful process of deciding what to put in, rather than aiming solely for scale and trying haphazardly to weed out, post-hoc, flotsam deemed 'dangerous', 'unintelligible', or 'otherwise bad'. Static Data/Changing Social Views A central aspect of social movement formation involves using language strategically to destabilize dominant narratives and call attention to underrepresented social perspectives. Social movements produce new norms, language, and ways of communicating. This adds challenges to the deployment of LMs, as methodologies reliant on LMs run the risk of 'value-lock', where the LM-reliant technology reifies older, less-inclusive understandings. For instance, the Black Lives Matter movement (BLM) influenced Wikipedia article generation and editing such that, as the BLM movement grew, articles covering shootings of Black people increased in coverage and were generated with reduced latency [135]. Importantly, articles describing past shootings and incidents of police brutality were created and updated as articles for new events were created, reflecting how social movements make connections between events in time to form cohesive narratives [102]. More generally, Twyman et al. [135] highlight how social movements actively influence framings and reframings of minority narratives in the type of online discourse that potentially forms the data that underpins LMs. An important caveat is that social movements which are poorly documented and which do not receive significant media attention will not be captured at all. Media coverage can fail to cover protest events and social movements [41, 96] and can distort events that challenge state power [36]. This is exemplified by media outlets that tend to ignore peaceful protest activity and instead focus on dramatic or violent events that make for good television but nearly always result in critical coverage [81]. As a result, the data underpinning LMs stands to misrepresent social movements and disproportionately align with existing regimes of power. Developing and shifting frames stand to be learned in incomplete ways or lost in the big-ness of data used to train large LMs — particularly if the training data isn't continually updated. Given the compute costs alone of training large LMs, it likely isn't feasible for even large corporations to fully retrain them frequently enough to keep up with the kind of language change discussed here. Perhaps fine-tuning approaches could be used to retrain LMs, but here again, what would be required is thoughtful curation practices to find appropriate data to capture reframings and techniques for evaluating whether such fine-tuning appropriately captures the ways in which new framings contest hegemonic representations. Encoding Bias It is well established by now that large LMs exhibit various kinds of bias, including stereotypical associations [11, 12, 69, 119, 156, 157], or negative sentiment towards specific groups [61]. Furthermore, we see the effects of intersectionality [34], where BERT, ELMo, GPT and GPT-2 encode more bias against identities marginalized along more than one dimension than would be expected based on just the combination of the bias along each of the axes [54, 132]. Many of these works conclude that these issues are a reflection of training data characteristics. For instance, Hutchinson et al. find that BERT associates phrases referencing persons with disabilities with more negative sentiment words, and that gun violence, homelessness, and drug addiction are overrepresented in texts discussing mental illness [61]. Similarly, Gehman et al. show that models like GPT-3 trained with at least 570GB of data derived mostly from Common Crawl[^16] can generate sentences with high toxicity scores even when prompted with non-toxic sentences [53]. Their investigation of GPT-2's training data[^17] also finds 272K documents from unreliable news sites and 63K from banned subreddits. These demonstrations of biases learned by LMs are extremely valuable in pointing out the potential for harm when such models are deployed, either in generating text or as components of classification systems, as explored further in §6. However, they do not represent a methodology that can be used to exhaustively discover all such risks, for several reasons. First, model auditing techniques typically rely on automated systems for measuring sentiment, toxicity, or novel metrics such as 'regard' to measure attitudes towards a specific demographic group [119]. But these systems themselves may not be reliable means of measuring the toxicity of text generated by LMs. For example, the Perspective API model has been found to associate higher levels of toxicity with sentences containing identity markers for marginalized groups or even specific names [61, 103]. Second, auditing an LM for biases requires an a priori understanding of what social categories might be salient. The works cited above generally start from US protected attributes such as race and gender (as understood within the US). But, of course, protected attributes aren't the only identity characteristics that can be subject to bias or discrimination, and the salient identity characteristics and expressions of bias are also culture-bound [46, 116]. Thus, components like toxicity classifiers would need culturally appropriate training data for each context of audit, and even still we may miss marginalized identities if we don't know what to audit for. Finally, we note that moving beyond demonstrating the existence of bias to building systems that verify the 'safety' of some LM (even for a given protected class) requires engaging with the systems of power that lead to the harmful outcomes such a system would seek to prevent [19]. For example, the #MeToo movement has spurred broad-reaching conversations about inappropriate sexual behavior from men in power, as well as men more generally [84]. These conversations challenge behaviors that have been historically considered appropriate or even the fault of women, shifting notions of sexually inappropriate behavior. Any product development that involves operationalizing definitions around such shifting topics into algorithms is necessarily political (whether or not developers choose the path of maintaining the status quo ante). For example, men and women make significantly different assessments of sexual harassment online [40]. An algorithmic definition of what constitutes inappropriately sexual communication will inherently be concordant with some views and discordant with others. Thus, an attempt to measure the appropriateness of text generated by LMs, or the biases encoded by a system, always needs to be done in relation to particular social contexts and marginalized perspectives [19]. Curation, Documentation & Accountability In summary, LMs trained on large, uncurated, static datasets from the Web encode hegemonic views that are harmful to marginalized populations. We thus emphasize the need to invest significant resources into curating and documenting LM training data. In this, we follow Jo et al. [62], who cite archival history data collection methods as an example of the amount of resources that should be dedicated to this process, and Birhane and Prabhu [18], who call for a more justice-oriented data collection methodology. Birhane and Prabhu note, echoing Ruha Benjamin [15], \"Feeding AI systems on the world's beauty, ugliness, and cruelty, but expecting it to reflect only the beauty is a fantasy.\" [p.1541] When we rely on ever larger datasets we risk incurring documentation debt,[^18] i.e. putting ourselves in a situation where the datasets are both undocumented and too large to document post hoc. While documentation allows for potential accountability [13, 52, 86], undocumented training data perpetuates harm without recourse. Without documentation, one cannot try to understand training data characteristics in order to mitigate some of these attested issues or even unknown ones. The solution, we propose, is to budget for documentation as part of the planned costs of dataset creation, and only collect as much data as can be thoroughly documented within that budget. DOWN THE GARDEN PATH In §4 above, we discussed the ways in which different types of biases can be encoded in the corpora used to train large LMs. In §6 below we explore some of the risks and harms that can follow from deploying technology that has learned those biases. In the present section, however, we focus on a different kind of risk: that of misdirected research effort, specifically around the application of LMs to tasks intended to test for natural language understanding (NLU). As the very large Transformer LMs posted striking gains in the state of the art on various benchmarks intended to model meaning-sensitive tasks, and as initiatives like [142] made the models broadly accessible to researchers seeking to apply them, large quantities of research effort turned towards measuring how well BERT and its kin do on both existing and new benchmarks.[^19] This allocation of research effort brings with it an opportunity cost, on the one hand in terms of time not spent applying meaning capturing approaches to meaning sensitive tasks, and on the other hand in terms of time not spent exploring more effective ways of building technology with datasets of a size that can be carefully curated and available for a broader set of languages [65, 91]. The original BERT paper [39] showed the effectiveness of the architecture and the pretraining technique by evaluating on the General Language Understanding Evaluation (GLUE) benchmark [138], the Stanford Question Answering Datasets (SQuAD 1.1 and 2.0) [108], and the Situations With Adversarial Generations benchmark (SWAG) [155], all datasets designed to test language understanding and/or commonsense reasoning. BERT posted state of the art results on all of these tasks, and the authors conclude by saying that \"unsupervised pre-training is an integral part of many language understanding systems.\" [39, p.4179]. Even before [39] was published, BERT was picked up by the NLP community and applied with great success to a wide variety of tasks [e.g. 2, 149]. However, no actual language understanding is taking place in LM-driven approaches to these tasks, as can be shown by careful manipulation of the test data to remove spurious cues the systems are leveraging [21, 93]. Furthermore, as Bender and Koller [14] argue from a theoretical perspective, languages are systems of signs [37], i.e. pairings of form and meaning. But the training data for LMs is only form; they do not have access to meaning. Therefore, claims about model abilities must be carefully characterized. As the late Karen Spärck Jones pointed out: the use of LMs ties us to certain (usually unstated) epistemological and methodological commitments [124]. Either i) we commit ourselves to a noisy-channel interpretation of the task (which rarely makes sense outside of ASR), ii) we abandon any goals of theoretical insight into tasks and treat LMs as \"just some convenient technology\" [p.7], or iii) we implicitly assume a certain statistical relationship — known to be invalid — between inputs, outputs and meanings.[^20] Although she primarily had n-gram models in mind, the conclusions remain apt and relevant. There are interesting linguistic questions to ask about what exactly BERT, GPT-3 and their kin are learning about linguistic structure from the unsupervised language modeling task, as studied in the emerging field of 'BERTology' [e.g. 110, 133]. However, from the perspective of work on language technology, it is far from clear that all of the effort being put into using large LMs to 'beat' tasks designed to test natural language understanding, and all of the effort to create new such tasks, once the existing ones have been bulldozed by the LMs, brings us any closer to long-term goals of general language understanding systems. If a large LM, endowed with hundreds of billions of parameters and trained on a very large dataset, can manipulate linguistic form well enough to cheat its way through tests meant to require language understanding, have we learned anything of value about how to build machine language understanding or have we been led down the garden path? STOCHASTIC PARROTS In this section, we explore the ways in which the factors laid out in §4 and §5 — the tendency of training data ingested from the Internet to encode hegemonic worldviews, the tendency of LMs to amplify biases and other issues in the training data, and the tendency of researchers and other people to mistake LM-driven performance gains for actual natural language understanding — present real-world risks of harm, as these technologies are deployed. After exploring some reasons why humans mistake LM output for meaningful text, we turn to the risks and harms from deploying such a model at scale. We find that the mix of human biases and seemingly coherent language heightens the potential for automation bias, deliberate misuse, and amplification of a hegemonic worldview. We focus primarily on cases where LMs are used in generating text, but we will also touch on risks that arise when LMs or word embeddings derived from them are components of systems for classification, query expansion, or other tasks, or when users can query LMs for information memorized from their training data. Coherence in the Eye of the Beholder Where traditional n-gram LMs [117] can only model relatively local dependencies, predicting each word given the preceding sequence of N words (usually 5 or fewer), the Transformer LMs capture much larger windows and can produce text that is seemingly not only fluent but also coherent even over paragraphs. For example, McGuffie and Newhouse [80] prompted GPT-3 with the text in bold in Figure 1, and it produced the rest of the text, including the Q&A format.[^21] This example illustrates GPT-3's ability to produce coherent and on-topic text; the topic is connected to McGuffie and Newhouse's study of GPT-3 in the context of extremism, discussed below. We say seemingly coherent because coherence is in fact in the eye of the beholder. Our human understanding of coherence derives from our ability to recognize interlocutors' beliefs [30, 31] and intentions [23, 33] within context [32]. That is, human language use takes place between individuals who share common ground and are mutually aware of that sharing (and its extent), who have communicative intents which they use language to convey, and who model each others' mental states as they communicate. As such, human communication relies on the interpretation of implicit meaning conveyed between individuals. The fact that human-human communication is a jointly constructed activity [29, 128] is most clearly true in co-situated spoken or signed communication, but we use the same facilities for producing language that is intended for audiences not co-present with us (readers, listeners, watchers at a distance in time or space) and in interpreting such language when we encounter it. It must follow that even when we don't know the person who generated the language we are interpreting, we build a partial model of who they are and what common ground we think they share with us, and use this in interpreting their words. Text generated by an LM is not grounded in communicative intent, any model of the world, or any model of the reader's state of mind. It can't have been, because the training data never included sharing thoughts with a listener, nor does the machine have the ability to do that. This can seem counter-intuitive given the increasingly fluent qualities of automatically generated text, but we have to account for the fact that our perception of natural language text, regardless of how it was generated, is mediated by our own linguistic competence and our predisposition to interpret communicative acts as conveying coherent meaning and intent, whether or not they do [89, 140]. The problem is, if one side of the communication does not have meaning, then the comprehension of the implicit meaning is an illusion arising from our singular human understanding of language (independent of the model).[^22] Contrary to how it may seem when we observe its output, an LM is a system for haphazardly stitching together sequences of linguistic forms it has observed in its vast training data, according to probabilistic information about how they combine, but without any reference to meaning: a stochastic parrot. Risks and Harms The ersatz fluency and coherence of LMs raises several risks, precisely because humans are prepared to interpret strings belonging to languages they speak as meaningful and corresponding to the communicative intent of some individual or group of individuals who have accountability for what is said. We now turn to examples, laying out the potential follow-on harms. The first risks we consider are the risks that follow from the LMs absorbing the hegemonic worldview from their training data. When humans produce language, our utterances reflect our worldviews, including our biases [78, 79]. As people in positions of privilege with respect to a society's racism, misogyny, ableism, etc., tend to be overrepresented in training data for LMs (as discussed in §4 above), this training data thus includes encoded biases, many already recognized as harmful. Biases can be encoded in ways that form a continuum from subtle patterns like referring to women doctors as if doctor itself entails not-woman or referring to both genders excluding the possibility of non-binary gender identities, through directly contested framings (e.g. undocumented immigrants vs. illegal immigrants or illegals), to language that is widely recognized to be derogatory (e.g. racial slurs) yet still used by some. While some of the most overtly derogatory words could be filtered out, not all forms of online abuse are easily detectable using such taboo words, as evidenced by the growing body of research on online abuse detection [45, 109]. Furthermore, in addition to abusive language [139] and hate speech [67], there are subtler forms of negativity such as gender bias [137], microaggressions [22], dehumanization [83], and various socio-political framing biases [44, 114] that are prevalent in language data. For example, describing a woman's account of her experience of sexism with the word tantrum both reflects a worldview where the sexist actions are normative and foregrounds a stereotype of women as childish and not in control of their emotions. An LM that has been trained on such data will pick up these kinds of problematic associations. If such an LM produces text that is put into the world for people to interpret (flagged as produced by an 'AI' or otherwise), what risks follow? In the first instance, we foresee that LMs producing text will reproduce and even amplify the biases in their input [53]. Thus the risk is that people disseminate text generated by LMs, meaning more text in the world that reinforces and propagates stereotypes and problematic associations, both to humans who encounter the text and to future LMs trained on training sets that ingested the previous generation LM's output. Humans who encounter this text may themselves be subjects of those stereotypes and associations or not. Either way, harms ensue: readers subject to the stereotypes may experience the psychological harms of microaggressions [88, 141] and stereotype threat [97, 126]. Other readers may be introduced to stereotypes or have ones they already carry reinforced, leading them to engage in discrimination (consciously or not) [55], which in turn leads to harms of subjugation, denigration, belittlement, loss of opportunity [3, 4, 56] and others on the part of those discriminated against. If the LM outputs overtly abusive language (as Gehman et al. [53] show that they can and do), then a similar set of risks arises. These include: propagating or proliferating overtly abusive views and associations, amplifying abusive language, and producing more (synthetic) abusive language that may be included in the next iteration of large-scale training data collection. The harms that could follow from these risks are again similar to those identified above for more subtly biased language, but perhaps more acute to the extent that the language in question is overtly violent or defamatory. They include the psychological harm experienced by those who identify with the categories being denigrated if they encounter the text; the reinforcement of sexist, racist, ableist, etc. ideology; follow-on effects of such reinforced ideologies (including violence); and harms to the reputation of any individual or organization perceived to be the source of the text. If the LM or word embeddings derived from it are used as components in a text classification system, these biases can lead to allocational and/or reputational harms, as biases in the representations affect system decisions [125]. This case is especially pernicious for being largely invisible to both the direct user of the system and any indirect stakeholders about whom decisions are being made. Similarly, biases in an LM used in query expansion could influence search results, further exacerbating the risk of harms of the type documented by Noble in [94], where the juxtaposition of search queries and search results, when connected by negative stereotypes, reinforce those stereotypes and cause psychological harm. The above cases involve risks that could arise when LMs are deployed without malicious intent. A third category of risk involves bad actors taking advantage of the ability of large LMs to produce large quantities of seemingly coherent texts on specific topics on demand in cases where those deploying the LM have no investment in the truth of the generated text. These include prosaic cases, such as services set up to 'automatically' write term papers or interact on social media,[^23] as well as use cases connected to promoting extremism. For example, McGuffie and Newhouse [80] show how GPT-3 could be used to generate text in the persona of a conspiracy theorist, which in turn could be used to populate extremist recruitment message boards. This would give such groups a cheap way to boost recruitment by making human targets feel like they were among many like-minded people. If the LMs are deployed in this way to recruit more people to extremist causes, then harms, in the first instance, befall the people so recruited and (likely more severely) to others as a result of violence carried out by the extremists. Yet another risk connected to seeming coherence and fluency involves machine translation (MT) and the way that increased fluency of MT output changes the perceived adequacy of that output [77]. This differs somewhat from the cases above in that there was an initial human communicative intent, by the author of the source language text. However, MT systems can (and frequently do) produce output that is inaccurate yet both fluent and (again, seemingly) coherent in its own right to a consumer who either doesn't see the source text or cannot understand the source text on their own. When such consumers therefore mistake the meaning attributed to the MT output as the actual communicative intent of the original text's author, real-world harm can ensue. A case in point is the story of a Palestinian man, arrested by Israeli police, after MT translated his Facebook post which said \"good morning\" (in Arabic) to \"hurt them\" (in English) and \"attack them\" (in Hebrew).[^24] This case involves a short phrase, but it is easy to imagine how the ability of large LMs to produce seemingly coherent text over larger passages could erase cues that might tip users off to translation errors in longer passages as well [77]. Finally, we note that there are risks associated with the fact that LMs with extremely large numbers of parameters model their training data very closely and can be prompted to output specific information from that training data. For example, [28] demonstrate a methodology for extracting personally identifiable information (PII) from an LM and find that larger LMs are more susceptible to this style of attack than smaller ones. Building training data out of publicly available documents doesn't fully mitigate this risk: just because the PII was already available in the open on the Internet doesn't mean there isn't additional harm in collecting it and providing another avenue to its discovery. This type of risk differs from those noted above because it doesn't hinge on seeming coherence of synthetic text, but the possibility of a sufficiently motivated user gaining access to training data via the LM. In a similar vein, users might query LMs for 'dangerous knowledge' (e.g. tax avoidance advice), knowing that what they were getting was synthetic and therefore not credible but nonetheless representing clues to what is in the training data in order to refine their own search queries. Summary In this section, we have discussed how the human tendency to attribute meaning to text, in combination with large LMs' ability to learn patterns of forms that humans associate with various biases and other harmful attitudes, leads to risks of real-world harm, should LM-generated text be disseminated. We have also reviewed risks connected to using LMs as components in classification systems and the risks of LMs memorizing training data. We note that the risks associated with synthetic but seemingly coherent text are deeply connected to the fact that such synthetic text can enter into conversations without any person or entity being accountable for it. This accountability both involves responsibility for truthfulness and is important in situating meaning. As Maggie Nelson [92] writes: \"Words change depending on who speaks them; there is no cure.\" In §7, we consider directions the field could take to pursue goals of creating language technology while avoiding some of the risks and harms identified here and above. PATHS FORWARD In order to mitigate the risks that come with the creation of increasingly large LMs, we urge researchers to shift to a mindset of careful planning, along many dimensions, before starting to build either datasets or systems trained on datasets. We should consider our research time and effort a valuable resource, to be spent to the extent possible on research projects that build towards a technological ecosystem whose benefits are at least evenly distributed or better accrue to those historically most marginalized. This means considering how research contributions shape the overall direction of the field and keeping alert to directions that limit access. Likewise, it means considering the financial and environmental costs of model development up front, before deciding on a course of investigation. The resources needed to train and tune state-of-the-art models stand to increase economic inequities unless researchers incorporate energy and compute efficiency in their model evaluations. Furthermore, the goals of energy and compute efficient model building and of creating datasets and models where the incorporated biases can be understood both point to careful curation of data. Significant time should be spent on assembling datasets suited for the tasks at hand rather than ingesting massive amounts of data from convenient or easily-scraped Internet sources. As discussed in §4.1, simply turning to massive dataset size as a strategy for being inclusive of diverse viewpoints is doomed to failure. We recall again Birhane and Prabhu's [18] words (inspired by Ruha Benjamin [15]): \"Feeding AI systems on the world's beauty, ugliness, and cruelty, but expecting it to reflect only the beauty is a fantasy.\" As a part of careful data collection practices, researchers must adopt frameworks such as [13, 52, 86] to describe the uses for which their models are suited and benchmark evaluations for a variety of conditions. This involves providing thorough documentation on the data used in model building, including the motivations underlying data selection and collection processes. This documentation should reflect and indicate researchers' goals, values, and motivations in assembling data and creating a given model. It should also make note of potential users and stakeholders, particularly those that stand to be negatively impacted by model errors or misuse. We note that just because a model might have many different applications doesn't mean that its developers don't need to consider stakeholders. An exploration of stakeholders for likely use cases can still be informative around potential risks, even when there is no way to guarantee that all use cases can be explored. We also advocate for a re-alignment of research goals: Where much effort has been allocated to making models (and their training data) bigger and to achieving ever higher scores on leaderboards often featuring artificial tasks, we believe there is more to be gained by focusing on understanding how machines are achieving the tasks in question and how they will form part of socio-technical systems. To that end, LM development may benefit from guided evaluation exercises such as pre-mortems [68]. Frequently used in business settings before the deployment of new products or projects, pre-mortem analyses center hypothetical failures and ask team members to reverse engineer previously unanticipated causes.[^25] Critically, pre-mortem analyses prompt team members to consider not only a range of potential known and unknown project risks, but also alternatives to current project plans. In this way, researchers can consider the risks and limitations of their LMs in a guided way while also considering fixes to current designs or alternative methods of achieving a task-oriented goal in relation to specific pitfalls. Value sensitive design [49, 50] provides a range of methodologies for identifying stakeholders (both direct stakeholders who will use a technology and indirect stakeholders who will be affected through others' use of it), working with them to identify their values, and designing systems that support those values. These include such techniques as envisioning cards [48], the development of value scenarios [90], and working with panels of experiential experts [152]. These approaches help surface not only stakeholder values, but also values expressed by systems and enacted through interactions between systems and society [120]. For researchers working with LMs, value sensitive design is poised to help throughout the development process in identifying whose values are expressed and supported through a technology and, subsequently, how a lack of support might result in harm. All of these approaches take time and are most valuable when applied early in the development process as part of a conceptual investigation of values and harms rather than as a post-hoc discovery of risks [72]. These conceptual investigations should come before researchers become deeply committed to their ideas and therefore less likely to change course when confronted with evidence of possible harms. This brings us again to the idea we began this section with: that research and development of language technology, at once concerned with deeply human data (language) and creating systems which humans interact with in immediate and vivid ways, should be done with forethought and care. Finally, we would like to consider use cases of large LMs that have specifically served marginalized populations. If, as we advocate, the field backs off from the path of ever larger LMs, are we thus sacrificing benefits that would accrue to these populations? As a case in point, consider automatic speech recognition, which has seen some improvements thanks to advances in LMs, including both in size and in architecture [e.g. 8, 59, 121], though the largest LMs typically are too large and too slow for the near real-time needs of ASR systems [60]. Improved ASR has many beneficial applications, including automatic captioning which has the potential to be beneficial for Deaf and hard of hearing people, providing access to otherwise inaccessible audio content.[^26] We see two beneficial paths forward here: The first is a broader search for means of improving ASR systems, as indeed is underway, since the contexts of application of the technology aren't conducive to using ever larger LMs [60]. But even if larger LMs could be used, just because we've seen that large LMs can help doesn't mean that this is the only effective path to stronger ASR technology. (And we note that if we want to build strong ASR technology across most of the world's languages, we can't rely on having terabytes of data in all cases.) The second, should we determine that large LMs are critical (when available), is to recognize this as an instance of a dual use problem and consider how to mitigate the harms of LMs used as stochastic parrots while still preserving them for use in ASR systems. Could LMs be built in such a way that synthetic text generated with them would be watermarked and thus detectable [7, 66, 123]? Are there policy approaches that could effectively regulate their use? In summary, we advocate for research that centers the people who stand to be adversely affected by the resulting technology, with a broad view on the possible ways that technology can affect people. This, in turn, means making time in the research process for considering environmental impacts, for doing careful data curation and documentation, for engaging with stakeholders early in the design process, for exploring multiple possible paths towards long-term goals, for keeping alert to dual-use scenarios, and finally for allocating research effort to harm mitigation in such cases. CONCLUSION The past few years, ever since processing capacity caught up with neural models, have been heady times in the world of NLP. Neural approaches in general, and large, Transformer LMs in particular, have rapidly overtaken the leaderboards on a wide variety of benchmarks and once again the adage \"there's no data like more data\" seems to be true. It may seem like progress in the field, in fact, depends on the creation of ever larger language models (and research into how to deploy them to various ends). In this paper, we have invited readers to take a step back and ask: Are ever larger LMs inevitable or necessary? What costs are associated with this research direction and what should we consider before pursuing it? Do the field of NLP or the public that it serves in fact need larger LMs? If so, how can we pursue this research direction while mitigating its associated risks? If not, what do we need instead? We have identified a wide variety of costs and risks associated with the rush for ever larger LMs, including: environmental costs (borne typically by those not benefiting from the resulting technology); financial costs, which in turn erect barriers to entry, limiting who can contribute to this research area and which languages can benefit from the most advanced techniques; opportunity cost, as researchers pour effort away from directions requiring less resources; and the risk of substantial harms, including stereotyping, denigration, increases in extremist ideology, and wrongful arrest, should humans encounter seemingly coherent LM output and take it for the words of some person or organization who has accountability for what is said. Thus, we call on NLP researchers to carefully weigh these risks while pursuing this research direction, consider whether the benefits outweigh the risks, and investigate dual use scenarios utilizing the many techniques (e.g. those from value sensitive design) that have been put forth. We hope these considerations encourage NLP researchers to direct resources and effort into techniques for approaching NLP tasks that are effective without being endlessly data hungry. But beyond that, we call on the field to recognize that applications that aim to believably mimic humans bring risk of extreme harms. Work on synthetic human behavior is a bright line in ethical AI development, where downstream effects need to be understood and modeled in order to block foreseeable harm to society and different social groups. Thus what is also needed is scholarship on the benefits, harms, and risks of mimicking humans and thoughtful design of target tasks grounded in use cases sufficiently concrete to allow collaborative design with affected communities.",
      "word_count": 9527,
      "character_count": 61073,
      "vector": [
        0.14019155502319336,
        -0.17752671241760254,
        0.035182610154151917,
        -0.014379183761775494,
        0.02894812636077404,
        -0.050537001341581345,
        -0.1204325258731842,
        0.008981485851109028,
        -0.04192870855331421,
        0.017852971330285072,
        -0.07526284456253052,
        0.14095193147659302,
        -0.02112213708460331,
        -0.06101805344223976,
        0.07223404198884964,
        0.045614104717969894,
        -0.10062792897224426,
        -0.0010607532458379865,
        -0.11577338725328445,
        -0.04510040208697319,
        -0.016915351152420044,
        -0.013234789483249187,
        0.07733124494552612,
        0.06467174738645554,
        -0.0015862735453993082,
        0.020300032570958138,
        -0.1242515817284584,
        -0.07884468138217926,
        -0.07280151546001434,
        0.03728409484028816,
        0.11436685174703598,
        -0.04168780893087387,
        0.04321683198213577,
        -0.10220164060592651,
        0.009719066321849823,
        -0.04473790153861046,
        0.09680240601301193,
        -0.0010902779176831245,
        -0.046435944736003876,
        -0.02773120068013668,
        0.00903065875172615,
        0.02790304273366928,
        0.014882594347000122,
        -0.031228570267558098,
        0.10295432060956955,
        0.05889697000384331,
        0.05495348945260048,
        -0.015023219399154186,
        0.018627719953656197,
        0.04577038809657097,
        0.0027835967484861612,
        0.08291549235582352,
        -0.024709878489375114,
        0.013251081109046936,
        -0.015928931534290314,
        0.008725302293896675,
        0.0479201078414917,
        0.003345007309690118,
        -0.0008445369312539697,
        -0.0018610648112371564,
        -0.07456719130277634,
        0.05192680284380913,
        0.03074050135910511,
        -0.003603587858378887,
        -0.01967020146548748,
        0.0486614964902401,
        -0.01140583772212267,
        -0.08407708257436752,
        0.007889466360211372,
        -0.01583496481180191,
        -0.04652978107333183,
        -0.009052911773324013,
        0.03990565612912178,
        0.08455928415060043,
        -0.05545312538743019,
        0.016025027260184288,
        -0.007229074835777283,
        0.002208639867603779,
        0.02905787155032158,
        0.0013477378524839878,
        0.13218915462493896,
        0.016830017790198326,
        0.03117944672703743,
        -0.03342823311686516,
        0.050671178847551346,
        0.07082720845937729,
        -0.01280014868825674,
        -0.021146420389413834,
        0.0301672276109457,
        0.03865332156419754,
        0.03993119299411774,
        -0.06517638266086578,
        -0.08215105533599854,
        -0.060853708535432816,
        0.03630344942212105,
        0.01587909460067749,
        -0.03576132282614708,
        0.041869234293699265,
        0.004268919117748737,
        0.004949714057147503,
        0.02164630964398384,
        0.0298900306224823,
        -0.11503618955612183,
        0.052309226244688034,
        -0.01773708686232567,
        0.025095539167523384,
        -0.007363712415099144,
        0.013607333414256573,
        -0.057004038244485855,
        -0.023784223943948746,
        -0.06668173521757126,
        0.04688500985503197,
        -0.017156915739178658,
        -0.024012502282857895,
        -0.027050882577896118,
        0.04012281820178032,
        0.016273248940706253,
        0.027147909626364708,
        0.04917161911725998,
        -0.03323588892817497,
        -0.02709704451262951,
        0.0003308771119918674,
        -0.008368365466594696,
        0.03634463623166084,
        0.020442619919776917,
        0.0014392974553629756,
        -0.04681648686528206,
        -0.04204725846648216,
        0.0021321282256394625,
        -0.06772222369909286,
        -0.012766679748892784,
        0.04319601505994797,
        -0.025385206565260887,
        0.023044602945446968,
        -0.021768389269709587,
        -0.007513334043323994,
        0.043279096484184265,
        -0.01062677800655365,
        -0.035226501524448395,
        0.01632104441523552,
        -0.030866926535964012,
        0.05944499000906944,
        0.013698718510568142,
        -0.018464820459485054,
        -0.0544024296104908,
        -0.053022656589746475,
        0.006606478244066238,
        -0.05507360398769379,
        0.009917140938341618,
        -0.03976570814847946,
        0.022274000570178032,
        -0.008417323231697083,
        -0.004359268583357334,
        0.06436620652675629,
        -0.03953516483306885,
        -0.018466966226696968,
        -0.03252546861767769,
        0.00872375350445509,
        -0.009144721552729607,
        0.020997343584895134,
        0.0017823277739807963,
        0.008337123319506645,
        0.02271595411002636,
        0.00939736608415842,
        -0.026982858777046204,
        0.04603380709886551,
        -0.07534710317850113,
        0.014796058647334576,
        0.04838069528341293,
        0.0033254255540668964,
        -0.02248246595263481,
        -0.0022948437836021185,
        0.040106937289237976,
        -0.040383726358413696,
        0.006592271849513054,
        -0.02734232507646084,
        -0.030722206458449364,
        0.04176308959722519,
        0.0030841913539916277,
        0.06376943737268448,
        0.002075304975733161,
        0.01622849516570568,
        -0.04246019199490547,
        -0.004374807700514793,
        -0.030070612207055092,
        0.002573630539700389,
        0.015433249995112419,
        0.010015521198511124,
        -0.0059935045428574085,
        -0.00903091486543417,
        0.02089395932853222,
        0.017709996551275253,
        0.06601256877183914,
        0.041885532438755035,
        0.01701894775032997,
        -0.015074233524501324,
        -0.05234429985284805,
        0.03548490256071091,
        -0.0032138729002326727,
        -0.011839107610285282,
        -0.02596776932477951,
        -0.05027826502919197,
        -0.006279679946601391,
        -0.01255282573401928,
        0.00972792785614729,
        0.023268848657608032,
        -0.035857826471328735,
        -0.04121856018900871,
        -0.002710773143917322,
        0.039949458092451096,
        -0.03246919438242912,
        0.041803739964962006,
        0.037663016468286514,
        0.04134299233555794,
        -0.05691656842827797,
        -0.0075932275503873825,
        0.03653138130903244,
        0.053157322108745575,
        0.06982707977294922,
        -0.0022759519051760435,
        0.03203568607568741,
        -0.0064448220655322075,
        0.04171771556138992,
        -0.002713166642934084,
        0.034443508833646774,
        -0.016530869528651237,
        0.023636814206838608,
        0.055877767503261566,
        0.003553482936695218,
        0.00689678406342864,
        0.024629930034279823,
        0.01134468987584114,
        0.003028620034456253,
        0.013563505373895168,
        -0.019372111186385155,
        -0.024526407942175865,
        -0.041629984974861145,
        0.020039524883031845,
        0.06346777081489563,
        -0.026573581621050835,
        -0.0036759693175554276,
        0.005655529908835888,
        -0.03088429756462574,
        0.04537178948521614,
        -0.07558757066726685,
        0.01667012833058834,
        -0.007703335955739021,
        -0.04127398133277893,
        0.02766735665500164,
        -0.010347581468522549,
        0.01345225889235735,
        -0.05977137014269829,
        -0.079944908618927,
        -0.01802271232008934,
        0.01626446843147278,
        -0.03478235378861427,
        0.024697082117199898,
        -0.027078643441200256,
        -0.03570383042097092,
        -0.007692948915064335,
        -0.018122274428606033,
        0.004561799578368664,
        -0.005198845639824867,
        -0.006087256595492363,
        -0.02102569490671158,
        0.012734881602227688,
        -0.015267913229763508,
        -0.0025404994376003742,
        -0.01730763539671898,
        -0.09375321120023727,
        -0.016049236059188843,
        -0.0638376772403717,
        -0.018507210537791252,
        0.0406888984143734,
        0.023411093279719353,
        0.03629960119724274,
        -0.04395667836070061,
        0.0217390488833189,
        0.003770350944250822,
        -0.02279544621706009,
        -0.09121466428041458,
        0.00718480721116066,
        0.020700762048363686,
        -0.008029190823435783,
        -0.021240180358290672,
        -0.01524402480572462,
        -0.0002604105102363974,
        0.0321219228208065,
        -0.01428030151873827,
        -0.009765161201357841,
        -0.003595958463847637,
        -0.011737456545233727,
        -0.014200634323060513,
        0.001414027763530612,
        -0.021337119862437248,
        0.034448616206645966,
        -0.05884438380599022,
        0.0016676194500178099,
        0.07764528691768646,
        0.036645904183387756,
        -0.03399570286273956,
        0.02373434789478779,
        0.03546188771724701,
        0.039598822593688965,
        0.016220631077885628,
        -0.009973686188459396,
        -0.026112167164683342,
        -0.01040310226380825,
        -0.03128454461693764,
        0.008323720656335354,
        -0.01831348054111004,
        -0.0332811214029789,
        -0.023379793390631676,
        0.008527437224984169,
        -0.018388692289590836,
        0.017719928175210953,
        -0.0024842643178999424,
        0.033441998064517975,
        0.001206530025228858,
        -0.02763805352151394,
        0.025681648403406143,
        -0.0008007227443158627,
        0.024123847484588623,
        0.010253422893583775,
        -0.021959174424409866,
        -0.06372106820344925,
        0.02053559198975563,
        -0.00785586703568697,
        -0.0024515290278941393,
        -0.005287411622703075,
        -0.018261615186929703,
        0.010611995123326778,
        0.034138694405555725,
        0.03443038836121559,
        0.011944420635700226,
        -0.01775977946817875,
        -0.06530988216400146,
        0.00415116036310792,
        0.04510369524359703,
        0.012441267259418964,
        0.024847213178873062,
        -0.00041128078009933233,
        0.03638201951980591,
        -0.05195808783173561,
        -0.004757788497954607,
        0.06008387729525566,
        0.020536912605166435,
        -0.03365885466337204,
        0.01740817353129387,
        0.04819294810295105,
        0.01432886254042387,
        0.0035018064081668854,
        -0.01044903602451086,
        0.0020963321439921856,
        -0.012245120480656624,
        0.02113805152475834,
        -0.02569652535021305,
        0.002269543008878827,
        0.02129092812538147,
        -0.03270983323454857,
        -0.0037770848721265793,
        0.000852975354064256,
        -0.026643181219697,
        0.0694056823849678,
        -0.02756921760737896,
        0.019224420189857483,
        0.022800521925091743,
        0.013038556091487408,
        -7.86289238021709e-05,
        0.01556308288127184,
        -0.018614955246448517,
        -0.003963470458984375,
        0.025039182975888252,
        0.015803774818778038,
        -0.0063503095880150795,
        0.006571716628968716,
        0.04203221574425697,
        -0.011846099980175495,
        0.06906444579362869,
        0.014011375606060028,
        -0.003963066730648279,
        -0.02290649525821209,
        0.03894184157252312,
        0.006657766178250313,
        0.04780445247888565,
        -0.0020649335347115993,
        0.07983890175819397,
        -0.044081911444664,
        -0.024532107636332512,
        0.0013904618099331856,
        -0.01867205649614334,
        0.018111295998096466,
        0.04691333323717117,
        0.009788352996110916,
        -0.04749445989727974,
        -0.005869191139936447,
        0.03315166383981705,
        0.0014076834777370095,
        0.017908524721860886,
        0.0361485555768013,
        0.00979516003280878,
        0.00974529329687357,
        -0.0004247328615747392,
        -0.042750243097543716,
        0.022851070389151573,
        0.012127486988902092,
        0.02395252138376236,
        0.006610488519072533,
        -0.012894838117063046,
        -0.010937836952507496,
        -0.04027212783694267,
        -0.012313053011894226,
        -0.045311085879802704,
        0.005293456371873617,
        -0.01314836461097002,
        -0.0382964164018631,
        0.0056842174381017685,
        0.03868354111909866,
        -0.01616559736430645,
        0.0038207799661904573,
        -0.001508064684458077,
        0.03788881376385689,
        0.018315499648451805,
        -0.02492254599928856,
        0.014879031106829643,
        -0.009810462594032288,
        -0.03379112482070923,
        -0.04121479019522667,
        -0.012039014138281345,
        0.016437603160738945,
        -0.004940629471093416,
        -0.014289814978837967,
        0.022449389100074768,
        0.008760647848248482,
        -0.015374484471976757,
        0.016280939802527428,
        -0.017390010878443718,
        0.005704550072550774,
        -0.009500331245362759,
        0.013700398616492748,
        0.03579118475317955,
        0.022438209503889084,
        0.021784648299217224,
        -0.027667781338095665,
        0.00761501956731081,
        0.0344465933740139,
        0.022093884646892548,
        -0.05290014296770096,
        -0.012348605319857597,
        -0.0033902006689459085,
        -0.021717781201004982,
        0.05370861664414406,
        -0.05372209474444389,
        -0.01080777682363987,
        -0.016182251274585724,
        -0.013974064961075783,
        0.02389836683869362,
        0.009427635930478573,
        -0.006829140242189169,
        0.04207439720630646,
        0.003885578131303191,
        -0.013457353226840496,
        0.0701492577791214,
        -0.029544619843363762,
        0.0673622116446495,
        0.026926040649414062,
        0.04875339940190315,
        0.04795200005173683,
        0.025409197434782982,
        -0.03882612660527229,
        0.025371525436639786,
        0.035942498594522476,
        0.027246329933404922,
        -0.04393133893609047,
        -0.057044193148612976,
        -0.016779256984591484,
        -0.03925540670752525,
        -0.02265908755362034,
        0.017587676644325256,
        -0.022978447377681732,
        -0.026015087962150574,
        -0.02792203053832054,
        0.021942779421806335,
        0.051774635910987854,
        0.015729881823062897,
        -0.024613361805677414,
        0.05494920536875725,
        -0.004093092866241932,
        -0.0008026338182389736,
        0.021246451884508133,
        -0.008609382435679436,
        0.00593261094763875,
        -0.0026835415046662092,
        0.018415970727801323,
        0.025955207645893097,
        0.00761927105486393,
        -0.007814278826117516,
        -0.009868606925010681,
        -0.03974992781877518,
        -0.04178202152252197,
        -0.044596850872039795,
        -0.014419655315577984,
        -0.030120067298412323,
        -0.008785855025053024,
        -0.03402695432305336,
        0.011757057160139084,
        0.0022944840602576733,
        -0.004510080441832542,
        0.037430718541145325,
        -0.004503547213971615,
        0.004775260575115681,
        0.018319223076105118,
        0.009821527637541294,
        -0.022445084527134895,
        0.011707158759236336,
        0.010084283538162708,
        0.020680230110883713,
        -0.004182498436421156,
        -0.03911368548870087,
        0.019921885803341866,
        -0.01021944172680378,
        0.020591257140040398,
        0.02009778469800949,
        -0.04721330478787422,
        -0.0015429363120347261,
        0.0010303165763616562,
        -0.030122429132461548,
        -2.7294785468257032e-05,
        0.037468936294317245,
        -0.03073931112885475,
        0.039404548704624176,
        0.019928378984332085,
        0.004093831870704889,
        -0.036894578486680984,
        0.007313730660825968,
        0.008034742437303066,
        -0.005078587681055069,
        -0.0321422703564167,
        -0.0034350119531154633,
        0.01314386073499918,
        -0.005604799836874008,
        -0.015281549654901028,
        -0.019068652763962746,
        -0.03993602469563484,
        -0.03179606795310974,
        -0.018368547782301903,
        0.00574501184746623,
        0.026034142822027206,
        0.013468843884766102,
        0.025882430374622345,
        -0.012384934350848198,
        0.011524192988872528,
        -0.017859606072306633,
        0.016747107729315758,
        -0.0227793138474226,
        -0.015171361155807972,
        0.012602417729794979,
        -0.021210303530097008,
        -0.027959279716014862,
        0.011189952492713928,
        0.022484352812170982,
        -0.009040906094014645,
        0.009291214868426323,
        -0.05088275298476219,
        0.004634814336895943,
        -0.001399348140694201,
        0.007490554358810186,
        -0.0020094900391995907,
        -0.005571507383137941,
        0.0023027502465993166,
        0.008302630856633186,
        -0.0353945828974247,
        0.004640275612473488,
        0.012443882413208485,
        0.00026149331824854016,
        -0.014191824942827225,
        -0.0024438337422907352,
        0.05570974573493004,
        0.006601573433727026,
        -0.0005909967003390193,
        -0.007938079535961151,
        -0.030258268117904663,
        -0.03430965542793274,
        0.022828949615359306,
        -0.03129057586193085,
        0.015681907534599304,
        0.017061825841665268,
        -0.04336291551589966,
        -0.013384238816797733,
        0.0221586711704731,
        -0.0016003412893041968,
        -0.007494338788092136,
        -0.0020608394406735897,
        -0.00504467636346817,
        0.04550241678953171,
        -2.0718734958791174e-05,
        -0.035338208079338074,
        -0.04015737771987915,
        0.0036538278218358755,
        -0.008128548972308636,
        -0.04905053973197937,
        -0.012635293416678905,
        0.0067979879677295685,
        0.004582697059959173,
        0.003035787958651781,
        0.044384364038705826,
        0.006462084595113993,
        0.025112297385931015,
        -0.028356175869703293,
        -0.044755492359399796,
        0.007405826356261969,
        0.009968713857233524,
        0.005684477277100086,
        0.017513716593384743,
        0.05406991392374039,
        0.012913698330521584,
        0.0031596729531884193,
        -0.007934619672596455,
        -0.030934078618884087,
        0.01934104785323143,
        -0.029340216889977455,
        0.0019032044801861048,
        0.039228010922670364,
        0.03055674210190773,
        0.031961098313331604,
        0.00028407867648638785,
        0.030688680708408356,
        0.051817554980516434,
        -0.010919537395238876,
        0.02928951010107994,
        -0.016168514266610146,
        0.029470453038811684,
        0.010093554854393005,
        -0.021412968635559082,
        -0.00023605459136888385,
        0.019594179466366768,
        0.05386624485254288,
        0.0013275649398565292,
        0.030184423550963402,
        0.008417962118983269,
        0.01820666901767254,
        -0.018423371016979218,
        0.004223156720399857,
        0.01874978467822075,
        -0.0197637677192688,
        -0.04941069707274437,
        0.01812848635017872,
        -0.016631200909614563,
        -0.008958367630839348,
        -0.008591223508119583,
        -0.012036045081913471,
        0.022094186395406723,
        -0.0060726250521838665,
        -0.007104904390871525,
        -0.009389481507241726,
        -0.016547689214348793,
        -0.03771310672163963,
        0.02506287209689617,
        -0.027276434004306793,
        -0.04992589354515076,
        0.023162489756941795,
        -0.023389775305986404,
        0.047365546226501465,
        -0.0022959476336836815,
        -0.030506275594234467,
        0.007992136292159557,
        0.009817231446504593,
        0.03484336659312248,
        -0.027162035927176476,
        0.020688747987151146,
        -0.028971994295716286,
        0.005920604337006807,
        0.019468236714601517,
        -0.00980299524962902,
        0.011561859399080276,
        0.027372825890779495,
        0.00930106919258833,
        0.004211859777569771,
        0.027512259781360626,
        -0.016849610954523087,
        0.008490628562867641,
        0.008816802874207497,
        -0.004463036544620991,
        0.009845308028161526,
        0.016397064551711082,
        -0.0011473647318780422,
        -0.029515238478779793,
        0.013897431083023548,
        -0.03597898781299591,
        0.014808940701186657,
        -0.02324511483311653,
        0.003196192905306816,
        0.01196044310927391,
        -0.00658769253641367,
        0.012940457090735435,
        -0.016188956797122955,
        0.019094008952379227,
        0.030659066513180733,
        -0.005942823365330696,
        -0.01520765945315361,
        -0.03974270075559616,
        0.006137637421488762,
        0.03139965981245041,
        -0.008721558377146721,
        -0.005773893091827631,
        0.017957281321287155,
        -0.03896407410502434,
        0.015513245016336441,
        0.014548703096807003,
        0.03398771211504936,
        0.0001400052133249119,
        -0.02317914180457592,
        0.021159688010811806,
        0.002104078186675906,
        0.014116870239377022,
        0.0037195980548858643,
        0.021134868264198303,
        -0.05259595438838005,
        0.0468093678355217,
        -0.014145825989544392,
        0.0032047589775174856,
        -0.0020887700375169516,
        0.01907602697610855,
        -0.04247918725013733,
        -0.03388781100511551,
        0.033947866410017014,
        0.06400511413812637,
        0.0346493124961853,
        -0.01762630045413971,
        -0.017751343548297882,
        -0.009793655946850777,
        0.0002900575054809451,
        -0.022659504786133766,
        -0.02437080256640911,
        0.00045569107169285417,
        -0.02015969157218933,
        -0.0027708092238754034,
        -0.00434517627581954,
        0.005192579701542854,
        -0.04208087548613548,
        0.005406029522418976,
        0.023236915469169617,
        -0.011918244883418083,
        0.05339468643069267,
        0.014047176577150822,
        -0.031201789155602455,
        0.006640584673732519,
        -0.0217137411236763,
        0.007635305169969797,
        -0.0450051873922348,
        0.005341450218111277,
        0.028567878529429436,
        0.015056091360747814,
        -0.01144605316221714,
        -0.012074933387339115,
        -0.01376428548246622,
        -0.01314828172326088,
        0.008213261142373085,
        -0.0005265845684334636,
        -0.026280943304300308,
        -0.040777359157800674,
        0.038049597293138504,
        0.01738615520298481,
        0.05549187213182449,
        -0.031246382743120193,
        0.04426974058151245,
        0.020595017820596695,
        -0.005875780247151852,
        0.011045316234230995,
        0.009325409308075905,
        0.007019457407295704,
        0.014102879911661148,
        -0.019445177167654037,
        -0.0009318794473074377,
        0.025334054604172707,
        0.015093808993697166,
        -0.006366981193423271,
        0.0031435294076800346,
        -0.01970154605805874,
        0.018274229019880295,
        -0.02452235110104084,
        -0.023131897673010826,
        -0.020133215934038162,
        0.012511059641838074,
        0.018905693665146828,
        0.013764063827693462,
        0.017271919175982475,
        0.004731517285108566,
        -0.05685914680361748,
        0.007380637805908918,
        -0.008029729127883911,
        -0.020492037758231163,
        -0.020149696618318558,
        0.04379253089427948,
        -0.03362211957573891,
        0.024019617587327957,
        -0.024935854598879814,
        0.009402585215866566,
        0.0227953027933836,
        0.007366925477981567,
        0.03032088465988636,
        0.01351234596222639,
        -0.0047613088972866535,
        0.0051394361071288586,
        0.01209971308708191,
        0.038713715970516205,
        0.003788130823522806,
        -0.013933716341853142,
        0.02041618525981903,
        -0.012982932850718498,
        0.024293843656778336,
        0.016638632863759995,
        0.023398570716381073,
        -0.016348717734217644,
        -0.006172001361846924,
        -0.02612849697470665,
        -0.004013821482658386,
        0.0004121179517824203,
        -0.02461296319961548,
        0.005996657535433769,
        -0.006896170321851969,
        0.015618063509464264,
        -0.034726839512586594,
        0.0030639744363725185,
        -0.055094536393880844,
        0.03701409697532654,
        0.0031322536524385214,
        0.02586747147142887,
        -0.035434432327747345,
        0.0024635763838887215,
        0.004648999776691198,
        0.032570868730545044,
        -0.0523868054151535,
        0.019464900717139244,
        -0.006403591949492693,
        -0.009691743180155754,
        -0.03530913591384888,
        0.01670558750629425,
        -0.004297878127545118,
        0.00818848516792059,
        -0.010740404017269611,
        -0.00597400264814496,
        -0.002448863349854946,
        0.019749322906136513,
        -0.018895292654633522,
        0.043797340244054794,
        -0.03065464459359646,
        -0.014561842195689678,
        -0.0013403890188783407,
        -0.004156679380685091,
        -0.005812684539705515,
        -0.02002921886742115,
        0.005658660549670458,
        -0.007799736224114895,
        -0.017471926286816597,
        -0.006084025371819735,
        0.012937520630657673,
        -0.003079999703913927,
        -0.011682071723043919,
        -0.010767580941319466,
        -0.028494898229837418,
        -0.0029198455158621073,
        -0.046933792531490326,
        -0.005849598906934261,
        -0.013017354533076286,
        0.02265085279941559,
        -0.05990380793809891,
        0.005243755877017975,
        -0.0032413366716355085,
        0.016250232234597206,
        0.015012220479547977,
        0.0217024777084589,
        0.04144176468253136,
        -0.009993798099458218,
        -0.012958402745425701,
        -0.04017103090882301,
        -0.02501022256910801,
        -0.003671137848868966,
        -0.016932951286435127,
        0.018247518688440323,
        -0.0035143473651260138,
        0.03408634290099144,
        -0.0032874010503292084,
        0.004998453892767429,
        0.03837763890624046,
        0.013695647940039635,
        0.012126047164201736,
        -0.00898475106805563,
        -0.03514762222766876,
        -0.007091349456459284,
        -0.019559377804398537,
        -0.011771324090659618,
        -0.037243638187646866,
        -0.011565766297280788,
        -0.04205382987856865,
        -0.006023322232067585,
        -0.03372747451066971,
        -0.01962013728916645,
        0.006125158630311489,
        -0.013349045999348164,
        -0.036738015711307526,
        0.018293533474206924,
        -0.01359823253005743,
        0.006595849525183439,
        0.003754481440410018,
        0.007905149832367897,
        0.03514961153268814,
        -0.01699354499578476,
        0.008151195012032986,
        -0.02729685790836811,
        0.05210145562887192,
        0.01853075996041298,
        0.015803707763552666,
        0.02055491879582405,
        -0.03868114575743675,
        0.02412845566868782,
        0.01205241959542036,
        0.03240170702338219,
        -0.060401804745197296,
        0.01897030510008335,
        -0.01289504673331976,
        0.0014960735570639372,
        -0.003176682163029909,
        -0.07786000519990921,
        -0.00695143174380064,
        0.00979750044643879,
        0.010219795629382133,
        -0.011114029213786125,
        0.022297099232673645,
        -0.016606934368610382,
        -0.010082866996526718,
        0.02127768285572529,
        0.04338754341006279,
        -0.03450454771518707,
        -0.012875291518867016,
        -0.0109040392562747,
        -0.014800267294049263,
        0.007051208056509495,
        0.0036286127287894487,
        0.03853737562894821,
        0.005374586675316095,
        0.011831460520625114,
        -0.031878720968961716,
        0.021013373509049416,
        0.015865158289670944,
        0.004112951923161745,
        0.02284882217645645,
        -0.02439177967607975,
        -0.009272780269384384,
        -0.02202613279223442,
        -0.011600056663155556,
        0.0035233439411967993,
        -0.012654070742428303,
        -0.004705637693405151,
        -0.015825370326638222,
        -0.0023783163633197546,
        0.032097578048706055,
        0.01807725802063942,
        -0.03834092244505882,
        -0.0038977423682808876,
        -0.010863014496862888,
        0.022893080487847328,
        -0.0009979071328416467,
        0.017409425228834152,
        -0.00588889280334115,
        0.01125122606754303,
        0.01006596814841032,
        0.03428466245532036,
        -0.017092246562242508,
        0.028765786439180374,
        0.02047213539481163,
        -0.018767710775136948,
        -0.02697647735476494,
        0.023117192089557648,
        0.003708356060087681,
        -0.011185575276613235,
        0.008650977164506912,
        0.011862273328006268,
        -0.003278553020209074,
        0.02145806886255741,
        -0.01090134959667921,
        0.017205653712153435,
        0.04478038474917412,
        -0.016263794153928757,
        0.002122415229678154,
        0.0241069458425045,
        0.012421893887221813,
        0.011284349486231804,
        0.026590779423713684,
        0.01729264296591282,
        0.0020673030521720648,
        0.010065117850899696,
        -0.024424705654382706,
        0.0023522870615124702,
        -0.00025153221213258803,
        -0.00831686519086361,
        0.019585832953453064,
        0.017114562913775444,
        0.012888992205262184,
        -0.015307016670703888,
        -0.014569380320608616,
        -0.02808437868952751,
        0.0011367148254066706,
        -0.028208842501044273,
        0.02258565090596676,
        0.0024761823005974293,
        -0.029256707057356834,
        0.0024742677342146635,
        -0.004343048669397831,
        0.00910681951791048,
        0.0484052412211895,
        0.030838685110211372,
        0.02443815767765045,
        0.025990888476371765,
        -0.004408643580973148,
        0.004342414904385805,
        0.039770569652318954,
        -0.011442610062658787,
        -0.04572992026805878,
        -0.015954401344060898,
        -0.01781732402741909,
        0.025411412119865417,
        -0.01045394316315651,
        -0.009789944626390934
      ],
      "title": "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?"
    },
    {
      "id": "gai-eng_corpus-item003",
      "count": 3,
      "created": "2025-07-06T04:40:15.063193",
      "text": "Recommendation on the Ethics of Artificial Intelligence PREAMBLE The General Conference of the United Nations Educational, Scientific and Cultural Organization (UNESCO), meeting in Paris from 9 to 24 November 2021, at its 41st session, Recognizing the profound and dynamic positive and negative impacts of artificial intelligence (AI) on societies, environment, ecosystems and human lives, including the human mind, in part because of the new ways in which its use influences human thinking, interaction and decision-making and affects education, human, social and natural sciences, culture, and communication and information, Recalling that, by the terms of its Constitution, UNESCO seeks to contribute to peace and security by promoting collaboration among nations through education, the sciences, culture, and communication and information, in order to further universal respect for justice, for the rule of law and for the human rights and fundamental freedoms which are affirmed for the peoples of the world, Convinced that the Recommendation presented here, as a standard-setting instrument developed through a global approach, based on international law, focusing on human dignity and human rights, as well as gender equality, social and economic justice and development, physical and mental well-being, diversity, interconnectedness, inclusiveness, and environmental and ecosystem protection can guide AI technologies in a responsible direction, Guided by the purposes and principles of the Charter of the United Nations, Considering that AI technologies can be of great service to humanity and all countries can benefit from them, but also raise fundamental ethical concerns, for instance regarding the biases they can embed and exacerbate, potentially resulting in discrimination, inequality, digital divides, exclusion and a threat to cultural, social and biological diversity and social or economic divides; the need for transparency and understandability of the workings of algorithms and the data with which they have been trained; and their potential impact on, including but not limited to, human dignity, human rights and fundamental freedoms, gender equality, democracy, social, economic, political and cultural processes, scientific and engineering practices, animal welfare, and the environment and ecosystems, Also recognizing that AI technologies can deepen existing divides and inequalities in the world, within and between countries, and that justice, trust and fairness must be upheld so that no country and no one should be left behind, either by having fair access to AI technologies and enjoying their benefits or in the protection against their negative implications, while recognizing the different circumstances of different countries and respecting the desire of some people not to take part in all technological developments, Conscious of the fact that all countries are facing an acceleration in the use of information and communication technologies and AI technologies, as well as an increasing need for media and information literacy, and that the digital economy presents important societal, economic and environmental challenges and opportunities of benefit-sharing, especially for low- and middle-income countries (LMICs), including but not limited to least developed countries (LDCs), landlocked developing countries (LLDCs) and small island developing States (SIDS), requiring the recognition, protection and promotion of endogenous cultures, values and knowledge in order to develop sustainable digital economies, Further recognizing that AI technologies have the potential to be beneficial to the environment and ecosystems, and in order for those benefits to be realized, potential harms to and negative impacts on the environment and ecosystems should not be ignored but instead addressed, Noting that addressing risks and ethical concerns should not hamper innovation and development but rather provide new opportunities and stimulate ethically-conducted research and innovation that anchor AI technologies in human rights and fundamental freedoms, values and principles, and moral and ethical reflection, Also recalling that in November 2019, the General Conference of UNESCO, at its 40th session, adopted 40 C/Resolution 37, by which it mandated the Director-General 'to prepare an international standard-setting instrument on the ethics of artificial intelligence (AI) in the form of a recommendation', which is to be submitted to the General Conference at its 41st session in 2021, Recognizing that the development of AI technologies necessitates a commensurate increase in data, media and information literacy as well as access to independent, pluralistic, trusted sources of information, including as part of efforts to mitigate risks of misinformation, disinformation and hate speech, and harm caused through the misuse of personal data, Observing that a normative framework for AI technologies and its social implications finds its basis in international and national legal frameworks, human rights and fundamental freedoms, ethics, need for access to data, information and knowledge, the freedom of research and innovation, human and environmental and ecosystem well-being, and connects ethical values and principles to the challenges and opportunities linked to AI technologies, based on common understanding and shared aims, Also recognizing that ethical values and principles can help develop and implement rights-based policy measures and legal norms, by providing guidance with a view to the fast pace of technological development, Also convinced that globally accepted ethical standards for AI technologies, in full respect of international law, in particular human rights law, can play a key role in developing AI-related norms across the globe, Bearing in mind the Universal Declaration of Human Rights (1948), the instruments of the international human rights framework, including the Convention Relating to the Status of Refugees (1951), the Discrimination (Employment and Occupation) Convention (1958), the International Convention on the Elimination of All Forms of Racial Discrimination (1965), the International Covenant on Civil and Political Rights (1966), the International Covenant on Economic, Social and Cultural Rights (1966), the Convention on the Elimination of All Forms of Discrimination against Women (1979), the Convention on the Rights of the Child (1989), and the Convention on the Rights of Persons with Disabilities (2006), the Convention against Discrimination in Education (1960), the Convention on the Protection and Promotion of the Diversity of Cultural Expressions (2005), as well as any other relevant international instruments, recommendations and declarations, Also noting the United Nations Declaration on the Right to Development (1986); the Declaration on the Responsibilities of the Present Generations Towards Future Generations (1997); the Universal Declaration on Bioethics and Human Rights (2005); the United Nations Declaration on the Rights of Indigenous Peoples (2007); the United Nations General Assembly resolution on the review of the World Summit on the Information Society (A/RES/70/125) (2015); the United Nations General Assembly Resolution on Transforming our world: the 2030 Agenda for Sustainable Development (A/RES/70/1) (2015); the Recommendation Concerning the Preservation of, and Access to, Documentary Heritage Including in Digital Form (2015); the Declaration of Ethical Principles in relation to Climate Change (2017); the Recommendation on Science and Scientific Researchers (2017); the Internet Universality Indicators (endorsed by UNESCO's International Programme for the Development of Communication in 2018), including the ROAM principles (endorsed by UNESCO's General Conference in 2015); the Human Rights Council's resolution on 'The right to privacy in the digital age' (A/HRC/RES/42/15) (2019); and the Human Rights Council's resolution on 'New and emerging digital technologies and human rights' (A/HRC/RES/41/11) (2019), Emphasizing that specific attention must be paid to LMICs, including but not limited to LDCs, LLDCs and SIDS, as they have their own capacity but have been underrepresented in the AI ethics debate, which raises concerns about neglecting local knowledge, cultural pluralism, value systems and the demands of global fairness to deal with the positive and negative impacts of AI technologies, Also conscious of the many existing national policies, other frameworks and initiatives elaborated by relevant United Nations entities, intergovernmental organizations, including regional organizations, as well as those by the private sector, professional organizations, non-governmental organizations, and the scientific community, related to the ethics and regulation of AI technologies, Further convinced that AI technologies can bring important benefits, but that achieving them can also amplify tension around innovation, asymmetric access to knowledge and technologies, including the digital and civic literacy deficit that limits the public's ability to engage in topics related to AI, as well as barriers to access to information and gaps in capacity, human and institutional capacities, barriers to access to technological innovation, and a lack of adequate physical and digital infrastructure and regulatory frameworks, including those related to data, all of which need to be addressed, Underlining that the strengthening of global cooperation and solidarity, including through multilateralism, is needed to facilitate fair access to AI technologies and address the challenges that they bring to diversity and interconnectivity of cultures and ethical systems, to mitigate potential misuse, to realize the full potential that AI can bring, especially in the area of development, and to ensure that national AI strategies are guided by ethical principles, Taking fully into account that the rapid development of AI technologies challenges their ethical implementation and governance, as well as the respect for and protection of cultural diversity, and has the potential to disrupt local and regional ethical standards and values, 1. Adopts the present Recommendation on the Ethics of Artificial Intelligence on this twenty-third day of November 2021; 2. Recommends that Member States apply on a voluntary basis the provisions of this Recommendation by taking appropriate steps, including whatever legislative or other measures may be required, in conformity with the constitutional practice and governing structures of each State, to give effect within their jurisdictions to the principles and norms of the Recommendation in conformity with international law, including international human rights law; 3. Also recommends that Member States engage all stakeholders, including business enterprises, to ensure that they play their respective roles in the implementation of this Recommendation; and bring the Recommendation to the attention of the authorities, bodies, research and academic organizations, institutions and organizations in public, private and civil society sectors involved in AI technologies, so that the development and use of AI technologies are guided by both sound scientific research as well as ethical analysis and evaluation. I. SCOPE OF APPLICATION 1. This Recommendation addresses ethical issues related to the domain of Artificial Intelligence to the extent that they are within UNESCO's mandate. It approaches AI ethics as a systematic normative reflection, based on a holistic, comprehensive, multicultural and evolving framework of interdependent values, principles and actions that can guide societies in dealing responsibly with the known and unknown impacts of AI technologies on human beings, societies and the environment and ecosystems, and offers them a basis to accept or reject AI technologies. It considers ethics as a dynamic basis for the normative evaluation and guidance of AI technologies, referring to human dignity, well-being and the prevention of harm as a compass and as rooted in the ethics of science and technology. 2. This Recommendation does not have the ambition to provide one single definition of AI, since such a definition would need to change over time, in accordance with technological developments. Rather, its ambition is to address those features of AI systems that are of central ethical relevance. Therefore, this Recommendation approaches AI systems as systems which have the capacity to process data and information in a way that resembles intelligent behaviour, and typically includes aspects of reasoning, learning, perception, prediction, planning or control. Three elements have a central place in this approach: (a) AI systems are information-processing technologies that integrate models and algorithms that produce a capacity to learn and to perform cognitive tasks leading to outcomes such as prediction and decision-making in material and virtual environments. AI systems are designed to operate with varying degrees of autonomy by means of knowledge modelling and representation and by exploiting data and calculating correlations. AI systems may include several methods, such as but not limited to: (i) machine learning, including deep learning and reinforcement learning; (ii) machine reasoning, including planning, scheduling, knowledge representation and reasoning, search, and optimization. AI systems can be used in cyber-physical systems, including the Internet of things, robotic systems, social robotics, and human-computer interfaces, which involve control, perception, the processing of data collected by sensors, and the operation of actuators in the environment in which AI systems work. (b) Ethical questions regarding AI systems pertain to all stages of the AI system life cycle, understood here to range from research, design and development to deployment and use, including maintenance, operation, trade, financing, monitoring and evaluation, validation, end-of-use, disassembly and termination. In addition, AI actors can be defined as any actor involved in at least one stage of the AI system life cycle, and can refer both to natural and legal persons, such as researchers, programmers, engineers, data scientists, end-users, business enterprises, universities and public and private entities, among others. (c) AI systems raise new types of ethical issues that include, but are not limited to, their impact on decision-making, employment and labour, social interaction, health care, education, media, access to information, digital divide, personal data and consumer protection, environment, democracy, rule of law, security and policing, dual use, and human rights and fundamental freedoms, including freedom of expression, privacy and non-discrimination. Furthermore, new ethical challenges are created by the potential of AI algorithms to reproduce and reinforce existing biases, and thus to exacerbate already existing forms of discrimination, prejudice and stereotyping. Some of these issues are related to the capacity of AI systems to perform tasks which previously only living beings could do, and which were in some cases even limited to human beings only. These characteristics give AI systems a profound, new role in human practices and society, as well as in their relationship with the environment and ecosystems, creating a new context for children and young people to grow up in, develop an understanding of the world and themselves, critically understand media and information, and learn to make decisions. In the long term, AI systems could challenge humans' special sense of experience and agency, raising additional concerns about, inter alia, human self-understanding, social, cultural and environmental interaction, autonomy, agency, worth and dignity. 3. This Recommendation pays specific attention to the broader ethical implications of AI systems in relation to the central domains of UNESCO: education, science, culture, and communication and information, as explored in the 2019 Preliminary Study on the Ethics of Artificial Intelligence by the UNESCO World Commission on Ethics of Scientific Knowledge and Technology (COMEST): (a) Education, because living in digitalizing societies requires new educational practices, ethical reflection, critical thinking, responsible design practices and new skills, given the implications for the labour market, employability and civic participation. (b) Science, in the broadest sense and including all academic fields from the natural sciences and medical sciences to the social sciences and humanities, as AI technologies bring new research capacities and approaches, have implications for our concepts of scientific understanding and explanation, and create a new basis for decision-making. (c) Cultural identity and diversity, as AI technologies can enrich cultural and creative industries, but can also lead to an increased concentration of supply of cultural content, data, markets and income in the hands of only a few actors, with potential negative implications for the diversity and pluralism of languages, media, cultural expressions, participation and equality. (d) Communication and information, as AI technologies play an increasingly important role in the processing, structuring and provision of information; the issues of automated journalism and the algorithmic provision of news and moderation and curation of content on social media and search engines are just a few examples raising issues related to access to information, disinformation, misinformation, hate speech, the emergence of new forms of societal narratives, discrimination, freedom of expression, privacy and media and information literacy, among others. 4. This Recommendation is addressed to Member States, both as AI actors and as authorities responsible for developing legal and regulatory frameworks throughout the entire AI system life cycle, and for promoting business responsibility. It also provides ethical guidance to all AI actors, including the public and private sectors, by providing a basis for an ethical impact assessment of AI systems throughout their life cycle. II. AIMS AND OBJECTIVES 5. This Recommendation aims to provide a basis to make AI systems work for the good of humanity, individuals, societies and the environment and ecosystems, and to prevent harm. It also aims at stimulating the peaceful use of AI systems. 6. In addition to the existing ethical frameworks regarding AI around the world, this Recommendation aims to bring a globally accepted normative instrument that focuses not only on the articulation of values and principles, but also on their practical realization, via concrete policy recommendations, with a strong emphasis on inclusion issues of gender equality and protection of the environment and ecosystems. 7. Because the complexity of the ethical issues surrounding AI necessitates the cooperation of multiple stakeholders across the various levels and sectors of international, regional and national communities, this Recommendation aims to enable stakeholders to take shared responsibility based on a global and intercultural dialogue. 8. The objectives of this Recommendation are: (a) to provide a universal framework of values, principles and actions to guide States in the formulation of their legislation, policies or other instruments regarding AI, consistent with international law; (b) to guide the actions of individuals, groups, communities, institutions and private sector companies to ensure the embedding of ethics in all stages of the AI system life cycle; (c) to protect, promote and respect human rights and fundamental freedoms, human dignity and equality, including gender equality; to safeguard the interests of present and future generations; to preserve the environment, biodiversity and ecosystems; and to respect cultural diversity in all stages of the AI system life cycle; (d) to foster multi-stakeholder, multidisciplinary and pluralistic dialogue and consensus building about ethical issues relating to AI systems; (e) to promote equitable access to developments and knowledge in the field of AI and the sharing of benefits, with particular attention to the needs and contributions of LMICs, including LDCs, LLDCs and SIDS. III. VALUES AND PRINCIPLES 9. The values and principles included below should be respected by all actors in the AI system life cycle, in the first place and, where needed and appropriate, be promoted through amendments to the existing and elaboration of new legislation, regulations and business guidelines. This must comply with international law, including the United Nations Charter and Member States' human rights obligations, and should be in line with internationally agreed social, political, environmental, educational, scientific and economic sustainability objectives, such as the United Nations Sustainable Development Goals (SDGs). 10. Values play a powerful role as motivating ideals in shaping policy measures and legal norms. While the set of values outlined below thus inspires desirable behaviour and represents the foundations of principles, the principles unpack the values underlying them more concretely so that the values can be more easily operationalized in policy statements and actions. 11. While all the values and principles outlined below are desirable per se, in any practical contexts, there may be tensions between these values and principles. In any given situation, a contextual assessment will be necessary to manage potential tensions, taking into account the principle of proportionality and in compliance with human rights and fundamental freedoms. In all cases, any possible limitations on human rights and fundamental freedoms must have a lawful basis, and be reasonable, necessary and proportionate, and consistent with States' obligations under international law. To navigate such scenarios judiciously will typically require engagement with a broad range of appropriate stakeholders, making use of social dialogue, as well as ethical deliberation, due diligence and impact assessment. 12. The trustworthiness and integrity of the life cycle of AI systems is essential to ensure that AI technologies will work for the good of humanity, individuals, societies and the environment and ecosystems, and embody the values and principles set out in this Recommendation. People should have good reason to trust that AI systems can bring individual and shared benefits, while adequate measures are taken to mitigate risks. An essential requirement for trustworthiness is that, throughout their life cycle, AI systems are subject to thorough monitoring by the relevant stakeholders as appropriate. As trustworthiness is an outcome of the operationalization of the principles in this document, the policy actions proposed in this Recommendation are all directed at promoting trustworthiness in all stages of the AI system life cycle. III.1 VALUES Respect, protection and promotion of human rights and fundamental freedoms and human dignity 13. The inviolable and inherent dignity of every human constitutes the foundation for the universal, indivisible, inalienable, interdependent and interrelated system of human rights and fundamental freedoms. Therefore, respect, protection and promotion of human dignity and rights as established by international law, including international human rights law, is essential throughout the life cycle of AI systems. Human dignity relates to the recognition of the intrinsic and equal worth of each individual human being, regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds. 14. No human being or human community should be harmed or subordinated, whether physically, economically, socially, politically, culturally or mentally during any phase of the life cycle of AI systems. Throughout the life cycle of AI systems, the quality of life of human beings should be enhanced, while the definition of 'quality of life' should be left open to individuals or groups, as long as there is no violation or abuse of human rights and fundamental freedoms, or the dignity of humans in terms of this definition. 15. Persons may interact with AI systems throughout their life cycle and receive assistance from them, such as care for vulnerable people or people in vulnerable situations, including but not limited to children, older persons, persons with disabilities or the ill. Within such interactions, persons should never be objectified, nor should their dignity be otherwise undermined, or human rights and fundamental freedoms violated or abused. 16. Human rights and fundamental freedoms must be respected, protected and promoted throughout the life cycle of AI systems. Governments, private sector, civil society, international organizations, technical communities and academia must respect human rights instruments and frameworks in their interventions in the processes surrounding the life cycle of AI systems. New technologies need to provide new means to advocate, defend and exercise human rights and not to infringe them. Environmental and ecosystem flourishing 17. Environmental and ecosystem flourishing should be recognized, protected and promoted through the life cycle of AI systems. Furthermore, environment and ecosystems are the existential necessity for humanity and other living beings to be able to enjoy the benefits of advances in AI. 18. All actors involved in the life cycle of AI systems must comply with applicable international law and domestic legislation, standards and practices, such as precaution, designed for environmental and ecosystem protection and restoration, and sustainable development. They should reduce the environmental impact of AI systems, including but not limited to its carbon footprint, to ensure the minimization of climate change and environmental risk factors, and prevent the unsustainable exploitation, use and transformation of natural resources contributing to the deterioration of the environment and the degradation of ecosystems. Ensuring diversity and inclusiveness 19. Respect, protection and promotion of diversity and inclusiveness should be ensured throughout the life cycle of AI systems, consistent with international law, including human rights law. This may be done by promoting active participation of all individuals or groups regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds. 20. The scope of lifestyle choices, beliefs, opinions, expressions or personal experiences, including the optional use of AI systems and the co-design of these architectures should not be restricted during any phase of the life cycle of AI systems. 21. Furthermore, efforts, including international cooperation, should be made to overcome, and never take advantage of, the lack of necessary technological infrastructure, education and skills, as well as legal frameworks, particularly in LMICs, LDCs, LLDCs and SIDS, affecting communities. Living in peaceful, just and interconnected societies 22. AI actors should play a participative and enabling role to ensure peaceful and just societies, which is based on an interconnected future for the benefit of all, consistent with human rights and fundamental freedoms. The value of living in peaceful and just societies points to the potential of AI systems to contribute throughout their life cycle to the interconnectedness of all living creatures with each other and with the natural environment. 23. The notion of humans being interconnected is based on the knowledge that every human belongs to a greater whole, which thrives when all its constituent parts are enabled to thrive. Living in peaceful, just and interconnected societies requires an organic, immediate, uncalculated bond of solidarity, characterized by a permanent search for peaceful relations, tending towards care for others and the natural environment in the broadest sense of the term. 24. This value demands that peace, inclusiveness and justice, equity and interconnectedness should be promoted throughout the life cycle of AI systems, in so far as the processes of the life cycle of AI systems should not segregate, objectify or undermine freedom and autonomous decision-making as well as the safety of human beings and communities, divide and turn individuals and groups against each other, or threaten the coexistence between humans, other living beings and the natural environment. III.2 PRINCIPLES Proportionality and Do No Harm 25. It should be recognized that AI technologies do not necessarily, per se, ensure human and environmental and ecosystem flourishing. Furthermore, none of the processes related to the AI system life cycle shall exceed what is necessary to achieve legitimate aims or objectives and should be appropriate to the context. In the event of possible occurrence of any harm to human beings, human rights and fundamental freedoms, communities and society at large or the environment and ecosystems, the implementation of procedures for risk assessment and the adoption of measures in order to preclude the occurrence of such harm should be ensured. 26. The choice to use AI systems and which AI method to use should be justified in the following ways: (a) the AI method chosen should be appropriate and proportional to achieve a given legitimate aim; (b) the AI method chosen should not infringe upon the foundational values captured in this document, in particular, its use must not violate or abuse human rights; and (c) the AI method should be appropriate to the context and should be based on rigorous scientific foundations. In scenarios where decisions are understood to have an impact that is irreversible or difficult to reverse or may involve life and death decisions, final human determination should apply. In particular, AI systems should not be used for social scoring or mass surveillance purposes. Safety and security 27. Unwanted harms (safety risks), as well as vulnerabilities to attack (security risks) should be avoided and should be addressed, prevented and eliminated throughout the life cycle of AI systems to ensure human, environmental and ecosystem safety and security. Safe and secure AI will be enabled by the development of sustainable, privacy-protective data access frameworks that foster better training and validation of AI models utilizing quality data. Fairness and non-discrimination 28. AI actors should promote social justice and safeguard fairness and non-discrimination of any kind in compliance with international law. This implies an inclusive approach to ensuring that the benefits of AI technologies are available and accessible to all, taking into consideration the specific needs of different age groups, cultural systems, different language groups, persons with disabilities, girls and women, and disadvantaged, marginalized and vulnerable people or people in vulnerable situations. Member States should work to promote inclusive access for all, including local communities, to AI systems with locally relevant content and services, and with respect for multilingualism and cultural diversity. Member States should work to tackle digital divides and ensure inclusive access to and participation in the development of AI. At the national level, Member States should promote equity between rural and urban areas, and among all persons regardless of race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other grounds, in terms of access to and participation in the AI system life cycle. At the international level, the most technologically advanced countries have a responsibility of solidarity with the least advanced to ensure that the benefits of AI technologies are shared such that access to and participation in the AI system life cycle for the latter contributes to a fairer world order with regard to information, communication, culture, education, research and socio-economic and political stability. 29. AI actors should make all reasonable efforts to minimize and avoid reinforcing or perpetuating discriminatory or biased applications and outcomes throughout the life cycle of the AI system to ensure fairness of such systems. Effective remedy should be available against discrimination and biased algorithmic determination. 30. Furthermore, digital and knowledge divides within and between countries need to be addressed throughout an AI system life cycle, including in terms of access and quality of access to technology and data, in accordance with relevant national, regional and international legal frameworks, as well as in terms of connectivity, knowledge and skills and meaningful participation of the affected communities, such that every person is treated equitably. Sustainability 31. The development of sustainable societies relies on the achievement of a complex set of objectives on a continuum of human, social, cultural, economic and environmental dimensions. The advent of AI technologies can either benefit sustainability objectives or hinder their realization, depending on how they are applied across countries with varying levels of development. The continuous assessment of the human, social, cultural, economic and environmental impact of AI technologies should therefore be carried out with full cognizance of the implications of AI technologies for sustainability as a set of constantly evolving goals across a range of dimensions, such as currently identified in the Sustainable Development Goals (SDGs) of the United Nations. Right to Privacy, and Data Protection 32. Privacy, a right essential to the protection of human dignity, human autonomy and human agency, must be respected, protected and promoted throughout the life cycle of AI systems. It is important that data for AI systems be collected, used, shared, archived and deleted in ways that are consistent with international law and in line with the values and principles set forth in this Recommendation, while respecting relevant national, regional and international legal frameworks. 33. Adequate data protection frameworks and governance mechanisms should be established in a multi-stakeholder approach at the national or international level, protected by judicial systems, and ensured throughout the life cycle of AI systems. Data protection frameworks and any related mechanisms should take reference from international data protection principles and standards concerning the collection, use and disclosure of personal data and exercise of their rights by data subjects while ensuring a legitimate aim and a valid legal basis for the processing of personal data, including informed consent. 34. Algorithmic systems require adequate privacy impact assessments, which also include societal and ethical considerations of their use and an innovative use of the privacy by design approach. AI actors need to ensure that they are accountable for the design and implementation of AI systems in such a way as to ensure that personal information is protected throughout the life cycle of the AI system. Human oversight and determination 35. Member States should ensure that it is always possible to attribute ethical and legal responsibility for any stage of the life cycle of AI systems, as well as in cases of remedy related to AI systems, to physical persons or to existing legal entities. Human oversight refers thus not only to individual human oversight, but to inclusive public oversight, as appropriate. 36. It may be the case that sometimes humans would choose to rely on AI systems for reasons of efficacy, but the decision to cede control in limited contexts remains that of humans, as humans can resort to AI systems in decision-making and acting, but an AI system can never replace ultimate human responsibility and accountability. As a rule, life and death decisions should not be ceded to AI systems. Transparency and explainability 37. The transparency and explainability of AI systems are often essential preconditions to ensure the respect, protection and promotion of human rights, fundamental freedoms and ethical principles. Transparency is necessary for relevant national and international liability regimes to work effectively. A lack of transparency could also undermine the possibility of effectively challenging decisions based on outcomes produced by AI systems and may thereby infringe the right to a fair trial and effective remedy, and limits the areas in which these systems can be legally used. 38. While efforts need to be made to increase transparency and explainability of AI systems, including those with extra-territorial impact, throughout their life cycle to support democratic governance, the level of transparency and explainability should always be appropriate to the context and impact, as there may be a need to balance between transparency and explainability and other principles such as privacy, safety and security. People should be fully informed when a decision is informed by or is made on the basis of AI algorithms, including when it affects their safety or human rights, and in those circumstances should have the opportunity to request explanatory information from the relevant AI actor or public sector institutions. In addition, individuals should be able to access the reasons for a decision affecting their rights and freedoms, and have the option of making submissions to a designated staff member of the private sector company or public sector institution able to review and correct the decision. AI actors should inform users when a product or service is provided directly or with the assistance of AI systems in a proper and timely manner. 39. From a socio-technical lens, greater transparency contributes to more peaceful, just, democratic and inclusive societies. It allows for public scrutiny that can decrease corruption and discrimination, and can also help detect and prevent negative impacts on human rights. Transparency aims at providing appropriate information to the respective addressees to enable their understanding and foster trust. Specific to the AI system, transparency can enable people to understand how each stage of an AI system is put in place, appropriate to the context and sensitivity of the AI system. It may also include insight into factors that affect a specific prediction or decision, and whether or not appropriate assurances (such as safety or fairness measures) are in place. In cases of serious threats of adverse human rights impacts, transparency may also require the sharing of code or datasets. 40. Explainability refers to making intelligible and providing insight into the outcome of AI systems. The explainability of AI systems also refers to the understandability of the input, output and the functioning of each algorithmic building block and how it contributes to the outcome of the systems. Thus, explainability is closely related to transparency, as outcomes and sub-processes leading to outcomes should aim to be understandable and traceable, appropriate to the context. AI actors should commit to ensuring that the algorithms developed are explainable. In the case of AI applications that impact the end user in a way that is not temporary, easily reversible or otherwise low risk, it should be ensured that the meaningful explanation is provided with any decision that resulted in the action taken in order for the outcome to be considered transparent. 41. Transparency and explainability relate closely to adequate responsibility and accountability measures, as well as to the trustworthiness of AI systems. Responsibility and accountability 42. AI actors and Member States should respect, protect and promote human rights and fundamental freedoms, and should also promote the protection of the environment and ecosystems, assuming their respective ethical and legal responsibility, in accordance with national and international law, in particular Member States' human rights obligations, and ethical guidance throughout the life cycle of AI systems, including with respect to AI actors within their effective territory and control. The ethical responsibility and liability for the decisions and actions based in any way on an AI system should always ultimately be attributable to AI actors corresponding to their role in the life cycle of the AI system. 43. Appropriate oversight, impact assessment, audit and due diligence mechanisms, including whistle-blowers' protection, should be developed to ensure accountability for AI systems and their impact throughout their life cycle. Both technical and institutional designs should ensure auditability and traceability of (the working of) AI systems in particular to address any conflicts with human rights norms and standards and threats to environmental and ecosystem well-being. Awareness and literacy 44. Public awareness and understanding of AI technologies and the value of data should be promoted through open and accessible education, civic engagement, digital skills and AI ethics training, media and information literacy and training led jointly by governments, intergovernmental organizations, civil society, academia, the media, community leaders and the private sector, and considering the existing linguistic, social and cultural diversity, to ensure effective public participation so that all members of society can take informed decisions about their use of AI systems and be protected from undue influence. 45. Learning about the impact of AI systems should include learning about, through and for human rights and fundamental freedoms, meaning that the approach and understanding of AI systems should be grounded by their impact on human rights and access to rights, as well as on the environment and ecosystems. Multi-stakeholder and adaptive governance and collaboration 46. International law and national sovereignty must be respected in the use of data. That means that States, complying with international law, can regulate the data generated within or passing through their territories, and take measures towards effective regulation of data, including data protection, based on respect for the right to privacy in accordance with international law and other human rights norms and standards. Participation of different stakeholders throughout the AI system life cycle is necessary for inclusive approaches to AI governance, enabling the benefits to be shared by all, and to contribute to sustainable development. Stakeholders include but are not limited to governments, intergovernmental organizations, the technical community, civil society, researchers and academia, media, education, policy-makers, private sector companies, human rights institutions and equality bodies, anti-discrimination monitoring bodies, and groups for youth and children. The adoption of open standards and interoperability to facilitate collaboration should be in place. Measures should be adopted to take into account shifts in technologies, the emergence of new groups of stakeholders, and to allow for meaningful participation by marginalized groups, communities and individuals and, where relevant, in the case of Indigenous Peoples, respect for the self-governance of their data. IV. AREAS OF POLICY ACTION 48. The policy actions described in the following policy areas operationalize the values and principles set out in this Recommendation. The main action is for Member States to put in place effective measures, including, for example, policy frameworks or mechanisms, and to ensure that other stakeholders, such as private sector companies, academic and research institutions, and civil society adhere to them by, among other actions, encouraging all stakeholders to develop human rights, rule of law, democracy, and ethical impact assessment and due diligence tools in line with guidance including the United Nations Guiding Principles on Business and Human Rights. The process for developing such policies or mechanisms should be inclusive of all stakeholders and should take into account the circumstances and priorities of each Member State. UNESCO can be a partner and support Member States in the development as well as monitoring and evaluation of policy mechanisms. 49. UNESCO recognizes that Member States will be at different stages of readiness to implement this Recommendation, in terms of scientific, technological, economic, educational, legal, regulatory, infrastructural, societal, cultural and other dimensions. It is noted that \"readiness\" here is a dynamic status. In order to enable the effective implementation of this Recommendation, UNESCO will therefore: (1) develop a readiness assessment methodology to assist interested Member States in identifying their status at specific moments of their readiness trajectory along a continuum of dimensions; and (2) ensure support for interested Member States in terms of developing a UNESCO methodology for Ethical Impact Assessment (EIA) of AI technologies, sharing of best practices, assessment guidelines and other mechanisms and analytical work. POLICY AREA 1: ETHICAL IMPACT ASSESSMENT 50. Member States should introduce frameworks for impact assessments, such as ethical impact assessment, to identify and assess benefits, concerns and risks of AI systems, as well as appropriate risk prevention, mitigation and monitoring measures, among other assurance mechanisms. Such impact assessments should identify impacts on human rights and fundamental freedoms, in particular but not limited to the rights of marginalized and vulnerable people or people in vulnerable situations, labour rights, the environment and ecosystems and ethical and social implications, and facilitate citizen participation in line with the values and principles set forth in this Recommendation. 51. Member States and private sector companies should develop due diligence and oversight mechanisms to identify, prevent, mitigate and account for how they address the impact of AI systems on the respect for human rights, rule of law and inclusive societies. Member States should also be able to assess the socio-economic impact of AI systems on poverty and ensure that the gap between people living in wealth and poverty, as well as the digital divide among and within countries, are not increased with the massive adoption of AI technologies at present and in the future. In order to do this, in particular, enforceable transparency protocols should be implemented, corresponding to the access to information, including information of public interest held by private entities. Member States, private sector companies and civil society should investigate the sociological and psychological effects of AI-based recommendations on humans in their decision-making autonomy. AI systems identified as potential risks to human rights should be broadly tested by AI actors, including in real-world conditions if needed, as part of the Ethical Impact Assessment, before releasing them in the market. 52. Member States and business enterprises should implement appropriate measures to monitor all phases of an AI system life cycle, including the functioning of algorithms used for decision-making, the data, as well as AI actors involved in the process, especially in public services and where direct end-user interaction is needed, as part of ethical impact assessment. Member States' human rights law obligations should form part of the ethical aspects of AI system assessments. 53. Governments should adopt a regulatory framework that sets out a procedure, particularly for public authorities, to carry out ethical impact assessments on AI systems to predict consequences, mitigate risks, avoid harmful consequences, facilitate citizen participation and address societal challenges. The assessment should also establish appropriate oversight mechanisms, including auditability, traceability and explainability, which enable the assessment of algorithms, data and design processes, as well as include external review of AI systems. Ethical impact assessments should be transparent and open to the public, where appropriate. Such assessments should also be multidisciplinary, multi-stakeholder, multicultural, pluralistic and inclusive. The public authorities should be required to monitor the AI systems implemented and/or deployed by those authorities by introducing appropriate mechanisms and tools. POLICY AREA 2: ETHICAL GOVERNANCE AND STEWARDSHIP 54. Member States should ensure that AI governance mechanisms are inclusive, transparent, multidisciplinary, multilateral (this includes the possibility of mitigation and redress of harm across borders) and multi-stakeholder. In particular, governance should include aspects of anticipation, and effective protection, monitoring of impact, enforcement and redress. 55. Member States should ensure that harms caused through AI systems are investigated and redressed, by enacting strong enforcement mechanisms and remedial actions, to make certain that human rights and fundamental freedoms and the rule of law are respected in the digital world and in the physical world. Such mechanisms and actions should include remediation mechanisms provided by private and public sector companies. The auditability and traceability of AI systems should be promoted to this end. In addition, Member States should strengthen their institutional capacities to deliver on this commitment and should collaborate with researchers and other stakeholders to investigate, prevent and mitigate any potentially malicious uses of AI systems. 56. Member States are encouraged to develop national and regional AI strategies and to consider forms of soft governance such as a certification mechanism for AI systems and the mutual recognition of their certification, according to the sensitivity of the application domain and expected impact on human rights, the environment and ecosystems, and other ethical considerations set forth in this Recommendation. Such a mechanism might include different levels of audit of systems, data, and adherence to ethical guidelines and to procedural requirements in view of ethical aspects. At the same time, such a mechanism should not hinder innovation or disadvantage small and medium enterprises or start-ups, civil society as well as research and science organizations, as a result of an excessive administrative burden. These mechanisms should also include a regular monitoring component to ensure system robustness and continued integrity and adherence to ethical guidelines over the entire life cycle of the AI system, requiring re-certification if necessary. 57. Member States and public authorities should carry out transparent self-assessment of existing and proposed AI systems, which, in particular, should include the assessment of whether the adoption of AI is appropriate and, if so, should include further assessment to determine what the appropriate method is, as well as assessment as to whether such adoption would result in violations or abuses of Member States' human rights law obligations, and if that is the case, prohibit its use. 58. Member States should encourage public entities, private sector companies and civil society organizations to involve different stakeholders in their AI governance and to consider adding the role of an independent AI Ethics Officer or some other mechanism to oversee ethical impact assessment, auditing and continuous monitoring efforts and ensure ethical guidance of AI systems. Member States, private sector companies and civil society organizations, with the support of UNESCO, are encouraged to create a network of independent AI Ethics Officers to give support to this process at national, regional and international levels. 59. Member States should foster the development of, and access to, a digital ecosystem for ethical and inclusive development of AI systems at the national level, including to address gaps in access to the AI system life cycle, while contributing to international collaboration. Such an ecosystem includes, in particular, digital technologies and infrastructure, and mechanisms for sharing AI knowledge, as appropriate. 60. Member States should establish mechanisms, in collaboration with international organizations, transnational corporations, academic institutions and civil society, to ensure the active participation of all Member States, especially LMICs, in particular LDCs, LLDCs and SIDS, in international discussions concerning AI governance. This can be through the provision of funds, ensuring equal regional participation, or any other mechanisms. Furthermore, in order to ensure the inclusiveness of AI fora, Member States should facilitate the travel of AI actors in and out of their territory, especially from LMICs, in particular LDCs, LLDCs and SIDS, for the purpose of participating in these fora. 61. Amendments to the existing or elaboration of new national legislation addressing AI systems must comply with Member States' human rights law obligations and promote human rights and fundamental freedoms throughout the AI system life cycle. Promotion thereof should also take the form of governance initiatives, good exemplars of collaborative practices regarding AI systems, and national and international technical and methodological guidelines as AI technologies advance. Diverse sectors, including the private sector, in their practices regarding AI systems must respect, protect and promote human rights and fundamental freedoms using existing and new instruments in combination with this Recommendation. 62. Member States that acquire Al systems for human rights-sensitive use cases, such as law enforcement, welfare, employment, media and information providers, health care and the independent judiciary system should provide mechanisms to monitor the social and economic impact of such systems by appropriate oversight authorities, including independent data protection authorities, sectoral oversight and public bodies responsible for oversight. 63. Member States should enhance the capacity of the judiciary to make decisions related to AI systems as per the rule of law and in line with international law and standards, including in the use of AI systems in their deliberations, while ensuring that the principle of human oversight is upheld. In case AI systems are used by the judiciary, sufficient safeguards are needed to guarantee inter alia the protection of fundamental human rights, the rule of law, judicial independence as well as the principle of human oversight, and to ensure a trustworthy, public interest-oriented and human-centric development and use of AI systems in the judiciary. 64. Member States should ensure that governments and multilateral organizations play a leading role in ensuring the safety and security of AI systems, with multi-stakeholder participation. Specifically, Member States, international organizations and other relevant bodies should develop international standards that describe measurable, testable levels of safety and transparency, so that systems can be objectively assessed and levels of compliance determined. Furthermore, Member States and business enterprises should continuously support strategic research on potential safety and security risks of AI technologies and should encourage research into transparency and explainability, inclusion and literacy by putting additional funding into those areas for different domains and at different levels, such as technical and natural language. 65. Member States should implement policies to ensure that the actions of AI actors are consistent with international human rights law, standards and principles throughout the life cycle of AI systems, while taking into full consideration the current cultural and social diversities, including local customs and religious traditions, with due regard to the precedence and universality of human rights. 66. Member States should put in place mechanisms to require AI actors to disclose and combat any kind of stereotyping in the outcomes of AI systems and data, whether by design or by negligence, and to ensure that training data sets for AI systems do not foster cultural, economic or social inequalities, prejudice, the spreading of disinformation and misinformation, and disruption of freedom of expression and access to information. Particular attention should be given to regions where the data are scarce. 67. Member States should implement policies to promote and increase diversity and inclusiveness that reflect their populations in AI development teams and training datasets, and to ensure equal access to AI technologies and their benefits, particularly for marginalized groups, both from rural and urban zones. 68. Member States should develop, review and adapt, as appropriate, regulatory frameworks to achieve accountability and responsibility for the content and outcomes of AI systems at the different phases of their life cycle. Member States should, where necessary, introduce liability frameworks or clarify the interpretation of existing frameworks to ensure the attribution of accountability for the outcomes and the functioning of AI systems. Furthermore, when developing regulatory frameworks, Member States should, in particular, take into account that ultimate responsibility and accountability must always lie with natural or legal persons and that AI systems should not be given legal personality themselves. To ensure this, such regulatory frameworks should be consistent with the principle of human oversight and establish a comprehensive approach focused on AI actors and the technological processes involved across the different stages of the AI system life cycle. 69. In order to establish norms where these do not exist, or to adapt the existing legal frameworks, Member States should involve all AI actors (including, but not limited to, researchers, representatives of civil society and law enforcement, insurers, investors, manufacturers, engineers, lawyers and users). The norms can mature into best practices, laws and regulations. Member States are further encouraged to use mechanisms such as policy prototypes and regulatory sandboxes to accelerate the development of laws, regulations and policies, including regular reviews thereof, in line with the rapid development of new technologies and ensure that laws and regulations can be tested in a safe environment before being officially adopted. Member States should support local governments in the development of local policies, regulations and laws in line with national and international legal frameworks. 70. Member States should set clear requirements for AI system transparency and explainability so as to help ensure the trustworthiness of the full AI system life cycle. Such requirements should involve the design and implementation of impact mechanisms that take into consideration the nature of application domain, intended use, target audience and feasibility of each particular AI system. POLICY AREA 3: DATA POLICY 71. Member States should work to develop data governance strategies that ensure the continual evaluation of the quality of training data for AI systems including the adequacy of the data collection and selection processes, proper data security and protection measures, as well as feedback mechanisms to learn from mistakes and share best practices among all AI actors. 72. Member States should put in place appropriate safeguards to protect the right to privacy in accordance with international law, including addressing concerns such as surveillance. Member States should, among others, adopt or enforce legislative frameworks that provide appropriate protection, compliant with international law. Member States should strongly encourage all AI actors, including business enterprises, to follow existing international standards and, in particular, to carry out adequate privacy impact assessments, as part of ethical impact assessments, which take into account the wider socio-economic impact of the intended data processing, and to apply privacy by design in their systems. Privacy should be respected, protected and promoted throughout the life cycle of AI systems. 73. Member States should ensure that individuals retain rights over their personal data and are protected by a framework, which notably foresees: transparency; appropriate safeguards for the processing of sensitive data; an appropriate level of data protection; effective and meaningful accountability schemes and mechanisms; the full enjoyment of the data subjects' rights and the ability to access and erase their personal data in AI systems, except for certain circumstances in compliance with international law; an appropriate level of protection in full compliance with data protection legislation where data are being used for commercial purposes such as enabling micro-targeted advertising, transferred cross-border; and an effective independent oversight as part of a data governance mechanism which keeps individuals in control of their personal data and fosters the benefits of a free flow of information internationally, including access to data. 74. Member States should establish their data policies or equivalent frameworks, or reinforce existing ones, to ensure full security for personal data and sensitive data, which, if disclosed, may cause exceptional damage, injury or hardship to individuals. Examples include data relating to offences, criminal proceedings and convictions, and related security measures; biometric, genetic and health data; and personal data such as that relating to race, colour, descent, gender, age, language, religion, political opinion, national origin, ethnic origin, social origin, economic or social condition of birth, or disability and any other characteristics. 75. Member States should promote open data. In this regard, Member States should consider reviewing their policies and regulatory frameworks, including on access to information and open government to reflect AI-specific requirements and promoting mechanisms, such as open repositories for publicly funded or publicly held data and source code and data trusts, to support the safe, fair, legal and ethical sharing of data, among others. 76. Member States should promote and facilitate the use of quality and robust datasets for training, development and use of AI systems, and exercise vigilance in overseeing their collection and use. This could, if possible and feasible, include investing in the creation of gold standard datasets, including open and trustworthy datasets, which are diverse, constructed on a valid legal basis, including consent of data subjects, when required by law. Standards for annotating datasets should be encouraged, including disaggregating data on gender and other bases, so it can easily be determined how a dataset is gathered and what properties it has. 77. Member States, as also suggested in the report of the United Nations Secretary-General's High-level Panel on Digital Cooperation, with the support of the United Nations and UNESCO, should adopt a digital commons approach to data where appropriate, increase interoperability of tools and datasets and interfaces of systems hosting data, and encourage private sector companies to share the data they collect with all stakeholders, as appropriate, for research, innovation or public benefits. They should also promote public and private efforts to create collaborative platforms to share quality data in trusted and secured data spaces. POLICY AREA 4: DEVELOPMENT AND INTERNATIONAL COOPERATION 78. Member States and transnational corporations should prioritize AI ethics by including discussions of AI-related ethical issues into relevant international, intergovernmental and multi-stakeholder fora. 79. Member States should ensure that the use of AI in areas of development such as education, science, culture, communication and information, health care, agriculture and food supply, environment, natural resource and infrastructure management, economic planning and growth, among others, adheres to the values and principles set forth in this Recommendation. 80. Member States should work through international organizations to provide platforms for international cooperation on AI for development, including by contributing expertise, funding, data, domain knowledge, infrastructure, and facilitating multi-stakeholder collaboration to tackle challenging development problems, especially for LMICs, in particular LDCs, LLDCs and SIDS. 81. Member States should work to promote international collaboration on AI research and innovation, including research and innovation centres and networks that promote greater participation and leadership of researchers from LMICs and other countries, including LDCs, LLDCs and SIDS. 82. Member States should promote AI ethics research by engaging international organizations and research institutions, as well as transnational corporations, that can be a basis for the ethical use of AI systems by public and private entities, including research into the applicability of specific ethical frameworks in specific cultures and contexts, and the possibilities to develop technologically feasible solutions in line with these frameworks. 83. Member States should encourage international cooperation and collaboration in the field of AI to bridge geo-technological lines. Technological exchanges and consultations should take place between Member States and their populations, between the public and private sectors, and between and among the most and least technologically advanced countries in full respect of international law. POLICY AREA 5: ENVIRONMENT AND ECOSYSTEMS 84. Member States and business enterprises should assess the direct and indirect environmental impact throughout the AI system life cycle, including, but not limited to, its carbon footprint, energy consumption and the environmental impact of raw material extraction for supporting the manufacturing of AI technologies, and reduce the environmental impact of AI systems and data infrastructures. Member States should ensure compliance of all AI actors with environmental law, policies and practices. 85. Member States should introduce incentives, when needed and appropriate, to ensure the development and adoption of rights-based and ethical AI-powered solutions for disaster risk resilience; the monitoring, protection and regeneration of the environment and ecosystems; and the preservation of the planet. These AI systems should involve the participation of local and indigenous communities throughout the life cycle of AI systems and should support circular economy type approaches and sustainable consumption and production patterns. Some examples include using AI systems, when needed and appropriate, to: (a) Support the protection, monitoring and management of natural resources. (b) Support the prediction, prevention, control and mitigation of climate-related problems. (c) Support a more efficient and sustainable food ecosystem. (d) Support the acceleration of access to and mass adoption of sustainable energy. (e) Enable and promote the mainstreaming of sustainable infrastructure, sustainable business models and sustainable finance for sustainable development. (f) Detect pollutants or predict levels of pollution and thus help relevant stakeholders identify, plan and put in place targeted interventions to prevent and reduce pollution and exposure. 86. When choosing AI methods, given the potential data-intensive or resource-intensive character of some of them and the respective impact on the environment, Member States should ensure that AI actors, in line with the principle of proportionality, favour data, energy and resource-efficient AI methods. Requirements should be developed to ensure that appropriate evidence is available to show that an AI application will have the intended effect, or that safeguards accompanying an AI application can support the justification for its use. If this cannot be done, the precautionary principle must be favoured, and in instances where there are disproportionate negative impacts on the environment, AI should not be used. POLICY AREA 6: GENDER 87. Member States should ensure that the potential for digital technologies and artificial intelligence to contribute to achieving gender equality is fully maximized, and must ensure that the human rights and fundamental freedoms of girls and women, and their safety and integrity are not violated at any stage of the AI system life cycle. Moreover, Ethical Impact Assessment should include a transversal gender perspective. 88. Member States should have dedicated funds from their public budgets linked to financing gender-responsive schemes, ensure that national digital policies include a gender action plan, and develop relevant policies, for example, on labour education, targeted at supporting girls and women to make sure they are not left out of the digital economy powered by AI. Special investment in providing targeted programmes and gender-specific language, to increase the opportunities of girls' and women's participation in science, technology, engineering, and mathematics (STEM), including information and communication technologies (ICT) disciplines, preparedness, employability, equal career development and professional growth of girls and women, should be considered and implemented. 89. Member States should ensure that the potential of AI systems to advance the achievement of gender equality is realized. They should ensure that these technologies do not exacerbate the already wide gender gaps existing in several fields in the analogue world, and instead eliminate those gaps. These gaps include: the gender wage gap; the unequal representation in certain professions and activities; the lack of representation at top management positions, boards of directors, or research teams in the AI field; the education gap; the digital and AI access, adoption, usage and affordability gap; and the unequal distribution of unpaid work and of the caring responsibilities in our societies. 90. Member States should ensure that gender stereotyping and discriminatory biases are not translated into AI systems, and instead identify and proactively redress these. Efforts are necessary to avoid the compounding negative effect of technological divides in achieving gender equality and avoiding violence such as harassment, bullying or trafficking of girls and women and under-represented groups, including in the online domain. 91. Member States should encourage female entrepreneurship, participation and engagement in all stages of an AI system life cycle by offering and promoting economic, regulatory incentives, among other incentives and support schemes, as well as policies that aim at a balanced gender participation in AI research in academia, gender representation on digital and AI companies' top management positions, boards of directors and research teams. Member States should ensure that public funds (for innovation, research and technologies) are channelled to inclusive programmes and companies, with clear gender representation, and that private funds are similarly encouraged through affirmative action principles. Policies on harassment-free environments should be developed and enforced, together with the encouragement of the transfer of best practices on how to promote diversity throughout the AI system life cycle. 92. Member States should promote gender diversity in AI research in academia and industry by offering incentives to girls and women to enter the field, putting in place mechanisms to fight gender stereotyping and harassment within the AI research community, and encouraging academic and private entities to share best practices on how to enhance gender diversity. 93. UNESCO can help form a repository of best practices for incentivizing the participation of girls, women and under-represented groups in all stages of the AI system life cycle. POLICY AREA 7: CULTURE 94. Member States are encouraged to incorporate AI systems, where appropriate, in the preservation, enrichment, understanding, promotion, management and accessibility of tangible, documentary and intangible cultural heritage, including endangered languages as well as indigenous languages and knowledges, for example by introducing or updating educational programmes related to the application of AI systems in these areas, where appropriate, and by ensuring a participatory approach, targeted at institutions and the public. 95. Member States are encouraged to examine and address the cultural impact of AI systems, especially natural language processing (NLP) applications such as automated translation and voice assistants, on the nuances of human language and expression. Such assessments should provide input for the design and implementation of strategies that maximize the benefits from these systems by bridging cultural gaps and increasing human understanding, as well as addressing the negative implications such as the reduction of use, which could lead to the disappearance of endangered languages, local dialects, and tonal and cultural variations associated with human language and expression. 96. Member States should promote AI education and digital training for artists and creative professionals to assess the suitability of AI technologies for use in their profession, and contribute to the design and implementation of suitable AI technologies, as AI technologies are being used to create, produce, distribute, broadcast and consume a variety of cultural goods and services, bearing in mind the importance of preserving cultural heritage, diversity and artistic freedom. 97. Member States should promote awareness and evaluation of AI tools among local cultural industries and small and medium enterprises working in the field of culture, to avoid the risk of concentration in the cultural market. 98. Member States should engage technology companies and other stakeholders to promote a diverse supply of and plural access to cultural expressions, and in particular to ensure that algorithmic recommendation enhances the visibility and discoverability of local content. 99. Member States should foster new research at the intersection between AI and intellectual property (IP), for example to determine whether or how to protect with IP rights the works created by means of Al technologies. Member States should also assess how AI technologies are affecting the rights or interests of IP owners, whose works are used to research, develop, train or implement AI applications. 100. Member States should encourage museums, galleries, libraries and archives at the national level to use AI systems to highlight their collections and enhance their libraries, databases and knowledge base, while also providing access to their users. POLICY AREA 8: EDUCATION AND RESEARCH 101. Member States should work with international organizations, educational institutions and private and non-governmental entities to provide adequate AI literacy education to the public on all levels in all countries in order to empower people and reduce the digital divides and digital access inequalities resulting from the wide adoption of AI systems. 102. Member States should promote the acquisition of 'prerequisite skills' for AI education, such as basic literacy, numeracy, coding and digital skills, and media and information literacy, as well as critical and creative thinking, teamwork, communication, socio-emotional and AI ethics skills, especially in countries and in regions or areas within countries where there are notable gaps in the education of these skills. 103. Member States should promote general awareness programmes about AI developments, including on data and the opportunities and challenges brought about by AI technologies, the impact of AI systems on human rights and their implications, including children's rights. These programmes should be accessible to non-technical as well as technical groups. 104. Member States should encourage research initiatives on the responsible and ethical use of AI technologies in teaching, teacher training and e-learning, among other issues, to enhance opportunities and mitigate the challenges and risks involved in this area. The initiatives should be accompanied by an adequate assessment of the quality of education and impact on students and teachers of the use of AI technologies. Member States should also ensure that AI technologies empower students and teachers and enhance their experience, bearing in mind that relational and social aspects and the value of traditional forms of education are vital in teacher-student and student-student relationships and should be considered when discussing the adoption of AI technologies in education. AI systems used in learning should be subject to strict requirements when it comes to the monitoring, assessment of abilities, or prediction of the learners' behaviours. AI should support the learning process without reducing cognitive abilities and without extracting sensitive information, in compliance with relevant personal data protection standards. The data handed over to acquire knowledge collected during the learner's interactions with the AI system must not be subject to misuse, misappropriation or criminal exploitation, including for commercial purposes. 105. Member States should promote the participation and leadership of girls and women, diverse ethnicities and cultures, persons with disabilities, marginalized and vulnerable people or people in vulnerable situations, minorities and all persons not enjoying the full benefits of digital inclusion, in AI education programmes at all levels, as well as the monitoring and sharing of best practices in this regard with other Member States. 106. Member States should develop, in accordance with their national education programmes and traditions, AI ethics curricula for all levels, and promote cross-collaboration between AI technical skills education and humanistic, ethical and social aspects of AI education. Online courses and digital resources of AI ethics education should be developed in local languages, including indigenous languages, and take into account the diversity of environments, especially ensuring accessibility of formats for persons with disabilities. 107. Member States should promote and support AI research, notably AI ethics research, including for example through investing in such research or by creating incentives for the public and private sectors to invest in this area, recognizing that research contributes significantly to the further development and improvement of AI technologies with a view to promoting international law and the values and principles set forth in this Recommendation. Member States should also publicly promote the best practices of, and cooperation with, researchers and companies who develop AI in an ethical manner. 108. Member States should ensure that AI researchers are trained in research ethics and require them to include ethical considerations in their designs, products and publications, especially in the analyses of the datasets they use, how they are annotated, and the quality and scope of the results with possible applications. Member States should encourage private sector companies to facilitate the access of the scientific community to their data for research, especially in LMICs, in particular LDCs, LLDCs and SIDS. This access should conform to relevant privacy and data protection standards. 110. To ensure a critical evaluation of AI research and proper monitoring of potential misuses or adverse effects, Member States should ensure that any future developments with regards to AI technologies should be based on rigorous and independent scientific research, and promote interdisciplinary AI research by including disciplines other than science, technology, engineering and mathematics (STEM), such as cultural studies, education, ethics, international relations, law, linguistics, philosophy, political science, sociology and psychology. 111. Recognizing that AI technologies present great opportunities to help advance scientific knowledge and practice, especially in traditionally model-driven disciplines, Member States should encourage scientific communities to be aware of the benefits, limits and risks of their use; this includes attempting to ensure that conclusions drawn from data-driven approaches, models and treatments are robust and sound. Furthermore, Member States should welcome and support the role of the scientific community in contributing to policy and in cultivating awareness of the strengths and weaknesses of AI technologies. POLICY AREA 9: COMMUNICATION AND INFORMATION 112. Member States should use AI systems to improve access to information and knowledge. This can include support to researchers, academia, journalists, the general public and developers, to enhance freedom of expression, academic and scientific freedoms, access to information, and increased proactive disclosure of official data and information. 113. Member States should ensure that AI actors respect and promote freedom of expression as well as access to information with regard to automated content generation, moderation and curation. Appropriate frameworks, including regulation, should enable transparency of online communication and information operators and ensure users have access to a diversity of viewpoints, as well as processes for prompt notification to the users on the reasons for removal or other treatment of content, and appeal mechanisms that allow users to seek redress. 114. Member States should invest in and promote digital and media and information literacy skills to strengthen critical thinking and competencies needed to understand the use and implication of AI systems, in order to mitigate and counter disinformation, misinformation and hate speech. A better understanding and evaluation of both the positive and potentially harmful effects of recommender systems should be part of those efforts. 115. Member States should create enabling environments for media to have the rights and resources to effectively report on the benefits and harms of AI systems, and also encourage media to make ethical use of AI systems in their operations. POLICY AREA 10: ECONOMY AND LABOUR 116. Member States should assess and address the impact of AI systems on labour markets and its implications for education requirements, in all countries and with special emphasis on countries where the economy is labour-intensive. This can include the introduction of a wider range of 'core' and interdisciplinary skills at all education levels to provide current workers and new generations a fair chance of finding jobs in a rapidly changing market, and to ensure their awareness of the ethical aspects of AI systems. Skills such as 'learning how to learn', communication, critical thinking, teamwork, empathy, and the ability to transfer one's knowledge across domains, should be taught alongside specialist, technical skills, as well as low-skilled tasks. Being transparent about what skills are in demand and updating curricula around these are key. 117. Member States should support collaboration agreements among governments, academic institutions, vocational education and training institutions, industry, workers' organizations and civil society to bridge the gap of skillset requirements to align training programmes and strategies with the implications of the future of work and the needs of industry, including small and medium enterprises. Project-based teaching and learning approaches for AI should be promoted, allowing for partnerships between public institutions, private sector companies, universities and research centres. 118. Member States should work with private sector companies, civil society organizations and other stakeholders, including workers and unions to ensure a fair transition for at-risk employees. This includes putting in place upskilling and reskilling programmes, finding effective mechanisms of retaining employees during those transition periods, and exploring 'safety net' programmes for those who cannot be retrained. Member States should develop and implement programmes to research and address the challenges identified that could include upskilling and reskilling, enhanced social protection, proactive industry policies and interventions, tax benefits, new taxation forms, among others. Member States should ensure that there is sufficient public funding to support these programmes. Relevant regulations, such as tax regimes, should be carefully examined and changed if needed to counteract the consequences of unemployment caused by AI-based automation. 119. Member States should encourage and support researchers to analyze the impact of AI systems on the local labour environment in order to anticipate future trends and challenges. These studies should have an interdisciplinary approach and investigate the impact of AI systems on economic, social and geographic sectors, as well as on human-robot interactions and human-human relationships, in order to advise on reskilling and redeployment best practices. 120. Member States should take appropriate steps to ensure competitive markets and consumer protection, considering possible measures and mechanisms at national, regional and international levels, to prevent abuse of dominant market positions, including by monopolies, in relation to AI systems throughout their life cycle, whether these are data, research, technology, or market. Member States should prevent the resulting inequalities, assess relevant markets and promote competitive markets. Due consideration should be given to LMICs, in particular LDCs, LLDCs and SIDS, which are more exposed and vulnerable to the possibility of abuses of market dominance as a result of a lack of infrastructure, human capacity and regulations, among other factors. AI actors developing AI systems in countries which have established or adopted ethical standards on AI should respect these standards when exporting these products, developing or applying their AI systems in countries where such standards may not exist, while respecting applicable international law and domestic legislation, standards and practices of these countries. POLICY AREA 11: HEALTH AND SOCIAL WELL-BEING 121. Member States should endeavour to employ effective AI systems for improving human health and protecting the right to life, including mitigating disease outbreaks, while building and maintaining international solidarity to tackle global health risks and uncertainties, and ensure that their deployment of AI systems in health care be consistent with international law and their human rights law obligations. Member States should ensure that actors involved in health care AI systems take into consideration the importance of a patient's relationships with their family and with health care staff. 122. Member States should ensure that the development and deployment of AI systems related to health in general and mental health in particular, paying due attention to children and youth, is regulated to the effect that they are safe, effective, efficient, scientifically and medically proven and enable evidence-based innovation and medical progress. Moreover, in the related area of digital health interventions, Member States are strongly encouraged to actively involve patients and their representatives in all relevant steps of the development of the system. (a) ensuring oversight to minimize and mitigate bias; (b) ensuring that the professional, the patient, caregiver or service user is included as a 'domain expert' in the team in all relevant steps when developing the algorithms; (c) paying due attention to privacy because of the potential need for being medically monitored and ensuring that all relevant national and international data protection requirements are met; (d) ensuring effective mechanisms so that those whose personal data is being analysed are aware of and provide informed consent for the use and analysis of their data, without preventing access to health care; (e) ensuring the human care and final decision of diagnosis and treatment are taken always by humans while acknowledging that AI systems can also assist in their work; (f) ensuring, where necessary, the review of AI systems by an ethical research committee prior to clinical use. 124. Member States should establish research on the effects and regulation of potential harms to mental health related to AI systems, such as higher degrees of depression, anxiety, social isolation, developing addiction, trafficking, radicalization and misinformation, among others. 125. Member States should develop guidelines for human-robot interactions and their impact on human-human relationships, based on research and directed at the future development of robots, and with special attention to the mental and physical health of human beings. Particular attention should be given to the use of robots in health care and the care for older persons and persons with disabilities, in education, and robots for use by children, toy robots, chatbots and companion robots for children and adults. Furthermore, assistance of AI technologies should be applied to increase the safety and ergonomic use of robots, including in a human-robot working environment. Special attention should be paid to the possibility of using AI to manipulate and abuse human cognitive biases. 126. Member States should ensure that human-robot interactions comply with the same values and principles that apply to any other AI systems, including human rights and fundamental freedoms, the promotion of diversity, and the protection of vulnerable people or people in vulnerable situations. Ethical questions related to AI-powered systems for neurotechnologies and brain-computer interfaces should be considered in order to preserve human dignity and autonomy. 127. Member States should ensure that users can easily identify whether they are interacting with a living being, or with an AI system imitating human or animal characteristics, and can effectively refuse such interaction and request human intervention. 128. Member States should implement policies to raise awareness about the anthropomorphization of AI technologies and technologies that recognize and mimic human emotions, including in the language used to mention them, and assess the manifestations, ethical implications and possible limitations of such anthropomorphization, in particular in the context of robot-human interaction and especially when children are involved. 129. Member States should encourage and promote collaborative research into the effects of long-term interaction of people with AI systems, paying particular attention to the psychological and cognitive impact that these systems can have on children and young people. This should be done using multiple norms, principles, protocols, disciplinary approaches, and assessment of the modification of behaviours and habits, as well as careful evaluation of the downstream cultural and societal impacts. Furthermore, Member States should encourage research on the effect of AI technologies on health system performance and health outcomes. 130. Member States, as well as all stakeholders, should put in place mechanisms to meaningfully engage children and young people in conversations, debates and decision-making with regard to the impact of AI systems on their lives and futures. V. MONITORING AND EVALUATION Member States should, according to their specific conditions, governing structures and constitutional provisions, credibly and transparently monitor and evaluate policies, programmes and mechanisms related to ethics of AI, using a combination of quantitative and qualitative approaches. To support Member States, UNESCO can contribute by: (a) developing a UNESCO methodology for Ethical Impact Assessment (EIA) of AI technologies based on rigorous scientific research and grounded in international human rights law, guidance for its implementation in all stages of the AI system life cycle, and capacity-building materials to support Member States' efforts to train government officials, policy-makers and other relevant AI actors on EIA methodology; (b) developing a UNESCO readiness assessment methodology to assist Member States in identifying their status at specific moments of their readiness trajectory along a continuum of dimensions; (c) developing a UNESCO methodology to evaluate ex ante and ex post the effectiveness and efficiency of the policies for AI ethics and incentives against defined objectives; (d) strengthening the research- and evidence-based analysis of and reporting on policies regarding AI ethics; (e) collecting and disseminating progress, innovations, research reports, scientific publications, data and statistics regarding policies for AI ethics, including through existing initiatives, to support sharing best practices and mutual learning, and to advance the implementation of this Recommendation. 132. Processes for monitoring and evaluation should ensure broad participation of all stakeholders, including, but not limited to, vulnerable people or people in vulnerable situations. Social, cultural and gender diversity should be ensured, with a view to improving learning processes and strengthening the connections between findings, decision-making, transparency and accountability for results. 133. In the interests of promoting best policies and practices related to ethics of AI, appropriate tools and indicators should be developed for assessing the effectiveness and efficiency thereof against agreed standards, priorities and targets, including specific targets for persons belonging to disadvantaged, marginalized populations, and vulnerable people or people in vulnerable situations, as well as the impact of AI systems at individual and societal levels. The monitoring and assessment of the impact of AI systems and related AI ethics policies and practices should be carried out continuously in a systematic way proportionate to the relevant risks. This should be based on internationally agreed frameworks and involve evaluations of private and public institutions, providers and programmes, including self-evaluations, as well as tracer studies and the development of sets of indicators. Data collection and processing should be conducted in accordance with international law, national legislation on data protection and data privacy, and the values and principles outlined in this Recommendation. 134. In particular, Member States may wish to consider possible mechanisms for monitoring and evaluation, such as an ethics commission, AI ethics observatory, repository covering human rights-compliant and ethical development of AI systems, or contributions to existing initiatives by addressing adherence to ethical principles across UNESCO's areas of competence, an experience-sharing mechanism, AI regulatory sandboxes, and an assessment guide for all AI actors to evaluate their adherence to policy recommendations mentioned in this document. VI. UTILIZATION AND EXPLOITATION OF THE PRESENT RECOMMENDATION 135. Member States and all other stakeholders as identified in this Recommendation should respect, promote and protect the ethical values, principles and standards regarding AI that are identified in this Recommendation, and should take all feasible steps to give effect to its policy recommendations. 136. Member States should strive to extend and complement their own action in respect of this Recommendation, by cooperating with all relevant national and international governmental and non-governmental organizations, as well as transnational corporations and scientific organizations, whose activities fall within the scope and objectives of this Recommendation. The development of a UNESCO Ethical Impact Assessment methodology and the establishment of national commissions for the ethics of AI can be important instruments for this. VII. PROMOTION OF THE PRESENT RECOMMENDATION 137. UNESCO has the vocation to be the principal United Nations agency to promote and disseminate this Recommendation, and accordingly will work in collaboration with other relevant United Nations entities, while respecting their mandate and avoiding duplication of work. 138. UNESCO, including its bodies, such as the World Commission on the Ethics of Scientific Knowledge and Technology (COMEST), the International Bioethics Committee (IBC) and the Intergovernmental Bioethics Committee (IGBC), will also work in collaboration with other international, regional and sub-regional governmental and non-governmental organizations. 139. Even though, within UNESCO, the mandate to promote and protect falls within the authority of governments and intergovernmental bodies, civil society will be an important actor to advocate for the public sector's interests and therefore UNESCO needs to ensure and promote its legitimacy. VIII. FINAL PROVISIONS 140. This Recommendation needs to be understood as a whole, and the foundational values and principles are to be understood as complementary and interrelated. 141. Nothing in this Recommendation may be interpreted as replacing, altering or otherwise prejudicing States' obligations or rights under international law, or as approval for any State, other political, economic or social actor, group or person to engage in any activity or perform any act contrary to human rights, fundamental freedoms, human dignity and concern for the environment and ecosystems, both living and non-living.",
      "word_count": 14221,
      "character_count": 98081,
      "vector": [
        0.16211305558681488,
        -0.16529954969882965,
        0.1467221975326538,
        0.005471324548125267,
        0.044936299324035645,
        -0.09976325184106827,
        0.01854698918759823,
        0.01993526518344879,
        -0.01180228777229786,
        0.03805787116289139,
        0.04396674409508705,
        0.1182127371430397,
        0.016569944098591805,
        -0.036636319011449814,
        0.09535180032253265,
        -0.01864650472998619,
        -0.07026398181915283,
        0.024200430139899254,
        -0.03348936513066292,
        -0.12291383743286133,
        0.02010989934206009,
        -0.07190226018428802,
        0.0852275863289833,
        0.14412543177604675,
        -0.09099229425191879,
        0.04639130458235741,
        -0.022086139768362045,
        0.014159834943711758,
        0.005561536177992821,
        -0.0015326956054195762,
        0.054475780576467514,
        -0.0888606607913971,
        0.03722936660051346,
        -0.08723393827676773,
        0.014498970471322536,
        0.021904876455664635,
        0.07580415904521942,
        -0.00927355233579874,
        0.015202664770185947,
        -0.031100058928132057,
        -0.01455644704401493,
        -0.04076609015464783,
        0.0486917681992054,
        -0.054844122380018234,
        0.051990676671266556,
        0.07512550055980682,
        0.05022720620036125,
        0.007002522237598896,
        -0.06124744564294815,
        -0.0412457212805748,
        0.08930008113384247,
        0.08305421471595764,
        -0.07409791648387909,
        0.05954468995332718,
        0.019877245649695396,
        0.03711490333080292,
        0.04537848010659218,
        -0.02523154392838478,
        -0.0725754126906395,
        -0.03293277695775032,
        -0.06534929573535919,
        0.04344021901488304,
        -0.039971109479665756,
        -0.024214811623096466,
        -0.020854882895946503,
        0.07797250151634216,
        -0.036858368664979935,
        -0.046936746686697006,
        -0.006051164120435715,
        -0.01831009052693844,
        -0.03930381312966347,
        0.011473922990262508,
        -0.03215213865041733,
        -0.014486781321465969,
        0.005754963494837284,
        0.04172884672880173,
        -0.021027222275733948,
        0.06184321269392967,
        -0.009985278360545635,
        0.03161144256591797,
        0.11204785853624344,
        0.048896338790655136,
        0.03715937212109566,
        -0.0177029836922884,
        0.03407344967126846,
        0.036335911601781845,
        -0.07764866948127747,
        0.010132682509720325,
        0.003736189566552639,
        -0.04069928824901581,
        0.004880476742982864,
        -0.05974933132529259,
        -0.06078529730439186,
        -0.03996628522872925,
        0.09353075176477432,
        0.01728195883333683,
        -0.017353588715195656,
        0.018340805545449257,
        -0.032172612845897675,
        0.0031432711984962225,
        -0.07081104815006256,
        0.032467473298311234,
        -0.08196312934160233,
        0.046830203384160995,
        0.00875740498304367,
        0.04499443247914314,
        -0.004067684058099985,
        -0.0171835757791996,
        -0.08258114755153656,
        -0.013559192419052124,
        -0.019296051934361458,
        0.017753487452864647,
        0.018455008044838905,
        -0.004676508251577616,
        0.03845863416790962,
        0.04574727267026901,
        -0.022275712341070175,
        0.07662107050418854,
        0.049264635890722275,
        -0.039080992341041565,
        0.022844413295388222,
        -0.04408451169729233,
        -0.021078014746308327,
        -0.005674166604876518,
        0.01089099608361721,
        -0.04238121584057808,
        -0.06849923729896545,
        0.042448390275239944,
        0.011270244605839252,
        -0.06407057493925095,
        0.0029460114892572165,
        0.03591514006257057,
        -0.060018789023160934,
        -0.013191151432693005,
        0.0038463554810732603,
        0.008065102621912956,
        0.004252484999597073,
        -0.03970073163509369,
        -0.00034076382871717215,
        0.01554707158356905,
        0.0007233676733449101,
        0.0077889952808618546,
        -0.04912032559514046,
        0.022453565150499344,
        0.006804645527154207,
        -0.03989725559949875,
        -0.013290666043758392,
        -0.0008618474821560085,
        0.003447420196607709,
        0.053201135247945786,
        0.054179612547159195,
        0.019322967156767845,
        -0.0004085769469384104,
        -0.005817704368382692,
        0.044961247593164444,
        0.011383737437427044,
        0.03426409512758255,
        0.017581356689333916,
        0.009903394617140293,
        0.012651355005800724,
        -0.006251518148928881,
        0.01480571273714304,
        -0.006569101009517908,
        -0.02958858013153076,
        -0.053197700530290604,
        -0.004960955586284399,
        -0.022270048037171364,
        0.021685652434825897,
        -0.014765298925340176,
        -0.01031161192804575,
        -0.04278029873967171,
        0.049217380583286285,
        0.024318363517522812,
        -0.036936599761247635,
        -0.05234123393893242,
        0.006855400744825602,
        0.01377709861844778,
        0.09025449305772781,
        0.018680771812796593,
        0.06597752869129181,
        0.02009017951786518,
        -0.024154039099812508,
        -0.030064987018704414,
        0.048941172659397125,
        -0.10536041110754013,
        -0.011237558908760548,
        0.015646763145923615,
        -0.009336012415587902,
        0.020841121673583984,
        -0.013344606384634972,
        -0.01267519872635603,
        -0.002753159264102578,
        0.05871415510773659,
        0.05716025456786156,
        -0.026814768090844154,
        0.017752142623066902,
        -0.03445141389966011,
        0.012548449449241161,
        -0.014723621308803558,
        -0.03501828387379646,
        -0.020033877342939377,
        -0.01724988967180252,
        9.819306796998717e-06,
        0.029118573293089867,
        -0.03309982270002365,
        0.032005488872528076,
        -0.01750478893518448,
        0.005927617661654949,
        -0.03534818813204765,
        0.020434843376278877,
        0.011689595878124237,
        0.020553309470415115,
        0.007225935347378254,
        -0.0026225619949400425,
        -0.06295284628868103,
        -0.026569658890366554,
        0.05451270937919617,
        0.04642069339752197,
        0.01248034369200468,
        -0.0047407676465809345,
        0.005325430538505316,
        0.0021464673336595297,
        0.006918096449226141,
        -0.01049262098968029,
        -0.020924130454659462,
        -0.00312568387016654,
        -0.010771519504487514,
        0.04330138489603996,
        -0.018098048865795135,
        0.03329896181821823,
        0.021059906110167503,
        0.0058110482059419155,
        0.003911599982529879,
        0.02269815281033516,
        0.04634784162044525,
        -0.0248444601893425,
        -0.0175513606518507,
        0.03680309280753136,
        0.08047047257423401,
        -0.006672397721558809,
        -0.05958613008260727,
        -0.034674305468797684,
        -0.034244146198034286,
        -0.0025150764267891645,
        -0.07242673635482788,
        -0.00901698786765337,
        -0.047324713319540024,
        -0.03313859552145004,
        -0.0365765281021595,
        -0.010778283700346947,
        0.0019157800124958158,
        -0.005410762969404459,
        -0.0460648238658905,
        -0.0312647670507431,
        0.03440430760383606,
        -0.021661624312400818,
        -0.0053043668158352375,
        -0.008051018230617046,
        -0.02481032721698284,
        0.01844128966331482,
        -0.03399616852402687,
        -0.017020029947161674,
        -0.017055043950676918,
        -0.0033256083261221647,
        0.02907511405646801,
        -0.015980608761310577,
        -0.0009982840856537223,
        -0.014601651579141617,
        0.007693637162446976,
        -0.036776524037122726,
        0.00309632602147758,
        -0.005232710856944323,
        -0.0006312771583907306,
        0.0633121132850647,
        0.017376095056533813,
        0.04049229621887207,
        -0.023346131667494774,
        0.02161138691008091,
        0.02358180098235607,
        -0.025408117100596428,
        -0.05300881713628769,
        -0.003748734947293997,
        0.015960372984409332,
        0.007085824850946665,
        -0.030741475522518158,
        -0.020823076367378235,
        -0.003701139474287629,
        0.015617704018950462,
        0.0056303078308701515,
        -0.004035678692162037,
        0.010386927984654903,
        -0.015894943848252296,
        -0.0016864801291376352,
        0.026564976200461388,
        0.007652435917407274,
        0.010231715627014637,
        -0.08614302426576614,
        0.0027983093168586493,
        0.04182066768407822,
        0.02167503722012043,
        -0.013843489810824394,
        0.018511518836021423,
        0.039569247514009476,
        0.029743386432528496,
        -0.008437679149210453,
        -0.01265503466129303,
        0.006772850640118122,
        -0.04934283345937729,
        -0.022814229130744934,
        0.000675519579090178,
        -0.014785883948206902,
        -0.023158209398388863,
        0.015474405139684677,
        0.023935092613101006,
        -0.047261983156204224,
        0.007241460960358381,
        -0.03289049118757248,
        0.013831463642418385,
        -0.012567196972668171,
        0.0003288647858425975,
        -0.02930537611246109,
        0.003950923681259155,
        -0.03700388967990875,
        0.04054313898086548,
        -0.03692079335451126,
        -0.04209069162607193,
        -0.008778922259807587,
        -0.0292211826890707,
        0.015695983543992043,
        -0.0012149665271863341,
        -0.008704246021807194,
        -0.006034857593476772,
        0.015231567434966564,
        0.05421154201030731,
        -0.0010876021115109324,
        -0.02003992162644863,
        -0.029048234224319458,
        0.015431854873895645,
        0.005241946782916784,
        0.0011300207115709782,
        0.021573703736066818,
        -0.002816258231177926,
        0.054712578654289246,
        -0.03404853120446205,
        0.008839788846671581,
        0.04100608453154564,
        0.006269428879022598,
        -0.019096743315458298,
        0.033659446984529495,
        0.05128788575530052,
        -0.014817104674875736,
        -0.0011652631219476461,
        -0.022160736843943596,
        0.014852090738713741,
        0.01062947791069746,
        0.03367837518453598,
        0.0009527572547085583,
        -0.020592819899320602,
        0.004577976651489735,
        -0.056595392525196075,
        -0.01053142361342907,
        0.022408058866858482,
        0.0029136971570551395,
        0.05973932519555092,
        -0.022701291367411613,
        0.00301341456361115,
        0.06385499238967896,
        -0.018147099763154984,
        0.01295153796672821,
        0.019671492278575897,
        -0.02320639044046402,
        -0.03952275216579437,
        -0.03998475521802902,
        -0.0010691254865378141,
        -0.0113066416233778,
        0.01044226624071598,
        0.02164577506482601,
        0.02551993727684021,
        0.059669286012649536,
        -0.018558470532298088,
        0.005346017424017191,
        -0.0380212627351284,
        0.0004638402024284005,
        -0.023904111236333847,
        0.011197201907634735,
        -0.00641963304951787,
        0.0682259351015091,
        -0.059712160378694534,
        0.013633019290864468,
        0.006108355708420277,
        -0.0048709469847381115,
        -0.0394306555390358,
        0.0435069277882576,
        -0.0221865177154541,
        -0.05240875855088234,
        0.0006665547261945903,
        0.03175508975982666,
        -0.0740477666258812,
        -0.008406823500990868,
        0.044851623475551605,
        0.05992886796593666,
        0.011457310989499092,
        0.007713306695222855,
        -0.032590679824352264,
        0.03624744340777397,
        0.008285409770905972,
        0.010142135433852673,
        -0.018803920596837997,
        -0.049983736127614975,
        0.010810420848429203,
        -0.04481319710612297,
        0.05579187721014023,
        -0.022407017648220062,
        0.021937958896160126,
        0.00829385221004486,
        -0.054657746106386185,
        0.020427336916327477,
        0.011304937303066254,
        -0.019115876406431198,
        -0.011520637199282646,
        -0.0033626179210841656,
        0.02738860808312893,
        -0.01999814622104168,
        -0.0205786544829607,
        0.04550813511013985,
        0.010681848973035812,
        -0.006298299413174391,
        -0.03441040962934494,
        0.024113668128848076,
        -0.00460229255259037,
        -0.032314758747816086,
        0.006776873487979174,
        0.02273278869688511,
        0.03230704739689827,
        0.015152189880609512,
        -0.011576215736567974,
        -0.0037340561393648386,
        -0.03445042669773102,
        -0.021378396078944206,
        -0.02111535146832466,
        0.021759076043963432,
        0.04017939418554306,
        -0.0023203138262033463,
        -0.010392808355391026,
        0.017182420939207077,
        0.030481481924653053,
        0.035621631890535355,
        -0.06294211000204086,
        -0.026101017370820045,
        -0.006921899970620871,
        -0.011494905687868595,
        0.017606515437364578,
        -0.04496033862233162,
        -0.006367085035890341,
        0.01477339118719101,
        0.020212434232234955,
        0.04187346249818802,
        0.0005082460702396929,
        0.019133146852254868,
        -0.010190951637923717,
        0.0077863833867013454,
        -0.035675909370183945,
        0.05647600069642067,
        0.0007792362594045699,
        0.09008432924747467,
        0.0011553926160559058,
        0.05782022699713707,
        0.02406414784491062,
        0.01119642797857523,
        -0.042378686368465424,
        0.014331272803246975,
        0.024577587842941284,
        0.009524723514914513,
        -0.03100213222205639,
        -0.011297064833343029,
        0.01860376074910164,
        -0.0001831205008784309,
        -0.014897610992193222,
        -0.03310299292206764,
        0.012014827691018581,
        0.008241833187639713,
        -0.013485868461430073,
        0.023166518658399582,
        0.03328612819314003,
        0.0231902115046978,
        -0.017706571146845818,
        -0.02203541249036789,
        -0.0017552032368257642,
        0.009307531639933586,
        0.022296693176031113,
        -0.007587968371808529,
        0.008300681598484516,
        0.007820766419172287,
        0.05429762601852417,
        0.012941604480147362,
        0.0035575642250478268,
        0.0505509190261364,
        -0.017557084560394287,
        -0.02421916089951992,
        -0.0633893832564354,
        -0.056958455592393875,
        -0.01463793683797121,
        0.020644154399633408,
        0.008788544684648514,
        -0.018146108835935593,
        -0.014028606005012989,
        -0.022616572678089142,
        -0.01936684176325798,
        -0.0009557375451549888,
        0.015565470792353153,
        -0.034184373915195465,
        0.02011837810277939,
        -0.009755699895322323,
        -0.0004750482621602714,
        0.03520140424370766,
        0.022834712639451027,
        0.015215705148875713,
        0.000762626004870981,
        -0.023335358127951622,
        0.0014083720743656158,
        -0.021174320951104164,
        -0.007896062918007374,
        0.04520711302757263,
        -0.03400307148694992,
        0.0028449383098632097,
        0.006657052785158157,
        -0.0013398593291640282,
        -0.041555922478437424,
        0.009068261831998825,
        -0.004849674645811319,
        0.038166895508766174,
        -0.0072032380849123,
        0.02291659265756607,
        -0.000988226616755128,
        -0.007865151390433311,
        0.02829640358686447,
        -0.003858262673020363,
        -0.03109816089272499,
        -0.0076530794613063335,
        0.003055030480027199,
        -0.007083958014845848,
        -0.012732013128697872,
        -0.006523510441184044,
        -0.06722269207239151,
        -0.06220925599336624,
        0.000993971130810678,
        -0.011760212481021881,
        0.030303625389933586,
        0.03378196060657501,
        0.008816654793918133,
        -0.005101938731968403,
        0.0006161019555293024,
        0.01377651933580637,
        0.01097371056675911,
        0.0031940247863531113,
        -0.08089067041873932,
        -0.0067665958777070045,
        -0.016523761674761772,
        0.004833452869206667,
        -0.0030508453492075205,
        0.027249937877058983,
        -0.011403693817555904,
        0.005428595002740622,
        -0.02541123703122139,
        -0.023698871955275536,
        0.003007924184203148,
        -0.006359773688018322,
        0.027846213430166245,
        -0.006011056248098612,
        0.014260725118219852,
        -0.010356632992625237,
        -0.02021825686097145,
        -0.025390585884451866,
        0.028017636388540268,
        0.045871391892433167,
        -0.011563841253519058,
        0.01636253111064434,
        0.01843572035431862,
        0.012329882942140102,
        0.026044702157378197,
        -0.0340869314968586,
        -0.010341241955757141,
        -0.01732761226594448,
        0.041152238845825195,
        0.021750187501311302,
        0.031779587268829346,
        -0.022884871810674667,
        -0.03233298659324646,
        0.011949930340051651,
        -0.030650697648525238,
        0.046140264719724655,
        0.008404317311942577,
        0.01925801858305931,
        0.0011376726906746626,
        0.018122801557183266,
        0.014018949121236801,
        -0.028777576982975006,
        -0.04577191546559334,
        -0.022494496777653694,
        0.030143694952130318,
        -0.0727212205529213,
        -0.01049056090414524,
        0.017923686653375626,
        0.021705428138375282,
        0.014852653257548809,
        0.03490811586380005,
        0.011116467416286469,
        -0.004146245773881674,
        -0.0436638668179512,
        -0.02048722468316555,
        -0.0024083417374640703,
        0.030599182471632957,
        -0.033477313816547394,
        -0.025387557223439217,
        0.03289611265063286,
        0.04043704643845558,
        0.005156735889613628,
        -0.031372833997011185,
        -0.024503853172063828,
        0.03331365808844566,
        0.021780304610729218,
        -0.023853635415434837,
        0.03803572431206703,
        0.005866078194230795,
        -0.00022620958043262362,
        -0.02517789788544178,
        0.056364383548498154,
        0.03124501183629036,
        0.0038455526810139418,
        0.011172663420438766,
        0.008196346461772919,
        0.04113880544900894,
        0.05461413413286209,
        3.29852664435748e-05,
        0.01053905300796032,
        0.026792794466018677,
        0.0028983105439692736,
        -0.02644970268011093,
        0.019796747714281082,
        0.026764636859297752,
        0.022537851706147194,
        -0.002362007973715663,
        -0.022333595901727676,
        0.03680233284831047,
        -0.018566293641924858,
        -0.05309715121984482,
        0.02309088036417961,
        -0.02754487469792366,
        0.00782173965126276,
        -0.030019719153642654,
        -0.011382992379367352,
        0.04127291962504387,
        0.0015217632753774524,
        -0.008199034258723259,
        -0.022813351824879646,
        -0.007120579481124878,
        -0.04675697162747383,
        0.015407406724989414,
        -0.018052389845252037,
        -0.034690625965595245,
        0.011080694384872913,
        0.003481718711555004,
        0.05446173623204231,
        -0.035573579370975494,
        -0.004514257423579693,
        -0.009786880575120449,
        0.009154760278761387,
        0.028356444090604782,
        -0.019354073330760002,
        0.004502362105995417,
        8.723719656700268e-05,
        -0.008541320450603962,
        0.007722202688455582,
        -0.01513196062296629,
        0.013263823464512825,
        0.002193430671468377,
        0.021426955237984657,
        0.0028510524425655603,
        -0.0005105230957269669,
        -0.02312845177948475,
        -0.015296142548322678,
        0.00468816515058279,
        -0.013216866180300713,
        0.03425311669707298,
        -0.005124018527567387,
        0.004173961468040943,
        -0.005346924997866154,
        -0.02996794879436493,
        0.008188759908080101,
        0.0002564499736763537,
        -0.009384210221469402,
        0.002514776075258851,
        0.02491721883416176,
        -0.0459023043513298,
        0.03742597624659538,
        -0.0023960706312209368,
        0.014458940364420414,
        0.0053344652988016605,
        0.022282501682639122,
        0.008595072664320469,
        -0.02319699339568615,
        -0.033916354179382324,
        0.021156057715415955,
        -0.0054095895029604435,
        -0.024496126919984818,
        0.0178033746778965,
        0.017366837710142136,
        -0.0030848111491650343,
        0.01623179018497467,
        -0.013274881057441235,
        -0.01875370927155018,
        0.028771376237273216,
        -0.0017019440419971943,
        -0.013202671892940998,
        -0.011025948449969292,
        -0.02379624731838703,
        0.04365207999944687,
        0.0035190898925065994,
        0.02426784671843052,
        -0.04453170672059059,
        0.026569277048110962,
        0.01985977217555046,
        -0.0057168337516486645,
        -0.045768044888973236,
        0.013078860938549042,
        0.01168031431734562,
        0.015916772186756134,
        0.03637760132551193,
        -0.01628691703081131,
        -0.022546591237187386,
        -0.041414473205804825,
        -0.006478576920926571,
        0.0038520661182701588,
        -0.0017733563436195254,
        -0.01600882038474083,
        -0.006576234940439463,
        0.02146994322538376,
        0.022672973573207855,
        0.014880010858178139,
        -0.039584457874298096,
        0.00445212097838521,
        0.032659295946359634,
        -0.025703618302941322,
        0.03764304518699646,
        -0.013131421990692616,
        -0.03967723622918129,
        0.00676077650859952,
        0.027204420417547226,
        -0.016278158873319626,
        -0.00784197449684143,
        0.01479332521557808,
        0.03296880051493645,
        -0.0065711005590856075,
        -0.021582840010523796,
        -0.0026597632095217705,
        0.012598642148077488,
        -0.0317978598177433,
        -0.0013797766296193004,
        0.022383389994502068,
        -0.04675087332725525,
        -0.032336484640836716,
        0.019754558801651,
        0.005832470487803221,
        0.015315459109842777,
        0.0002302744542248547,
        0.042064838111400604,
        0.011048570275306702,
        -0.007909384556114674,
        -0.021091613918542862,
        -0.02634865790605545,
        -0.004730295855551958,
        -0.01590539887547493,
        0.01657441072165966,
        -0.0072801001369953156,
        -0.008400081656873226,
        0.015020671300590038,
        -0.00698352325707674,
        0.02273550257086754,
        -0.004937068093568087,
        -0.024586716666817665,
        -0.014398165978491306,
        0.005752739496529102,
        -0.024416910484433174,
        0.028962383046746254,
        0.01251758448779583,
        0.04068714752793312,
        -0.005698965396732092,
        -0.024156026542186737,
        -0.02324911393225193,
        -0.006957325618714094,
        -0.05187813565135002,
        -0.01503062155097723,
        -0.009314542636275291,
        0.0016663909191265702,
        -0.012213034555315971,
        -0.009039424359798431,
        -0.03863808885216713,
        0.012204826809465885,
        0.023364383727312088,
        0.017638739198446274,
        0.02549109421670437,
        0.00882051046937704,
        -0.006260688416659832,
        -0.008502067998051643,
        0.011845857836306095,
        0.027391208335757256,
        -0.005934892687946558,
        -0.01796841435134411,
        0.011009885929524899,
        -0.023371918126940727,
        0.010744010098278522,
        0.016662882640957832,
        0.01717807725071907,
        -0.0065974085591733456,
        -0.0021071727387607098,
        -0.03178641200065613,
        -0.018312737345695496,
        0.0013127747224643826,
        -0.002545409370213747,
        0.06322168558835983,
        -0.009851112961769104,
        0.023230932652950287,
        -0.009165691211819649,
        -0.02446121722459793,
        -0.01895883120596409,
        0.00027220320771448314,
        -0.0019464755896478891,
        0.0006232602172531188,
        0.015291825868189335,
        0.04523341730237007,
        0.0003710788150783628,
        0.01619780994951725,
        -0.033986154943704605,
        0.05080091208219528,
        0.007245264947414398,
        0.0044382004998624325,
        -0.01841100864112377,
        0.012189306318759918,
        -0.011563943699002266,
        0.005427379161119461,
        -0.026340149343013763,
        -0.01912030763924122,
        0.000908476416952908,
        -0.010621743276715279,
        -0.02442682720720768,
        0.01472448743879795,
        -0.03031397983431816,
        -0.0027384362183511257,
        0.007686566561460495,
        -0.011118095368146896,
        0.006015430204570293,
        -0.012911495752632618,
        0.0037191815208643675,
        -0.0068319388665258884,
        -0.026479627937078476,
        -0.00772797642275691,
        0.008945958688855171,
        0.02432015724480152,
        0.0029600225389003754,
        -0.004886629991233349,
        -0.011018779128789902,
        -0.008821488358080387,
        -0.021954677999019623,
        -0.03492460772395134,
        -0.01934652030467987,
        0.04447689652442932,
        -0.04680256545543671,
        0.006424884777516127,
        0.03706679865717888,
        -0.005326714366674423,
        -0.013030001893639565,
        0.035898130387067795,
        0.031131498515605927,
        0.027679188176989555,
        -0.04301801323890686,
        -0.037639494985342026,
        0.0015441646100953221,
        -0.0007435640436597168,
        -0.017037035897374153,
        -0.006103551015257835,
        0.008110563270747662,
        0.04107831418514252,
        0.0026689679361879826,
        -0.02195006236433983,
        0.025765227153897285,
        -0.002068139845505357,
        0.004608880262821913,
        -0.0006659128703176975,
        0.013101531192660332,
        -0.014035418629646301,
        -0.007075290661305189,
        -0.022540923207998276,
        -0.0052622463554143906,
        -0.03093647211790085,
        -0.019957641139626503,
        0.001888472237624228,
        -0.04203429073095322,
        -0.0007401374750770628,
        0.007219933904707432,
        -0.016821684315800667,
        -0.03539091348648071,
        0.03135313838720322,
        0.0003642004739958793,
        0.002073973882943392,
        -0.044229622930288315,
        -0.011716407723724842,
        0.03905431926250458,
        0.0012696136254817247,
        0.028084993362426758,
        -0.015731196850538254,
        0.03511275723576546,
        -0.003172279102727771,
        0.009031345136463642,
        0.012404441833496094,
        0.01611240766942501,
        0.01770547404885292,
        0.005310497712343931,
        0.016901813447475433,
        -0.033658768981695175,
        0.010042605921626091,
        -0.0012384750880300999,
        0.0034676443319767714,
        -0.010438010096549988,
        -0.05000345781445503,
        0.008151489309966564,
        0.014822353608906269,
        -0.03683207556605339,
        -0.025061216205358505,
        0.011536002159118652,
        -0.00812164880335331,
        -0.034198615700006485,
        0.020057523623108864,
        0.0071425652131438255,
        -0.00927219819277525,
        -0.006851478945463896,
        -0.01119283214211464,
        -0.009530717507004738,
        -0.006573214661329985,
        -0.0010529683204367757,
        0.004749756772071123,
        -0.009341114200651646,
        0.0017064909916371107,
        -0.03466453775763512,
        0.020480073988437653,
        0.005718442145735025,
        -0.016661519184708595,
        0.027641287073493004,
        -0.015236767940223217,
        0.0007701646536588669,
        -0.03579436615109444,
        -0.026065170764923096,
        0.03225169703364372,
        0.008625408634543419,
        -0.026748107746243477,
        0.025996221229434013,
        -0.014518811367452145,
        0.02055075205862522,
        0.04003151133656502,
        -0.04409844055771828,
        0.042275141924619675,
        -0.020859012380242348,
        0.0014231953537091613,
        0.00822847057133913,
        0.005118933971971273,
        -0.005245995707809925,
        0.024519510567188263,
        0.0363539457321167,
        0.00796101801097393,
        -0.014338325709104538,
        0.0024213416036218405,
        -0.008475624024868011,
        -0.0048162261955440044,
        0.019876454025506973,
        0.004506914876401424,
        0.01197353471070528,
        0.0047790128737688065,
        0.013582658022642136,
        -0.014371735975146294,
        -0.010398207232356071,
        0.023515410721302032,
        0.005306414794176817,
        -0.000158923416165635,
        0.031199553981423378,
        -0.018822144716978073,
        0.010003103874623775,
        0.0281766876578331,
        0.017492931336164474,
        0.03009539656341076,
        0.01137220673263073,
        0.0005705864168703556,
        -0.010273752734065056,
        0.03064025193452835,
        -0.025892527773976326,
        0.004869155120104551,
        0.010993685573339462,
        -0.01709575764834881,
        0.033872414380311966,
        0.014233666472136974,
        0.016183724626898766,
        -0.005304879508912563,
        -0.047963615506887436,
        -0.008995170705020428,
        0.005795912351459265,
        0.0031994495075196028,
        0.017594527453184128,
        0.013583897612988949,
        -0.007126617711037397,
        -0.000188515565241687,
        -0.02680756151676178,
        0.01515771821141243,
        0.028401412069797516,
        7.484295929316431e-05,
        -0.006224189419299364,
        0.0037584032397717237,
        -0.0656825378537178,
        -0.0014264225028455257,
        0.023883206769824028,
        0.010401333682239056,
        -0.05625149607658386,
        -0.01629483699798584,
        -0.011560631915926933,
        0.010628845542669296,
        -0.01626015082001686,
        -0.000978427822701633
      ],
      "title": "Recommendation on the Ethics of Artificial Intelligence"
    },
    {
      "id": "gai-eng_corpus-item004",
      "count": 4,
      "created": "2025-07-06T04:58:54.523394",
      "text": "The Age of AI has begun Introduction In my lifetime, I've seen two demonstrations of technology that struck me as revolutionary. The first time was in 1980, when I was introduced to a graphical user interface—the forerunner of every modern operating system, including Windows. I sat with the person who had shown me the demo, a brilliant programmer named Charles Simonyi, and we immediately started brainstorming about all the things we could do with such a user-friendly approach to computing. Charles eventually joined Microsoft, Windows became the backbone of Microsoft, and the thinking we did after that demo helped set the company's agenda for the next 15 years. The second big surprise came just last year. I'd been meeting with the team from OpenAI since 2016 and was impressed by their steady progress. In mid-2022, I was so excited about their work that I gave them a challenge: train an artificial intelligence to pass an Advanced Placement biology exam. Make it capable of answering questions that it hasn't been specifically trained for. (I picked AP Bio because the test is more than a simple regurgitation of scientific facts—it asks you to think critically about biology.) If you can do that, I said, then you'll have made a true breakthrough. I thought the challenge would keep them busy for two or three years. They finished it in just a few months. In September, when I met with them again, I watched in awe as they asked GPT, their AI model, 60 multiple-choice questions from the AP Bio exam—and it got 59 of them right. Then it wrote outstanding answers to six open-ended questions from the exam. We had an outside expert score the test, and GPT got a 5—the highest possible score, and the equivalent to getting an A or A+ in a college-level biology course. Once it had aced the test, we asked it a non-scientific question: \"What do you say to a father with a sick child?\" It wrote a thoughtful answer that was probably better than most of us in the room would have given. The whole experience was stunning. I knew I had just seen the most important advance in technology since the graphical user interface. This inspired me to think about all the things that AI can achieve in the next five to 10 years. The development of AI is as fundamental as the creation of the microprocessor, the personal computer, the Internet, and the mobile phone. It will change the way people work, learn, travel, get health care, and communicate with each other. Entire industries will reorient around it. Businesses will distinguish themselves by how well they use it. Philanthropy is my full-time job these days, and I've been thinking a lot about how—in addition to helping people be more productive—AI can reduce some of the world's worst inequities. Globally, the worst inequity is in health: 5 million children under the age of 5 die every year. That's down from 10 million two decades ago, but it's still a shockingly high number. Nearly all of these children were born in poor countries and die of preventable causes like diarrhea or malaria. It's hard to imagine a better use of AIs than saving the lives of children. In the United States, the best opportunity for reducing inequity is to improve education, particularly making sure that students succeed at math. The evidence shows that having basic math skills sets students up for success, no matter what career they choose. But achievement in math is going down across the country, especially for Black, Latino, and low-income students. AI can help turn that trend around. Climate change is another issue where I'm convinced AI can make the world more equitable. The injustice of climate change is that the people who are suffering the most—the world's poorest—are also the ones who did the least to contribute to the problem. I'm still thinking and learning about how AI can help, but later in this post I'll suggest a few areas with a lot of potential. In short, I'm excited about the impact that AI will have on issues that the Gates Foundation works on, and the foundation will have much more to say about AI in the coming months. The world needs to make sure that everyone—and not just people who are well-off—benefits from artificial intelligence. Governments and philanthropy will need to play a major role in ensuring that it reduces inequity and doesn't contribute to it. This is the priority for my own work related to AI. Any new technology that's so disruptive is bound to make people uneasy, and that's certainly true with artificial intelligence. I understand why—it raises hard questions about the workforce, the legal system, privacy, bias, and more. AIs also make factual mistakes and experience hallucinations. Before I suggest some ways to mitigate the risks, I'll define what I mean by AI, and I'll go into more detail about some of the ways in which it will help empower people at work, save lives, and improve education. Defining artificial intelligence Technically, the term artificial intelligence refers to a model created to solve a specific problem or provide a particular service. What is powering things like ChatGPT is artificial intelligence. It is learning how to do chat better but can't learn other tasks. By contrast, the term artificial general intelligence refers to software that's capable of learning any task or subject. AGI doesn't exist yet—there is a robust debate going on in the computing industry about how to create it, and whether it can even be created at all. Developing AI and AGI has been the great dream of the computing industry. For decades, the question was when computers would be better than humans at something other than making calculations. Now, with the arrival of machine learning and large amounts of computing power, sophisticated AIs are a reality and they will get better very fast. I think back to the early days of the personal computing revolution, when the software industry was so small that most of us could fit onstage at a conference. Today it is a global industry. Since a huge portion of it is now turning its attention to AI, the innovations are going to come much faster than what we experienced after the microprocessor breakthrough. Soon the pre-AI period will seem as distant as the days when using a computer meant typing at a C:> prompt rather than tapping on a screen. Productivity enhancement Although humans are still better than GPT at a lot of things, there are many jobs where these capabilities are not used much. For example, many of the tasks done by a person in sales (digital or phone), service, or document handling (like payables, accounting, or insurance claim disputes) require decision-making but not the ability to learn continuously. Corporations have training programs for these activities and in most cases, they have a lot of examples of good and bad work. Humans are trained using these data sets, and soon these data sets will also be used to train the AIs that will empower people to do this work more efficiently. As computing power gets cheaper, GPT's ability to express ideas will increasingly be like having a white-collar worker available to help you with various tasks. Microsoft describes this as having a co-pilot. Fully incorporated into products like Office, AI will enhance your work—for example by helping with writing emails and managing your inbox. Eventually your main way of controlling a computer will no longer be pointing and clicking or tapping on menus and dialogue boxes. Instead, you'll be able to write a request in plain English. (And not just English—AIs will understand languages from around the world. In India earlier this year, I met with developers who are working on AIs that will understand many of the languages spoken there.) In addition, advances in AI will enable the creation of a personal agent. Think of it as a digital personal assistant: It will see your latest emails, know about the meetings you attend, read what you read, and read the things you don't want to bother with. This will both improve your work on the tasks you want to do and free you from the ones you don't want to do. You'll be able to use natural language to have this agent help you with scheduling, communications, and e-commerce, and it will work across all your devices. Because of the cost of training the models and running the computations, creating a personal agent is not feasible yet, but thanks to the recent advances in AI, it is now a realistic goal. Some issues will need to be worked out: For example, can an insurance company ask your agent things about you without your permission? If so, how many people will choose not to use it? Company-wide agents will empower employees in new ways. An agent that understands a particular company will be available for its employees to consult directly and should be part of every meeting so it can answer questions. It can be told to be passive or encouraged to speak up if it has some insight. It will need access to the sales, support, finance, product schedules, and text related to the company. It should read news related to the industry the company is in. I believe that the result will be that employees will become more productive. When productivity goes up, society benefits because people are freed up to do other things, at work and at home. Of course, there are serious questions about what kind of support and retraining people will need. Governments need to help workers transition into other roles. But the demand for people who help other people will never go away. The rise of AI will free people up to do things that software never will—teaching, caring for patients, and supporting the elderly, for example. Global health and education are two areas where there's great need and not enough workers to meet those needs. These are areas where AI can help reduce inequity if it is properly targeted. These should be a key focus of AI work, so I will turn to them now. Health I see several ways in which AIs will improve health care and the medical field. For one thing, they'll help health-care workers make the most of their time by taking care of certain tasks for them—things like filing insurance claims, dealing with paperwork, and drafting notes from a doctor's visit. I expect that there will be a lot of innovation in this area. Other AI-driven improvements will be especially important for poor countries, where the vast majority of under-5 deaths happen. For example, many people in those countries never get to see a doctor, and AIs will help the health workers they do see be more productive. (The effort to develop AI-powered ultrasound machines that can be used with minimal training is a great example of this.) AIs will even give patients the ability to do basic triage, get advice about how to deal with health problems, and decide whether they need to seek treatment. The AI models used in poor countries will need to be trained on different diseases than in rich countries. They will need to work in different languages and factor in different challenges, such as patients who live very far from clinics or can't afford to stop working if they get sick. People will need to see evidence that health AIs are beneficial overall, even though they won't be perfect and will make mistakes. AIs have to be tested very carefully and properly regulated, which means it will take longer for them to be adopted than in other areas. But then again, humans make mistakes too. And having no access to medical care is also a problem. In addition to helping with care, AIs will dramatically accelerate the rate of medical breakthroughs. The amount of data in biology is very large, and it's hard for humans to keep track of all the ways that complex biological systems work. There is already software that can look at this data, infer what the pathways are, search for targets on pathogens, and design drugs accordingly. Some companies are working on cancer drugs that were developed this way. The next generation of tools will be much more efficient, and they'll be able to predict side effects and figure out dosing levels. One of the Gates Foundation's priorities in AI is to make sure these tools are used for the health problems that affect the poorest people in the world, including AIDS, TB, and malaria. Similarly, governments and philanthropy should create incentives for companies to share AI-generated insights into crops or livestock raised by people in poor countries. AIs can help develop better seeds based on local conditions, advise farmers on the best seeds to plant based on the soil and weather in their area, and help develop drugs and vaccines for livestock. As extreme weather and climate change put even more pressure on subsistence farmers in low-income countries, these advances will be even more important. Education Computers haven't had the effect on education that many of us in the industry have hoped. There have been some good developments, including educational games and online sources of information like Wikipedia, but they haven't had a meaningful effect on any of the measures of students' achievement. But I think in the next five to 10 years, AI-driven software will finally deliver on the promise of revolutionizing the way people teach and learn. It will know your interests and your learning style so it can tailor content that will keep you engaged. It will measure your understanding, notice when you're losing interest, and understand what kind of motivation you respond to. It will give immediate feedback. There are many ways that AIs can assist teachers and administrators, including assessing a student's understanding of a subject and giving advice on career planning. Teachers are already using tools like ChatGPT to provide comments on their students' writing assignments. Of course, AIs will need a lot of training and further development before they can do things like understand how a certain student learns best or what motivates them. Even once the technology is perfected, learning will still depend on great relationships between students and teachers. It will enhance—but never replace—the work that students and teachers do together in the classroom. New tools will be created for schools that can afford to buy them, but we need to ensure that they are also created for and available to low-income schools in the U.S. and around the world. AIs will need to be trained on diverse data sets so they are unbiased and reflect the different cultures where they'll be used. And the digital divide will need to be addressed so that students in low-income households do not get left behind. I know a lot of teachers are worried that students are using GPT to write their essays. Educators are already discussing ways to adapt to the new technology, and I suspect those conversations will continue for quite some time. I've heard about teachers who have found clever ways to incorporate the technology into their work—like by allowing students to use GPT to create a first draft that they have to personalize. Risks and problems with AI You've probably read about problems with the current AI models. For example, they aren't necessarily good at understanding the context for a human's request, which leads to some strange results. When you ask an AI to make up something fictional, it can do that well. But when you ask for advice about a trip you want to take, it may suggest hotels that don't exist. This is because the AI doesn't understand the context for your request well enough to know whether it should invent fake hotels or only tell you about real ones that have rooms available. There are other issues, such as AIs giving wrong answers to math problems because they struggle with abstract reasoning. But none of these are fundamental limitations of artificial intelligence. Developers are working on them, and I think we're going to see them largely fixed in less than two years and possibly much faster. Other concerns are not simply technical. For example, there's the threat posed by humans armed with AI. Like most inventions, artificial intelligence can be used for good purposes or malign ones. Governments need to work with the private sector on ways to limit the risks. Then there's the possibility that AIs will run out of control. Could a machine decide that humans are a threat, conclude that its interests are different from ours, or simply stop caring about us? Possibly, but this problem is no more urgent today than it was before the AI developments of the past few months. Superintelligent AIs are in our future. Compared to a computer, our brains operate at a snail's pace: An electrical signal in the brain moves at 1/100,000th the speed of the signal in a silicon chip! Once developers can generalize a learning algorithm and run it at the speed of a computer—an accomplishment that could be a decade away or a century away—we'll have an incredibly powerful AGI. It will be able to do everything that a human brain can, but without any practical limits on the size of its memory or the speed at which it operates. This will be a profound change. These \"strong\" AIs, as they're known, will probably be able to establish their own goals. What will those goals be? What happens if they conflict with humanity's interests? Should we try to prevent strong AI from ever being developed? These questions will get more pressing with time. But none of the breakthroughs of the past few months have moved us substantially closer to strong AI. Artificial intelligence still doesn't control the physical world and can't establish its own goals. A recent New York Times article about a conversation with ChatGPT where it declared it wanted to become a human got a lot of attention. It was a fascinating look at how human-like the model's expression of emotions can be, but it isn't an indicator of meaningful independence. Three books have shaped my own thinking on this subject: Superintelligence, by Nick Bostrom; Life 3.0 by Max Tegmark; and A Thousand Brains, by Jeff Hawkins. I don't agree with everything the authors say, and they don't agree with each other either. But all three books are well written and thought-provoking. The next frontiers There will be an explosion of companies working on new uses of AI as well as ways to improve the technology itself. For example, companies are developing new chips that will provide the massive amounts of processing power needed for artificial intelligence. Some use optical switches—lasers, essentially—to reduce their energy consumption and lower the manufacturing cost. Ideally, innovative chips will allow you to run an AI on your own device, rather than in the cloud, as you have to do today. On the software side, the algorithms that drive an AI's learning will get better. There will be certain domains, such as sales, where developers can make AIs extremely accurate by limiting the areas that they work in and giving them a lot of training data that's specific to those areas. But one big open question is whether we'll need many of these specialized AIs for different uses—one for education, say, and another for office productivity—or whether it will be possible to develop an artificial general intelligence that can learn any task. There will be immense competition on both approaches. No matter what, the subject of AIs will dominate the public discussion for the foreseeable future. I want to suggest three principles that should guide that conversation. First, we should try to balance fears about the downsides of AI—which are understandable and valid—with its ability to improve people's lives. To make the most of this remarkable new technology, we'll need to both guard against the risks and spread the benefits to as many people as possible. Second, market forces won't naturally produce AI products and services that help the poorest. The opposite is more likely. With reliable funding and the right policies, governments and philanthropy can ensure that AIs are used to reduce inequity. Just as the world needs its brightest people focused on its biggest problems, we will need to focus the world's best AIs on its biggest problems. Although we shouldn't wait for this to happen, it's interesting to think about whether artificial intelligence would ever identify inequity and try to reduce it. Do you need to have a sense of morality in order to see inequity, or would a purely rational AI also see it? If it did recognize inequity, what would it suggest that we do about it? Finally, we should keep in mind that we're only at the beginning of what AI can accomplish. Whatever limitations it has today will be gone before we know it. I'm lucky to have been involved with the PC revolution and the Internet revolution. I'm just as excited about this moment. This new technology can help people everywhere improve their lives. At the same time, the world needs to establish the rules of the road so that any downsides of artificial intelligence are far outweighed by its benefits, and so that everyone can enjoy those benefits no matter where they live or how much money they have. The Age of AI is filled with opportunities and responsibilities.",
      "word_count": 3594,
      "character_count": 21154,
      "vector": [
        0.15953728556632996,
        -0.137161985039711,
        0.0832972303032875,
        0.008961886167526245,
        0.011908117681741714,
        -0.07167623192071915,
        -0.039879996329545975,
        0.029865812510252,
        -0.04099038243293762,
        -0.05052986741065979,
        -0.006919160019606352,
        0.02053006738424301,
        -0.03746503219008446,
        -0.026101240888237953,
        0.0142782898619771,
        0.018622495234012604,
        -0.004772344138473272,
        -0.06081867218017578,
        -0.049390170723199844,
        -0.07390329986810684,
        -0.005556665826588869,
        -0.06249171122908592,
        0.05754922702908516,
        0.14639778435230255,
        -0.08647608011960983,
        0.012804944068193436,
        -0.1280723214149475,
        -0.056881800293922424,
        0.013101553544402122,
        -0.07926853746175766,
        0.09197188913822174,
        -0.09741368889808655,
        0.009206299670040607,
        -0.07944454997777939,
        -0.014484011568129063,
        0.031193776056170464,
        0.010652042925357819,
        -0.0585225410759449,
        -0.028864068910479546,
        -0.03286958485841751,
        -0.0796908512711525,
        -0.042061202228069305,
        -0.016314897686243057,
        -0.032273974269628525,
        0.03894245997071266,
        0.05612371489405632,
        0.04314734414219856,
        0.12408911436796188,
        -0.014180035330355167,
        0.04018063843250275,
        0.11410395801067352,
        0.02974887378513813,
        -0.03960205614566803,
        0.033951859921216965,
        -0.008199701085686684,
        -0.05835993215441704,
        0.030939245596528053,
        0.022553808987140656,
        0.03814919665455818,
        -0.03618001565337181,
        -0.09262514114379883,
        0.09266927093267441,
        0.022555148229002953,
        -0.04476858302950859,
        -0.06319446861743927,
        0.06495816260576248,
        -0.05461196228861809,
        -0.02360033057630062,
        0.005812462884932756,
        -0.02916244976222515,
        -0.029234955087304115,
        0.012597058899700642,
        -0.010684270411729813,
        0.03863322734832764,
        -0.0067725102417171,
        0.061816032975912094,
        -0.025233348831534386,
        0.00879914965480566,
        0.02182472124695778,
        -0.021326616406440735,
        0.06981109827756882,
        0.05219972878694534,
        0.04988665133714676,
        0.026943178847432137,
        0.023765167221426964,
        0.019866246730089188,
        -0.054104190319776535,
        0.032354336231946945,
        -0.047906965017318726,
        -0.01728176884353161,
        0.03196584805846214,
        -0.06960293650627136,
        0.08121433854103088,
        -0.11256637424230576,
        0.05417224019765854,
        -0.014885533601045609,
        -0.026748882606625557,
        -0.00964964646846056,
        0.055474117398262024,
        -0.02598908171057701,
        -0.004061251878738403,
        0.0725957453250885,
        -0.1303100436925888,
        0.07020790874958038,
        0.011521246284246445,
        0.012855177745223045,
        -0.01052260585129261,
        0.03450910747051239,
        -0.07857202738523483,
        -0.014947550371289253,
        -0.010714500211179256,
        0.06218365952372551,
        0.02821139432489872,
        -0.028507215902209282,
        -0.004377330653369427,
        0.026473533362150192,
        -0.023015080019831657,
        0.02808045595884323,
        0.03129907697439194,
        -0.043118540197610855,
        -0.028648145496845245,
        0.04544961825013161,
        -0.04427211359143257,
        -0.019316980615258217,
        0.02694125287234783,
        -0.009771626442670822,
        -0.04974425956606865,
        -0.03485872596502304,
        -0.03455594927072525,
        -0.060475755482912064,
        -0.04147851839661598,
        0.06055939942598343,
        -0.04545358940958977,
        -0.013249118812382221,
        -0.02318662218749523,
        -0.019205229356884956,
        0.03037780150771141,
        -0.04360462725162506,
        0.05531138926744461,
        0.035365089774131775,
        0.016056830063462257,
        0.061120472848415375,
        -0.014189173467457294,
        -0.024138981476426125,
        0.004856192972511053,
        -0.0708615630865097,
        0.0019272742792963982,
        0.007661880925297737,
        -0.006237247493118048,
        0.011049270629882812,
        0.031021667644381523,
        0.012309600599110126,
        -0.036429714411497116,
        0.025311946868896484,
        -0.0335378497838974,
        0.061253342777490616,
        -0.008703392930328846,
        0.0034145957324653864,
        0.03851969167590141,
        0.01202162355184555,
        -0.009756983257830143,
        0.020904095843434334,
        0.004945840686559677,
        -0.01992424950003624,
        -0.051620375365018845,
        0.0446622334420681,
        -0.07382237911224365,
        0.031276389956474304,
        0.015287328511476517,
        0.008644637651741505,
        -0.0596160814166069,
        0.025324298068881035,
        0.0033116680569946766,
        0.0005920554394833744,
        -0.020382072776556015,
        -0.039097175002098083,
        0.029304584488272667,
        0.07459356635808945,
        0.015966981649398804,
        0.10381859540939331,
        0.0015835630474612117,
        0.0038690827786922455,
        -0.008247343823313713,
        -0.02954150177538395,
        -0.02561517059803009,
        -0.019808417186141014,
        0.0030768790747970343,
        -0.010083150118589401,
        0.03990396484732628,
        -0.02379533089697361,
        0.00820864737033844,
        0.019963832572102547,
        0.045614175498485565,
        0.043379295617341995,
        -0.022987093776464462,
        -0.022649183869361877,
        -0.037950482219457626,
        -0.009258734993636608,
        0.03422073274850845,
        -0.038920897990465164,
        -0.0329865887761116,
        0.0012949950760230422,
        -0.027679018676280975,
        0.026199357584118843,
        -0.03412861377000809,
        0.03364182636141777,
        -0.017587821930646896,
        -0.009750246070325375,
        -0.04608814790844917,
        -0.0069722398184239864,
        0.011614317074418068,
        0.011404422111809254,
        0.0606442354619503,
        0.0288804080337286,
        -0.06102168932557106,
        -0.040166303515434265,
        0.004799730610102415,
        0.004102043807506561,
        0.027154192328453064,
        -0.03137298300862312,
        -0.021396422758698463,
        0.006954691372811794,
        0.0011463119881227612,
        -0.05609365180134773,
        -0.01741335727274418,
        -0.03482023626565933,
        -0.012351201847195625,
        -0.0243776123970747,
        -0.02571362815797329,
        -0.00976371020078659,
        0.020814495161175728,
        0.05094414949417114,
        -0.010241474956274033,
        0.03613445162773132,
        0.01939442567527294,
        0.019023867323994637,
        -0.03263966366648674,
        -0.018934154883027077,
        0.0839548334479332,
        -0.010199148207902908,
        -0.01605481654405594,
        -0.003194053890183568,
        -0.05456738919019699,
        0.02050200290977955,
        -0.06386539340019226,
        0.008344322443008423,
        0.015096912160515785,
        -0.04107586294412613,
        -0.03436703607439995,
        0.018419986590743065,
        0.05972976237535477,
        -0.03305229917168617,
        -0.03220836818218231,
        -0.00406225398182869,
        0.015049701556563377,
        -0.03676832094788551,
        0.015309875831007957,
        -0.03812510147690773,
        -0.03952864184975624,
        0.02202954888343811,
        -0.030576655641198158,
        -0.006113584619015455,
        0.009907481260597706,
        -0.0207048449665308,
        -0.02299658954143524,
        0.047859739512205124,
        -0.003398115513846278,
        -0.005281107500195503,
        0.03281629458069801,
        -0.03665278106927872,
        -0.03888775408267975,
        -0.03158529847860336,
        -0.06219015643000603,
        0.04857566952705383,
        0.007530130445957184,
        0.016796428710222244,
        0.0005990921636112034,
        0.016883963719010353,
        -0.03315071761608124,
        -0.002098670694977045,
        -0.03347466513514519,
        -0.0067260246723890305,
        -0.004495613742619753,
        0.024180108681321144,
        -0.031658828258514404,
        0.036100875586271286,
        0.006388825364410877,
        0.005604160018265247,
        -0.010219802148640156,
        -0.01265216339379549,
        0.040357381105422974,
        -0.055521365255117416,
        -0.016917921602725983,
        -0.060685187578201294,
        0.029434047639369965,
        0.051991794258356094,
        -0.06732884794473648,
        0.0013235234655439854,
        0.04971589893102646,
        0.018903255462646484,
        -0.029390495270490646,
        0.014605337753891945,
        0.007908341474831104,
        0.04126165434718132,
        0.004233052488416433,
        0.007934894412755966,
        -0.041128337383270264,
        -0.05413944646716118,
        -0.012032178230583668,
        -0.010006331838667393,
        -0.010310926474630833,
        -0.0076685454696416855,
        0.004596958868205547,
        0.02719515934586525,
        0.014590571634471416,
        0.038518939167261124,
        -0.024143217131495476,
        0.02154904417693615,
        -0.00895087793469429,
        0.008545005694031715,
        -0.04965950921177864,
        0.0017501873662695289,
        -0.008657112717628479,
        0.0207155030220747,
        -0.036890000104904175,
        -0.06178998202085495,
        -0.012287573888897896,
        -0.01713038608431816,
        -0.02886982634663582,
        -0.011431447230279446,
        0.025940891355276108,
        -0.02502482943236828,
        0.04635770991444588,
        -0.01580020785331726,
        0.0025040465407073498,
        -0.07337255030870438,
        -0.024604689329862595,
        -0.008552544750273228,
        -0.011519823223352432,
        0.00821019895374775,
        0.010578214190900326,
        0.0021000136621296406,
        0.02378116361796856,
        -0.03995469957590103,
        0.016378354281187057,
        0.047327857464551926,
        -0.026426810771226883,
        -0.05762254446744919,
        0.005164135247468948,
        0.02460503950715065,
        0.03524653613567352,
        0.018310703337192535,
        0.00045982064330019057,
        0.02584521286189556,
        0.031100181862711906,
        0.022077852860093117,
        0.010102382861077785,
        -0.04302206262946129,
        0.033740751445293427,
        -0.059697117656469345,
        -0.0010828250087797642,
        0.04077519103884697,
        -0.01710074208676815,
        0.04949178174138069,
        -0.01824370212852955,
        0.014604979194700718,
        0.044680241495370865,
        0.047316428273916245,
        -0.004337657243013382,
        0.02360435761511326,
        -0.015863128006458282,
        0.019175462424755096,
        -0.004318995866924524,
        -0.008682998828589916,
        0.015411075204610825,
        0.010681255720555782,
        0.0312763936817646,
        -0.0034785910975188017,
        0.05196979641914368,
        0.02919735200703144,
        0.04583916813135147,
        -0.014811664819717407,
        -0.0018814062932506204,
        -0.015971411019563675,
        0.008061368949711323,
        0.03212568536400795,
        0.05701121687889099,
        -0.03015473671257496,
        0.03703427314758301,
        0.007212453987449408,
        -0.012155597098171711,
        -0.01274519506841898,
        0.005200098734349012,
        -0.03769592195749283,
        0.018051235005259514,
        -0.0006828933255746961,
        0.02723776176571846,
        -0.05064639076590538,
        0.0009930683299899101,
        0.05005645751953125,
        0.03515959158539772,
        0.018134426325559616,
        0.005701581947505474,
        -0.02287522703409195,
        0.028841745108366013,
        -0.009106247685849667,
        0.05247870087623596,
        -0.028952738270163536,
        -0.03858062997460365,
        -0.018547067418694496,
        -0.051141779869794846,
        0.03304773569107056,
        -0.0694192498922348,
        0.02036099135875702,
        0.005157272797077894,
        -0.05899948626756668,
        0.0200458075851202,
        0.02798730693757534,
        -0.027570629492402077,
        0.014794101007282734,
        0.004345294088125229,
        0.04943733662366867,
        0.017872799187898636,
        0.037434570491313934,
        0.05199548229575157,
        -0.006500069983303547,
        -0.026964979246258736,
        -0.015264665707945824,
        -0.01417507417500019,
        0.01330561563372612,
        -0.03983825445175171,
        -0.009933368302881718,
        -0.04161486402153969,
        0.03412025421857834,
        -0.003480857238173485,
        -0.00901652593165636,
        -0.00028822943568229675,
        0.005029737483710051,
        -0.02687612734735012,
        0.009676427580416203,
        -0.0011024331906810403,
        0.03358841687440872,
        0.015561852604150772,
        0.010214755311608315,
        0.054149333387613297,
        -0.022905632853507996,
        0.04173830524086952,
        -0.037588559091091156,
        0.020888427272439003,
        -0.03103276900947094,
        -0.02158641628921032,
        -0.00790825393050909,
        -0.012147592380642891,
        0.008603411726653576,
        0.04084603860974312,
        -0.00025125531828962266,
        0.013972033746540546,
        -0.000753797881770879,
        0.024255122989416122,
        -0.03509814292192459,
        0.03865903243422508,
        -0.058500830084085464,
        0.038092631846666336,
        -0.03372577577829361,
        0.024553775787353516,
        0.007251915987581015,
        0.07657694071531296,
        0.030735520645976067,
        0.009552160277962685,
        -0.007361173164099455,
        0.007529927883297205,
        -0.018787268549203873,
        -0.026155952364206314,
        9.933140245266259e-05,
        0.005900680553168058,
        0.02319232188165188,
        -0.027079761028289795,
        0.009664628654718399,
        -0.008863008581101894,
        -0.012135074473917484,
        -0.014583599753677845,
        -0.00688956631347537,
        0.030837999656796455,
        0.021638251841068268,
        0.007168587297201157,
        0.031643785536289215,
        0.011505848728120327,
        0.002223710296675563,
        0.0004203465941827744,
        0.01796947605907917,
        0.0006114511052146554,
        0.0020863867830485106,
        0.013322371058166027,
        0.06797806918621063,
        0.054170187562704086,
        -0.004259753040969372,
        0.01149595808237791,
        0.007056418340653181,
        -0.0006212883745320141,
        -0.03339076042175293,
        -0.05434578284621239,
        -0.052559707313776016,
        -0.0024117918219417334,
        -0.013062977232038975,
        0.016748467460274696,
        -0.03826306015253067,
        -0.033973678946495056,
        0.03253891319036484,
        0.023975795134902,
        -0.011701172217726707,
        0.001870142063125968,
        -0.01830459013581276,
        0.01329722162336111,
        -0.008575237356126308,
        0.01210835762321949,
        -2.5310318960691802e-05,
        0.007371046114712954,
        -0.008780507370829582,
        0.005284206476062536,
        0.007748378440737724,
        0.025198720395565033,
        -0.0020506586879491806,
        0.06111222133040428,
        -0.030985821038484573,
        0.02579808048903942,
        0.05535424128174782,
        -0.0025447127409279346,
        -0.03641765937209129,
        0.020364001393318176,
        0.00546581344678998,
        0.061846084892749786,
        0.016397664323449135,
        -0.001218147692270577,
        0.004166988655924797,
        0.013397568836808205,
        -0.009251805953681469,
        -0.02012983150780201,
        -0.011283657513558865,
        -0.014848265796899796,
        -0.005844603758305311,
        -0.027394795790314674,
        -0.0031738346442580223,
        -0.013473665341734886,
        -0.015886647626757622,
        -0.027009617537260056,
        -0.0021599498577415943,
        -0.01947411336004734,
        0.018468713387846947,
        0.009272553957998753,
        0.028638524934649467,
        -0.03529408201575279,
        -0.00488686328753829,
        0.03466877341270447,
        0.008228170685470104,
        0.0016211631009355187,
        -0.0508551150560379,
        0.010379663668572903,
        -0.02660076692700386,
        -0.026812713593244553,
        -0.01863381825387478,
        -0.0069772908464074135,
        -0.009953132830560207,
        0.024072173982858658,
        -0.011390820145606995,
        -0.021332677453756332,
        0.02023027278482914,
        -0.006312151905149221,
        -0.003524851519614458,
        -0.0024108877405524254,
        0.019010452553629875,
        -0.0064970459789037704,
        -0.025233102962374687,
        0.0062035550363361835,
        0.034607235342264175,
        0.009380951523780823,
        -8.638142753625289e-05,
        0.023785118013620377,
        0.04802604019641876,
        0.005774643737822771,
        -0.0019361047307029366,
        -0.003985071089118719,
        -0.046501319855451584,
        0.020658478140830994,
        -0.018829230219125748,
        -0.013889484107494354,
        0.019293395802378654,
        0.02840075083076954,
        -0.0002037185913650319,
        -0.007321192882955074,
        0.0008115742821246386,
        -0.03310200944542885,
        0.015507184900343418,
        0.012564904987812042,
        0.019740868359804153,
        0.05197090283036232,
        -0.017797837033867836,
        -0.034572403877973557,
        -0.02793818898499012,
        -0.02207108773291111,
        0.0014535787049680948,
        -0.05533730611205101,
        -0.018512075766921043,
        -0.019755661487579346,
        0.03329719603061676,
        0.028737736865878105,
        0.046252887696027756,
        -0.002412043511867523,
        0.0028346870094537735,
        -0.03175198286771774,
        -0.03278980404138565,
        0.01807406172156334,
        0.045811500400304794,
        0.00488788029178977,
        -0.02963348478078842,
        0.0707557201385498,
        -0.01569930650293827,
        0.01157064363360405,
        -0.015258397907018661,
        0.012301124632358551,
        0.01802436262369156,
        0.0017104907892644405,
        0.004631396848708391,
        0.03421569988131523,
        -0.007177078165113926,
        -0.021238166838884354,
        0.004464395809918642,
        0.01068450789898634,
        0.05959588661789894,
        0.024912452325224876,
        0.0028654690831899643,
        -0.02028200775384903,
        0.02763468585908413,
        0.01109109353274107,
        0.00884933490306139,
        0.02835151180624962,
        -0.01819327473640442,
        0.029181471094489098,
        -0.0235843975096941,
        -0.004596080165356398,
        0.028988875448703766,
        0.009975024498999119,
        -0.04166548699140549,
        -0.0012704277178272605,
        0.030152974650263786,
        -0.027286283671855927,
        -0.02460167184472084,
        0.012748705223202705,
        -0.007354794070124626,
        0.013628094457089901,
        -0.02907552756369114,
        -0.04515252634882927,
        0.04539341479539871,
        -0.015120498836040497,
        0.0063211084343492985,
        -0.01881076768040657,
        0.03169845789670944,
        -0.012928023934364319,
        0.01337059773504734,
        -0.02827117033302784,
        -0.03965461254119873,
        -0.019369130954146385,
        -0.012532984837889671,
        0.020880505442619324,
        0.029772544279694557,
        0.008602356538176537,
        0.028813261538743973,
        0.0012716326164081693,
        -0.000804825802333653,
        -0.02964238077402115,
        0.034993790090084076,
        -0.0073174647986888885,
        -0.04040566086769104,
        0.03848358988761902,
        -0.023701395839452744,
        -0.013740244321525097,
        0.017395682632923126,
        0.025762803852558136,
        0.013971197418868542,
        0.011529232375323772,
        0.0047192685306072235,
        -0.010697681456804276,
        0.01844712719321251,
        0.016016226261854172,
        0.025164974853396416,
        0.005747528746724129,
        -0.013722123578190804,
        -0.032118599861860275,
        0.014438694342970848,
        -0.021415939554572105,
        0.04481162503361702,
        0.0001287979685002938,
        0.0020035626366734505,
        0.032868143171072006,
        -0.035303305834531784,
        0.004587077535688877,
        -0.02355119213461876,
        0.02938753552734852,
        0.012784749269485474,
        0.014748670160770416,
        0.011020869947969913,
        0.0072595784440636635,
        -0.006986990571022034,
        0.0141061469912529,
        -0.011668871156871319,
        -0.021688280627131462,
        0.019499627873301506,
        0.019847961142659187,
        0.005839225370436907,
        -0.014529351145029068,
        0.007896879687905312,
        -0.0010077875340357423,
        0.03371643275022507,
        0.014397282153367996,
        -0.0032667245250195265,
        0.017166204750537872,
        -0.007482935208827257,
        -0.007366201840341091,
        -0.011054541915655136,
        0.007129545323550701,
        0.007856713607907295,
        -0.010517443530261517,
        0.031574226915836334,
        -0.009279145859181881,
        -0.04903232306241989,
        -0.0024639982730150223,
        -0.01689348742365837,
        0.025031816214323044,
        0.02823127806186676,
        -0.0255450289696455,
        0.004361624829471111,
        -0.01789815165102482,
        -0.002921536797657609,
        0.0020625521428883076,
        -0.027530904859304428,
        -0.01578354649245739,
        -0.012003295123577118,
        0.022446686401963234,
        0.007648932747542858,
        0.005475466605275869,
        -0.023205813020467758,
        0.007684934418648481,
        0.016244184225797653,
        -0.04699384793639183,
        0.04594077914953232,
        0.007071982603520155,
        -0.022928288206458092,
        -0.02252833917737007,
        0.02877993881702423,
        0.006499054841697216,
        -0.03142008185386658,
        0.011302406899631023,
        0.04911414906382561,
        -0.02857494354248047,
        -0.010318877175450325,
        -0.004124030005186796,
        0.02469060942530632,
        -0.026235682889819145,
        0.002692403271794319,
        -0.0039632366970181465,
        -0.032398272305727005,
        -0.04293644800782204,
        0.02597085013985634,
        0.012418869882822037,
        0.012789552100002766,
        0.0011855977354571223,
        0.011959538795053959,
        0.0015994810964912176,
        -0.005846232641488314,
        0.010343307629227638,
        -0.0048304065130651,
        -0.00027814728673547506,
        -0.04297156631946564,
        -0.004656550008803606,
        -0.0018419948173686862,
        0.007665567100048065,
        -0.01328684575855732,
        -0.04374516382813454,
        -0.012988041155040264,
        0.01668953336775303,
        -0.010187569074332714,
        -0.005081423092633486,
        0.012025265954434872,
        -0.01620432734489441,
        0.04420192912220955,
        0.006736245471984148,
        0.011971062049269676,
        0.0006628866540268064,
        -0.0007358334260061383,
        -0.025276552885770798,
        -0.00090579385869205,
        -0.015673592686653137,
        0.032698195427656174,
        -0.009950202889740467,
        0.009365713223814964,
        -0.02340777963399887,
        0.006709137000143528,
        -0.012448067776858807,
        0.006942020729184151,
        0.03328665718436241,
        0.032489676028490067,
        0.001256836811080575,
        -0.0033356999047100544,
        0.014930550009012222,
        0.016746988520026207,
        0.0331084169447422,
        0.03406178951263428,
        0.0012606397503986955,
        0.01209298986941576,
        -0.000932818278670311,
        0.0056606135331094265,
        0.04137197136878967,
        0.031650472432374954,
        0.014315924607217312,
        -0.028323842212557793,
        0.009856831282377243,
        -0.023751115426421165,
        -0.009826669469475746,
        0.007668424863368273,
        0.010492494329810143,
        0.03546188026666641,
        0.007935653440654278,
        0.02707253396511078,
        -0.003112784354016185,
        0.003503204556182027,
        -0.012118542566895485,
        0.026296604424715042,
        -0.017633046954870224,
        -0.017196493223309517,
        -0.0022555142641067505,
        0.018047254532575607,
        0.003557830583304167,
        0.0025898385792970657,
        -0.014755954034626484,
        -0.004240609239786863,
        -0.009419192560017109,
        0.0024268373381346464,
        -0.021235540509223938,
        0.012507379055023193,
        -0.005401501897722483,
        0.022536728531122208,
        0.012154028750956059,
        0.01120530441403389,
        0.015278088860213757,
        -0.012478413991630077,
        -0.0357678085565567,
        0.028911186382174492,
        -0.031703222543001175,
        -0.008666404522955418,
        0.02500029094517231,
        -0.016915347427129745,
        -0.01842157170176506,
        -0.01572098396718502,
        0.012674382887780666,
        -0.006716908887028694,
        -0.05125788226723671,
        -0.014885266311466694,
        0.009630758315324783,
        -0.00018759799422696233,
        -0.0031769650522619486,
        -0.00296689011156559,
        0.024776365607976913,
        0.018996817991137505,
        -0.05012381076812744,
        -0.026699863374233246,
        0.0034078790340572596,
        0.059100192040205,
        -0.03701133653521538,
        0.0473429411649704,
        -0.00904138945043087,
        -0.01994404010474682,
        -0.016685152426362038,
        0.024604937061667442,
        0.04091138020157814,
        0.01684691198170185,
        -0.048584118485450745,
        -0.02589835412800312,
        0.007888734340667725,
        0.0009838342666625977,
        0.007304470054805279,
        0.02066146582365036,
        0.02114960364997387,
        0.00702299689874053,
        0.0030508784111589193,
        -0.012521334923803806,
        0.02337465062737465,
        0.005586656276136637,
        0.02686336264014244,
        -0.015442785806953907,
        -0.014572380110621452,
        -0.018155593425035477,
        -0.04011945798993111,
        -0.0009869184577837586,
        -0.012572193518280983,
        -0.004657966084778309,
        -0.014817725867033005,
        0.00569474883377552,
        -0.020726695656776428,
        -0.02984868548810482,
        -0.01128368265926838,
        -0.01910381205379963,
        -0.019227160140872,
        0.004235484637320042,
        -0.020852424204349518,
        0.0027094597462564707,
        -0.026864908635616302,
        0.016785407438874245,
        0.0035263136960566044,
        0.014578347094357014,
        0.056665368378162384,
        0.006322857923805714,
        0.01577928476035595,
        0.005493768025189638,
        0.03891546651721001,
        0.01429552398622036,
        -0.011478551663458347,
        -0.0007640189724043012,
        0.020979460328817368,
        0.0005717289168387651,
        -0.041490357369184494,
        0.025687910616397858,
        -0.022409213706851006,
        -0.002082859631627798,
        -0.024159159511327744,
        -0.04417506977915764,
        -0.014766777865588665,
        -0.03094242885708809,
        -0.03802131116390228,
        -0.012285829521715641,
        0.01007838174700737,
        -0.010901854373514652,
        0.006540632341057062,
        0.009836792014539242,
        0.026473261415958405,
        -0.059304140508174896,
        -0.003220918821170926,
        0.0007668388425372541,
        0.004412972368299961,
        0.053758010268211365,
        -0.033739157021045685,
        0.020793519914150238,
        0.00338000082410872,
        -0.015530494973063469,
        -0.023866400122642517,
        0.014904697425663471,
        0.013987163081765175,
        -0.009695448912680149,
        0.005668138153851032,
        -0.013097108341753483,
        -0.03168246150016785,
        0.03696883097290993,
        -0.004206815734505653,
        0.0016784494509920478,
        0.011349632404744625,
        0.008510492742061615,
        -0.0028374604880809784,
        -0.0032295039854943752,
        0.023716384544968605,
        0.07386026531457901,
        -0.018419794738292694,
        0.001382756745442748,
        -0.0027377160731703043,
        -0.004433513153344393,
        0.02966010570526123,
        0.0020242519676685333,
        -0.027001652866601944,
        0.009285308420658112,
        0.03721776232123375,
        0.023585250601172447,
        -0.005287535488605499,
        0.007644929923117161,
        -0.005955222062766552,
        -0.0010461964411661029,
        0.003269724315032363,
        -0.019145797938108444,
        0.01252038311213255,
        -0.02023961953818798,
        0.00870378315448761,
        0.0018626569071784616,
        -0.012871330603957176,
        0.02247430942952633,
        0.002550674369558692,
        0.0008471522596664727,
        0.029049281030893326,
        -0.034198738634586334,
        0.01817910373210907,
        0.008031430654227734,
        0.023138446733355522,
        0.03207135200500488,
        0.016860948875546455,
        0.005519278347492218,
        0.005276678595691919,
        0.004032833967357874,
        -0.03036842681467533,
        -0.010569197125732899,
        0.03448106721043587,
        -0.018771477043628693,
        -0.012584575451910496,
        -0.0005609293002635241,
        0.024663632735610008,
        0.007740756496787071,
        -0.016557959839701653,
        -0.023235877975821495,
        0.006556588225066662,
        -0.008845922537147999,
        0.04651310667395592,
        -0.0034449670929461718,
        0.028355132788419724,
        -0.01723027043044567,
        -0.01107080653309822,
        0.025657571852207184,
        0.03243033215403557,
        0.008575105108320713,
        -0.010209511034190655,
        0.020894614979624748,
        -0.01135217770934105,
        0.0013975566253066063,
        0.012253365479409695,
        -0.01328156515955925,
        -0.03940065577626228,
        -0.018246321007609367,
        -0.004784229211509228,
        -0.006697293370962143,
        -0.004384230822324753,
        -0.012866083532571793
      ],
      "title": "The Age of AI has begun"
    },
    {
      "id": "gai-eng_corpus-item005",
      "count": 5,
      "created": "2025-07-06T05:02:39.388344",
      "text": "\"If I Had Another Job, I Would Not Accept Data Annotation Tasks\": How Syrian Refugees in Lebanon Train AI Self-driving cars, robots, chatbots, drones, ChatGPT, and many other AI applications surround us daily. However, we rarely consider how these incredible technologies were created and who contributed to their development. Behind these sophisticated applications lies the hard work and dedication of countless data workers, who are often unrecognized. These individuals, whom I call the \"hidden soldiers\" of the Artificial Intelligence revolution, play a crucial yet overlooked role in the AI industry. Developing and maintaining artificial intelligence (AI) and machine learning (ML) models requires more than just engineers, scientists, and data analysts – data annotators are important, too. They are responsible for accurately labeling and classifying data, an essential task for training algorithms. They assign labels to the data and ensure that these labels are accurate and consistent. Data annotators may work with images, text, audio, or video, drawing bounding boxes around objects in images, transcribing speech, or tagging entities in text. Their tasks also include reviewing and validating annotations to maintain high data quality, following specific guidelines, and using various annotation tools to facilitate their work. As the use of artificial intelligence and machine learning expands across industries such as healthcare, finance, retail, and manufacturing, the demand for skilled data annotators continues to rise. While automation can assist and streamline some aspects of data annotation, human input remains crucial to ensure the accuracy, quality, and contextual understanding needed for effective AI and machine learning models. In this article, I explore the challenges faced by data annotators in Lebanon, focusing particularly on Syrian refugees. These data workers confront significant psychological and economic obstacles that prevent them from achieving financial stability. My experiences as a refugee in Lebanon, combined with my role as a supervisor and lead of an annotation team of 10 members (all of them graduates in Lebanon), provide valuable insights into the struggles of this community. Through direct engagement with the data labeling team and a series of interviews with them, I delve into the psychological impact of their work, their satisfaction with compensation, barriers to achieving work-life balance, and potential support from recruitment agencies. By participating in the Data Workers' Inquiry Project as a co-researcher, I hope I can amplify the voices of data workers, especially the data annotators, and ensure that their experiences resonate internationally. It is important to highlight how this marginalized group is restricted by Lebanon's strict labor laws and the limited availability of annotation projects and to capture their diverse perspectives and experiences to enrich our understanding of them and the industry. The focus on the psychological impact of this work and its relationship to wage satisfaction is closely related to my own experience. The lack of available job opportunities and reliance on a single source of income creates a climate of psychological stress and despair, which negatively affects well-being. By focusing on these issues, I aim to advocate for meaningful changes and better support for data workers in general and Syrian refugees in particular. Hundreds of Syrian college graduates in Lebanon face significant employment challenges due to restrictive government policies that only allow Syrian refugees to seek employment in the limited sectors of agriculture, construction, and cleaning. This leaves many educated Syrians unemployed and searching for alternative sources of income. Ola, a Syrian refugee who is pursuing her studies in the field of information technology and has extensive training in graphic design, for example, feels \"chained, outcast, and worthless\" whenever she applies for a job and is rejected because of her nationality. In Lebanon, Syrians registered as refugees with the United Nations High Commissioner for Refugees (UNHCR) are not allowed to obtain work permits except in the three fields mentioned. Ola used to secure paid volunteer opportunities with associations and organizations in Lebanon, which helped her generate income. However, due to Lebanon's deteriorating economic situation, many non-profit organizations started giving Lebanese citizens preference in their activities and have given priority to finding them opportunities. Strict labor laws that require Syrians to obtain a work permit, which is expensive and often difficult to acquire, have forced many Syrians to work without a permit, which is illegal and makes them vulnerable to exploitation. Because they work illegally, they remain at the mercy of their employers. For example, one person talks about the pay discrimination he experienced solely because of his nationality. He says: I previously did paid volunteer work with a company specialized in monitoring UNHCR projects for people with disabilities. I was receiving $50 a day, while my less qualified colleague was receiving $200 only because he was not Syrian. The work included conducting interviews, entering data, and writing reports. Another refugee described how she was paid little for her work collecting data for a research company. Due to a technical problem with her laptop, she was unable to submit her work on time and received only $300 of the promised $800. When she objected, she was told that there was no official contract because a Syrian is legally not allowed to do this work and she had to accept the reduced payment or not get anything at all. These stories are just simple examples that reflect the suffering and loss experienced by Syrian graduates. The war not only destroyed their country but also their dreams, to the point that it has become common to see a Syrian engineer or teacher working illegally as a greengrocer in Lebanon to earn a living. DATA ANNOTATION: A GLIMMER OF HOPE High-quality data annotation is a necessity for the functioning of artificial intelligence but is relatively new and not widely known in the Arab world. My colleagues and I began our journey in this field 2 years ago with Humans in the Loop (HITL), a social enterprise organization that connects conflict-affected communities with digital action by providing free demonstration courses and linking graduates to the labor market through paid projects. It was a strange field and the first time we heard about it -none of us had imagined that we would work in it before. We were very happy with this opportunity. Finally, there was a field in which we could work, show our skills, and feel our importance. I still remember my feeling when we worked on the first paid project. I felt that I had returned to life. The girl who holds a bachelor's degree in medical laboratory technology and is pursuing a master's degree in public health is no longer just a housewife, but she works remotely and earns an income, albeit a modest one. This was a very happy change for all of us. Hala, an annotator with HITL, shares her story too: \"In light of the strict labor laws in Lebanon, the paid projects offered by HITL become my only source of income. I studied English literature and completed many training courses, but I could not find a job because I am a Syrian refugee in Lebanon.\" This is how it started, but no journey is without obstacles. Even the medication used for treatment has side effects, and so does our journey with data annotation. As the negative effects of this work began to appear and affect the workers, our initial enthusiasm was no longer what it had been. THE PSYCHOLOGICAL IMPACT OF DATA ANNOTATION WORK Commitment to specific deadlines while maintaining high accuracy (minimum of 97%) is the foundation of data annotation. In our line of work, we are governed by time. As a team supervisor, ensuring smooth project progression and meeting deadlines is my responsibility. I oversee the work of all participants, striving to maintain high performance and effective progress. The pressure of ensuring timely delivery can be stressful, and this stress often reflects on my team members. I assign daily tasks to each member, regardless of their circumstances. During a project, I cannot tolerate excuses and expect complete dedication from all participants. Though I may seem strict, my actions are driven by the collective goal of project success, which ultimately means team success. This pressure is exacerbated by Lebanon's unreliable electricity and internet, forcing some annotators to pay extra for a stable connection, often spending $10-$30 on projects that might only pay $40-$150, just to ensure timely delivery. Additionally, I have to expect the annotators to be highly accurate in the tasks that they do; otherwise, the tasks will be returned to them to fix. This extra work is not paid, even though it takes just as long as the main tasks. Punctuality and accuracy are crucial for the entire team's benefit; any lapse can damage our reputation and make HITL hesitant to assign us future projects. We are treated as freelancers and not as employees, which results in a lack of job security and stability. This, combined with our stressful working conditions, has a very negative impact on us and adversely affects our psychological health. Can you imagine the feeling of being abandoned or unwanted if you make a mistake, especially when you have no alternative for work? As a data annotation team in Lebanon, we depend entirely on projects from Humans in the Loop for our livelihood. Due to Lebanon's strict labor laws, these projects are our main source of income. While we are committed to delivering high-quality results and are eager to work, the projects we receive are often irregular. Sometimes, we receive only one project every few months. Consistent projects are crucial for us to achieve financial stability and improve our quality of life. Many annotators feel compelled to accept any available work, even if they are not fully available to complete it, due to the irregular nature of the projects and their pressing need for income. Having a stable source of work is vital for us, as it would provide a more reliable income and alleviates the financial and psychological pressures we face. One annotator who holds a bachelor's degree in interior design but is currently unemployed shared, \"when we get a project, I cannot refuse it even if I am not free because we do not get projects regularly. I need to seize every opportunity despite the pressure it creates, which negatively affects my mental health. If we had projects regularly, I would apologize for participating in the project when I am not free.\" DATA ANNOTATION AND WAGE SATISFACTION We all believe that fair compensation is crucial for our psychological well-being. We stress that adequate pay not only improves our quality of life but also motivates us to work diligently, feeling that our efforts are valued and rewarded. One annotator who is an electrical engineer but is also currently unemployed stated, \"fair compensation will make me enjoy my work, and good compensation will encourage me to take better care of my health. It will enable me to afford healthy food and participate in sports clubs. If my compensation is low, I will not be able to manage these expenses.\" Conversely, low and unfair compensation negatively impacts our mental health and professional performance, causing stress and anxiety while reducing our motivation to work. Our desire to work stems not from satisfaction with our wages but from the necessity to secure ongoing projects, as we have no alternative employment options. Through my series of interviews, most people expressed dissatisfaction with the project allowances they receive, believing that the compensation is not commensurate with the effort they put in. They usually get cleaning projects, ensuring that the datasets they work on are free of errors and inconsistencies based on the client's instructions. These projects are simple and low-paying, with workers typically earning between 0.014 and 0.04 Euros per image. One annotator lamented, \"when we get a low-compensation project, we don't refuse it because we have no other options. It's better than no work, but we do it under duress. I complete my tasks just to get rid of them, not because I like what I do. In the cleaning projects, it seems that we exclude unwanted images with a 'click of a button,' but it actually requires a lot of attention and focus. Despite our efforts, we only earn 0.014 euros per image. These projects usually last between 7-14 days, and we spend 4-7 hours a day working on them. The effort is not equivalent to the pay; I finish 10,000 images for 140 euros. In Lebanon, this amount only covers food costs for 10 days. If I had another job, I would not accept data annotation tasks.\" The annotators do not have direct communication with the client. They obtain the project details through HITL, which sends them the guidelines, which often do not cover all the cases in the project dataset. These anomalous cases need to be discussed with HITL, who communicates with the client. Sometimes, after completing and delivering the project, the client may show dissatisfaction with the results and send further clarifications of the guidelines. In this case, the annotators must repeat the work again, applying the client's modifications, even though HITL ensures the quality and correct implementation of instructions before submission. Some annotators describe this as working twice on the same tasks, double efforts for a single price, and that is very annoying. One annotator asked,\"why do we have to show flexibility and re-implement the work eventhough it is not our fault, as the instructions were not clear from the beginning? Would it not be better for us to work in direct communication with the client to understand their needs? Is it fair to work twice on a project for one wage? We were compelled to depart our homeland and must confront the unjust regulations in Lebanon that obstructed our pursuit of careers. Are they assigning these tasks to us because we are refugees and they want to support us, or because we are a marginalized group that cannot demand their rights? Would a citizen of their country accept this work and effort for these wages?\" Data annotators repeatedly raise these inquiries, highlighting their powerless position. They have no choice but to accept the work assigned to them without objecting to its pay. They comply with all demands to ensure they get more opportunities, hoping that their efforts will be appreciated in the future and that they will get better projects and higher wages. EFFORTS TO FIND ADDITIONAL OPPORTUNITIES Many data annotators are looking for additional job opportunities through platforms like Remotask, Appen, and Upwork. However, the lack of access to bank and financial accounts greatly hampers their efforts. These platforms require accounts such as PayPal or Payoneer to make money transfers, but these options are not available to Syrian refugees in Lebanon due to legal restrictions. Refugees are prohibited from opening bank accounts and cannot access other financial services. The consequences are dire: refugees are unable to get paid for their work, limiting their ability to earn a living and achieve financial stability. This financial exclusion exacerbates the economic difficulties they face and perpetuates their marginalized position. To confront this injustice, some workers resort to using the accounts of trusted friends or family members outside Lebanon. However, this method does not always succeed. One annotator shared his experience, saying: \"I opened an account on the Appen platform, and for financial transfers, it requires a Pioneer account, so I put the financial account of a friend of mine in Iraq: I received an audio transcription project, which paid an excellent allowance of two dollars for each audio recording, although its duration did not exceed 15 seconds. In the end, I could not get the money because the financial account must match the person who created the account. My friend created an account in his name to match his financial account and redid the work on the tasks I had finished and only this way I was able to get the money that arrived in his account and send it to me via Western Union.\" Our financial compensation from HITLis processed through an intermediary organization in Lebanon which partners with HITL. The organization handles financial transfers and distributes the money to us via telegraphic transfer. We receive the money from the bank that is associated with this organization. Since a valid residence permit is not required to receive the money, the process is convenient, but it can take some time. We sometimes do not receive our work allowances until after two months. While these coping mechanisms provide temporary relief, they are not sustainable solutions. The international community and financial institutions must work to create comprehensive financial systems that accommodate the needs of refugees, ensure their ability to participate in the digital economy, and improve their financial well-being. CONCLUSION AND CALL TO ACTION The experiences of Syrian refugees working as data annotators in Lebanon highlight the urgent need to find solutions to the barriers they face. Despite their high skill levels and dedication, these workers are restricted by stringent and discriminatory labor laws. While digital work to some extent offers an alternative and is undoubtedly beneficial, the scarcity of project opportunities and inadequate compensation prevents these vulnerable workers from achieving financial stability and psychological well-being. Addressing these challenges requires the combined efforts of international organizations, governments, and the tech industry, as workers hope that their cries will reach those with power and that they will begin to make decisions that will contribute to improving their lives. Efforts should be made to allow refugees access to bank accounts and financial services, which are essential for receiving payments and achieving financial stability. Financial institutions should develop services tailored to the needs of refugees, including simplified banking procedures, mobile banking solutions, and special financial products that cater to the unique circumstances of displaced individuals. Stakeholders such as HITL should work to increase the availability of consistent, fair-paying project opportunities, such as having agreements specifying the number of projects that will be assigned to the teams during the year or the month. Fostering solidarity among data annotators can empower them to advocate for their rights and push for better working conditions. This could include forming unions or workers' councils to address issues and negotiate with employers and policymakers collectively. The data workers hope that the \"Data Workers Inquiries Project\" will raise awareness about the plight of refugee data annotators and can garner support and drive action from global stakeholders. It is time to act and ensure that the digital economy benefits all, including the most vulnerable and overlooked members of our global community.",
      "word_count": 3074,
      "character_count": 19435,
      "vector": [
        0.06725727766752243,
        -0.20526455342769623,
        0.09867215156555176,
        -0.037821754813194275,
        -0.014078058302402496,
        0.0425519123673439,
        -0.06825924664735794,
        0.04336521029472351,
        -0.007561822421848774,
        0.021470867097377777,
        0.014709057286381721,
        0.06854535639286041,
        -0.05017005652189255,
        -0.09250473231077194,
        0.033743828535079956,
        0.017536252737045288,
        -0.0854831337928772,
        -0.05638667941093445,
        -0.019639834761619568,
        -0.037295326590538025,
        0.009852567687630653,
        -0.08908266574144363,
        -0.008685220032930374,
        0.04571390151977539,
        -0.10097794979810715,
        0.05991905927658081,
        -0.07945822179317474,
        -0.020998219028115273,
        -0.07529930770397186,
        0.01212916150689125,
        0.1280106157064438,
        -0.06018802523612976,
        -0.02532402239739895,
        -0.06438834965229034,
        -0.04886402562260628,
        0.1219642385840416,
        -0.009949373081326485,
        0.03410593420267105,
        -0.031217273324728012,
        -0.04792430251836777,
        -0.00233735260553658,
        0.082645483314991,
        0.060489922761917114,
        -1.1176334737683646e-05,
        0.0813712328672409,
        0.06014283746480942,
        -0.04088449478149414,
        -0.06019994243979454,
        0.0033885017037391663,
        0.013380172662436962,
        0.009393385611474514,
        -0.02727908454835415,
        -0.06414835155010223,
        0.03897538408637047,
        0.07512501627206802,
        -0.05274675413966179,
        0.001973834354430437,
        -0.04582501947879791,
        0.011807326227426529,
        0.06149077042937279,
        -0.09522648900747299,
        0.060117606073617935,
        -0.019276665523648262,
        -0.006185820326209068,
        -0.023756904527544975,
        0.10689127445220947,
        0.044312383979558945,
        -0.026586733758449554,
        0.037463318556547165,
        -0.02624836191534996,
        0.02184072509407997,
        -0.016572434455156326,
        -0.025720613077282906,
        -0.006756039336323738,
        -0.005386958830058575,
        0.020927414298057556,
        0.0012203138321638107,
        -0.003372113686054945,
        -0.026505757123231888,
        -0.005088677164167166,
        0.05456872656941414,
        0.003907247446477413,
        0.04674888402223587,
        0.021041447296738625,
        0.061469804495573044,
        0.04872046038508415,
        -0.060160450637340546,
        -0.04109419137239456,
        0.03403580188751221,
        -0.021761009469628334,
        0.09648455679416656,
        0.0083352355286479,
        0.021358659490942955,
        -0.09834346920251846,
        0.01127501018345356,
        -0.019857419654726982,
        0.031348057091236115,
        0.03985195606946945,
        0.015875546261668205,
        -0.005177764222025871,
        0.03198487311601639,
        0.04887648671865463,
        -0.13458934426307678,
        -0.012728963047266006,
        -0.008346818387508392,
        0.05392839387059212,
        0.07233906537294388,
        0.02827267348766327,
        -0.09723605215549469,
        -0.044969186186790466,
        -0.023469092324376106,
        -2.1726720660808496e-05,
        0.012636188417673111,
        0.0419967956840992,
        0.06397277116775513,
        0.0341065488755703,
        0.02865978144109249,
        0.06884066760540009,
        0.08291894197463989,
        -0.012577186338603497,
        -0.013905064202845097,
        0.05303085595369339,
        -0.018617846071720123,
        0.0453869104385376,
        0.009420161135494709,
        -0.04074583947658539,
        -0.006461499258875847,
        -0.07085219025611877,
        -0.007820901460945606,
        0.008682748302817345,
        0.02187865786254406,
        0.034366000443696976,
        0.009162921458482742,
        0.024009456858038902,
        -0.04433925077319145,
        -0.02711069956421852,
        0.016047559678554535,
        -0.08242414146661758,
        -0.005227928981184959,
        0.039958760142326355,
        0.011132406070828438,
        0.0054845004342496395,
        -0.05365877225995064,
        0.0030041425488889217,
        0.006544487085193396,
        -0.03129773959517479,
        -0.02418609708547592,
        -0.054108116775751114,
        0.04434973746538162,
        0.011003837920725346,
        0.010233085602521896,
        -0.04865657910704613,
        0.0013984654797241092,
        0.0008523044525645673,
        -0.022465046495199203,
        0.011497076600790024,
        0.014816425740718842,
        0.027319055050611496,
        -0.03169328346848488,
        0.008590755052864552,
        0.016818169504404068,
        0.01015312597155571,
        0.008468788117170334,
        -0.06664840877056122,
        0.0037901951000094414,
        -0.013514353893697262,
        -0.032545387744903564,
        -0.004946147557348013,
        0.05492621660232544,
        -0.05079348757863045,
        -0.019495446234941483,
        0.035243336111307144,
        0.032844360917806625,
        -0.048585936427116394,
        0.006594598758965731,
        -0.004204278811812401,
        0.005422582384198904,
        0.07686746120452881,
        0.03574007377028465,
        0.01812278851866722,
        0.00830453634262085,
        0.010319424793124199,
        -0.05929698050022125,
        0.011024381034076214,
        -0.03460825979709625,
        0.019839974120259285,
        0.02485104650259018,
        0.04715292900800705,
        0.023889468982815742,
        0.051474906504154205,
        0.012012079358100891,
        -0.007826453074812889,
        0.039536003023386,
        0.05481967329978943,
        -0.001517169177532196,
        -0.014869500882923603,
        -0.022116798907518387,
        0.034154314547777176,
        -0.015977980569005013,
        -0.022940928116440773,
        -0.015894610434770584,
        -0.03278489410877228,
        -0.05315939709544182,
        0.015896236523985863,
        0.032387614250183105,
        0.009269417263567448,
        0.0029737965669482946,
        0.037075214087963104,
        -0.05059570446610451,
        -0.013855586759746075,
        0.002879553474485874,
        0.03655797243118286,
        -0.0009318787488155067,
        0.040290459990501404,
        -0.02191252075135708,
        0.01148988213390112,
        0.08108539879322052,
        0.029151467606425285,
        -0.007840151898562908,
        0.006430936977267265,
        0.0388462208211422,
        -0.017824744805693626,
        -0.02979675866663456,
        -0.0202194731682539,
        0.01718592271208763,
        -0.03177478536963463,
        0.054338306188583374,
        0.04069726541638374,
        0.03754565492272377,
        -0.03920543193817139,
        -0.04390616714954376,
        -0.04828418791294098,
        -0.013907603919506073,
        0.03379455581307411,
        0.03904859349131584,
        -0.07084307074546814,
        -0.039452001452445984,
        0.0017615989781916142,
        0.020047035068273544,
        -0.017495734617114067,
        0.0015510316006839275,
        0.008797855116426945,
        -0.06469763070344925,
        -0.03143680468201637,
        -0.11185118556022644,
        0.002781383227556944,
        -0.03327077999711037,
        -0.06760583817958832,
        -0.04229728877544403,
        0.010600059293210506,
        0.028272053226828575,
        -0.029581770300865173,
        -0.04754825308918953,
        -0.07513171434402466,
        0.0022841612808406353,
        -0.007973588071763515,
        0.012460549362003803,
        0.006777620408684015,
        -0.029609741643071175,
        0.03635340556502342,
        -0.030286500230431557,
        0.00037765101296827197,
        0.010973900556564331,
        0.02117588184773922,
        0.019314490258693695,
        0.01914980448782444,
        -0.02374209463596344,
        0.0025138964410871267,
        0.01697322353720665,
        -0.0640573650598526,
        0.0032123480923473835,
        -0.06435606628656387,
        -0.0117406714707613,
        0.04493792727589607,
        0.015660641714930534,
        -0.02500571496784687,
        0.030710402876138687,
        0.025141801685094833,
        -0.004208195023238659,
        -0.04348267242312431,
        -0.03152387589216232,
        0.01076494250446558,
        -0.04550675302743912,
        -0.03871186077594757,
        -0.026670288294553757,
        -0.01487899199128151,
        -0.0011840243823826313,
        0.044070299714803696,
        -0.009462031535804272,
        -0.0232989639043808,
        0.026427773758769035,
        -0.013869321905076504,
        -0.017415504902601242,
        -0.009869249537587166,
        -0.006004886701703072,
        0.06052715331315994,
        -0.025547610595822334,
        -0.0032833407167345285,
        0.027471354231238365,
        0.04518507421016693,
        -0.021348655223846436,
        0.04369959607720375,
        0.03862200677394867,
        0.003295124275609851,
        -0.01002525258809328,
        0.016302812844514847,
        -0.04896093159914017,
        -0.04185302183032036,
        0.006615291815251112,
        0.026508033275604248,
        -0.006630202289670706,
        -0.011112777516245842,
        0.004864612128585577,
        -0.0032515833154320717,
        0.040373850613832474,
        0.025472797453403473,
        -0.03129962831735611,
        0.022534426301717758,
        0.004963301587849855,
        -0.010509421117603779,
        -0.019726863130927086,
        0.014298227615654469,
        0.014577323570847511,
        0.019895566627383232,
        -0.008498838171362877,
        -0.025669323280453682,
        0.027332928031682968,
        0.0348455086350441,
        -0.015187340788543224,
        0.005505443084985018,
        0.0020430919248610735,
        0.010437432676553726,
        0.03619677573442459,
        0.031053779646754265,
        -0.0059402682818472385,
        0.0071622529067099094,
        -0.025414954870939255,
        0.0072719077579677105,
        -0.011809772811830044,
        0.02303764969110489,
        0.012382595799863338,
        -0.03355080261826515,
        0.03703320026397705,
        -0.012639477849006653,
        -0.008405216038227081,
        0.051614463329315186,
        0.003993823658674955,
        -0.002552524209022522,
        0.0330856516957283,
        -0.010956094600260258,
        0.003668333636596799,
        0.0071357558481395245,
        0.00415987242013216,
        -0.018427373841404915,
        -0.0270297322422266,
        0.029241302981972694,
        -0.02418602630496025,
        -0.031121384352445602,
        -0.028517374768853188,
        -0.025643331930041313,
        -0.007895244285464287,
        -0.029439829289913177,
        -0.020048009231686592,
        0.03774065151810646,
        0.030684202909469604,
        -0.004067312926054001,
        0.03609587997198105,
        0.02063148096203804,
        -0.010858239606022835,
        -0.009105551056563854,
        -0.022725528106093407,
        -0.01829000748693943,
        0.02295399270951748,
        -0.009390837512910366,
        0.016635039821267128,
        0.004325495567172766,
        0.012005932629108429,
        0.0007561299717053771,
        0.02445237711071968,
        0.019348083063960075,
        -0.010415693745017052,
        -0.022500138729810715,
        0.022301509976387024,
        0.009983701631426811,
        0.0008014955674298108,
        0.02173173986375332,
        0.07647719979286194,
        -0.04270860552787781,
        0.011786733753979206,
        -0.02598295360803604,
        -0.034215983003377914,
        -0.007349624298512936,
        -0.030290726572275162,
        -0.020396823063492775,
        -0.010494312271475792,
        -0.031864553689956665,
        0.049879223108291626,
        -0.03625647723674774,
        0.009557622484862804,
        0.023644939064979553,
        0.01555383950471878,
        0.01657104678452015,
        -0.028438502922654152,
        -0.009943668730556965,
        0.021037915721535683,
        8.562968287151307e-05,
        -0.011722780764102936,
        0.00225437106564641,
        -0.03809841349720955,
        0.0027961726300418377,
        -0.02070975862443447,
        -0.016996759921312332,
        -0.053791701793670654,
        -0.006855654530227184,
        -0.03409990668296814,
        -0.041304945945739746,
        0.01441625040024519,
        0.02146652527153492,
        -0.009043092839419842,
        0.03678137809038162,
        -0.02919691614806652,
        0.01242128573358059,
        -0.02554398961365223,
        -0.011381090618669987,
        -0.009871292859315872,
        -0.01522909477353096,
        -0.02754746749997139,
        -0.03948794677853584,
        -0.0033011490013450384,
        0.014623401686549187,
        0.02943236567080021,
        0.003924453631043434,
        -0.0163295678794384,
        0.04108403995633125,
        0.03394148126244545,
        -0.033556338399648666,
        -0.01736077480018139,
        0.010361825115978718,
        0.011887782253324986,
        0.0209296066313982,
        -0.000897400313988328,
        0.03257645294070244,
        0.010342864319682121,
        -0.014856069348752499,
        0.034646227955818176,
        -0.0059285894967615604,
        0.06384900212287903,
        -0.01188991591334343,
        -0.011535771191120148,
        -0.02944674901664257,
        -0.058050721883773804,
        0.028203828260302544,
        -0.005986901465803385,
        0.012638511136174202,
        -0.0029419311322271824,
        -0.037277985364198685,
        -0.013123863376677036,
        0.020128287374973297,
        0.0034174693282693624,
        0.02991711162030697,
        -0.010249900631606579,
        -0.012155373580753803,
        0.023667069151997566,
        0.0060664936900138855,
        0.06403148919343948,
        0.014535107649862766,
        -0.0014280169270932674,
        -0.017355836927890778,
        0.03489130735397339,
        -0.0011853649048134685,
        0.04352583363652229,
        0.020817464217543602,
        -0.024973958730697632,
        -0.006568180397152901,
        -0.007985522970557213,
        -0.014925623312592506,
        -0.02395671233534813,
        -0.04548318684101105,
        -0.017487073317170143,
        -0.011037556454539299,
        -0.008060866966843605,
        -0.04216231778264046,
        -0.008008499629795551,
        0.03648073598742485,
        0.02858797088265419,
        0.009241322055459023,
        0.0011391389416530728,
        -0.009638934396207333,
        0.02785506285727024,
        0.05517853423953056,
        0.026392154395580292,
        -0.026252618059515953,
        -0.03628576546907425,
        0.03971057012677193,
        0.00817827694118023,
        0.03125736862421036,
        0.008903136476874352,
        -0.0014576552202925086,
        -0.026716820895671844,
        -0.06261218339204788,
        -0.041884150356054306,
        -0.02230079285800457,
        -0.007374389097094536,
        0.021527312695980072,
        -0.0016894100699573755,
        -0.055096592754125595,
        -0.022160541266202927,
        0.00260690925642848,
        0.005165292881429195,
        -0.025517050176858902,
        -0.05754922702908516,
        0.010089714080095291,
        0.02508625201880932,
        -0.026923347264528275,
        0.04041373357176781,
        0.005550967529416084,
        0.016190437600016594,
        0.0034425018820911646,
        0.003839110489934683,
        -0.021362628787755966,
        0.010614183731377125,
        0.022546805441379547,
        0.09114715456962585,
        -0.06091858446598053,
        0.05647921934723854,
        0.011734478175640106,
        0.014493325725197792,
        0.007430410943925381,
        0.00395545968785882,
        -0.0005784293171018362,
        0.01580829545855522,
        0.010404175147414207,
        0.04611508175730705,
        -0.02293778397142887,
        -0.013190804049372673,
        -0.0040849559009075165,
        -0.0020292808767408133,
        -0.008874207735061646,
        0.02437305822968483,
        0.042467858642339706,
        -0.021236231550574303,
        -0.05669105798006058,
        -0.019687358289957047,
        -0.034074775874614716,
        -0.054243143647909164,
        -0.0012748624430969357,
        0.028228726238012314,
        -0.008142736740410328,
        0.03414870426058769,
        0.03482367470860481,
        -0.02327752858400345,
        0.0017052515177056193,
        0.018071621656417847,
        0.004699110984802246,
        3.1576782930642366e-05,
        -0.013349822722375393,
        0.0021884222514927387,
        -0.0015528638614341617,
        -0.020874490961432457,
        0.0008482961566187441,
        0.017261814326047897,
        -0.0009645696845836937,
        0.009490746073424816,
        -0.03242238983511925,
        -0.04494740068912506,
        -0.04765155538916588,
        -0.004849493969231844,
        -0.009613349102437496,
        -0.030942795798182487,
        0.050924334675073624,
        0.000563593115657568,
        -0.007888776250183582,
        -0.0384526252746582,
        -0.006866778712719679,
        -0.0011567163746804,
        0.011578762903809547,
        0.014259970746934414,
        0.05081784725189209,
        -0.015424034558236599,
        0.008506674319505692,
        -0.009018081240355968,
        -0.0382537841796875,
        -0.019677074626088142,
        -0.0030711027793586254,
        -0.003323631128296256,
        0.033084385097026825,
        0.008703379891812801,
        -0.038785915821790695,
        -0.01871347986161709,
        -0.03865993022918701,
        0.03225461766123772,
        -0.00033260369673371315,
        0.028884707018733025,
        0.008126596920192242,
        0.030638154596090317,
        0.00939499493688345,
        -0.04244158789515495,
        -0.04309063032269478,
        0.0027598226442933083,
        -0.03444985672831535,
        -0.031073374673724174,
        -0.05064798519015312,
        -0.014215171337127686,
        0.014218747615814209,
        0.021616719663143158,
        0.04674307629466057,
        -0.035965412855148315,
        -0.003752270480617881,
        -0.00751912035048008,
        -0.03402706980705261,
        -0.01003081351518631,
        0.06007444113492966,
        -0.019146770238876343,
        0.033771440386772156,
        0.04894841089844704,
        -0.010067261755466461,
        0.0027251543942838907,
        0.01884409785270691,
        -0.0016085560200735927,
        0.009022264741361141,
        -0.016583800315856934,
        -0.0372336320579052,
        0.028256142511963844,
        0.018809791654348373,
        -0.012888551689684391,
        -0.003191848751157522,
        0.024476392194628716,
        0.030299272388219833,
        -0.028927141800522804,
        0.016063962131738663,
        0.009857106022536755,
        0.04012291505932808,
        -0.030318401753902435,
        -0.01629175990819931,
        -0.0010602866532281041,
        0.012545466423034668,
        0.0127689428627491,
        -0.02445993758738041,
        0.021741630509495735,
        0.042750779539346695,
        0.0018654062878340483,
        -0.01023886539041996,
        -0.006972394417971373,
        0.029220594093203545,
        -0.006942656356841326,
        0.01744719035923481,
        0.017405247315764427,
        -0.001729830983094871,
        0.046984490007162094,
        -0.0509854294359684,
        0.042407453060150146,
        0.0470040962100029,
        0.013300015591084957,
        0.025679484009742737,
        -0.03535977005958557,
        0.005238151177763939,
        -0.058196909725666046,
        0.004790537990629673,
        -0.0488307811319828,
        0.009788118302822113,
        -0.006610153242945671,
        -0.01646081730723381,
        0.04160863906145096,
        0.0015202187933027744,
        -0.0017181782750412822,
        2.6892375899478793e-05,
        0.0013053653528913856,
        0.014869102276861668,
        -0.002371625741943717,
        0.02048441208899021,
        0.031086696311831474,
        0.030223218724131584,
        0.026989193633198738,
        -0.006826404482126236,
        -0.010700695216655731,
        -0.008151567541062832,
        -0.013537473976612091,
        -0.024809932336211205,
        -0.008237222209572792,
        -0.003565227845683694,
        -0.0003519704332575202,
        -0.005576336290687323,
        0.012609018012881279,
        0.009095726534724236,
        -0.036887746304273605,
        -0.017958248034119606,
        0.003394225612282753,
        0.010201253928244114,
        -0.007479970343410969,
        0.005655763670802116,
        -0.007108655292540789,
        -0.019526368007063866,
        0.0062226783484220505,
        -0.02387687750160694,
        0.035237666219472885,
        0.001648975652642548,
        0.027392715215682983,
        0.016316311433911324,
        0.012614436447620392,
        0.018025891855359077,
        -0.004423718899488449,
        -0.027562763541936874,
        0.029801741242408752,
        0.017733829095959663,
        -0.011701738461852074,
        0.040915798395872116,
        -0.023809265345335007,
        0.033702168613672256,
        -0.025180086493492126,
        0.06735081970691681,
        -0.03378373757004738,
        0.0024727219715714455,
        0.010336542502045631,
        -0.004517728462815285,
        0.0026157947722822428,
        -0.027193397283554077,
        0.008467837236821651,
        0.0001319869770668447,
        0.014817090705037117,
        -0.03781434893608093,
        0.011316481046378613,
        -0.024051494896411896,
        -0.007911460474133492,
        0.010187292471528053,
        -0.047504957765340805,
        0.01141477469354868,
        0.03490035980939865,
        0.014194317162036896,
        -0.022053806111216545,
        0.011544141918420792,
        0.0030156243592500687,
        0.026833048090338707,
        0.0011460069799795747,
        -0.0124330073595047,
        0.014500431716442108,
        -0.019669247791171074,
        0.014337587170302868,
        -0.009522232227027416,
        0.046425506472587585,
        -0.017094412818551064,
        -0.004503030329942703,
        0.047679416835308075,
        -0.02633500285446644,
        0.022894514724612236,
        0.005239858757704496,
        -0.01431550644338131,
        0.028934290632605553,
        -0.006312971469014883,
        0.0011715602595359087,
        0.00877150148153305,
        -0.00846775807440281,
        0.0229769516736269,
        0.003957926295697689,
        -0.01702192984521389,
        -0.00778422225266695,
        0.0016438693273812532,
        -0.02612805739045143,
        0.0085812509059906,
        0.007772871293127537,
        -0.06189018860459328,
        -0.07976682484149933,
        0.023365354165434837,
        -0.025285150855779648,
        0.023813728243112564,
        -0.021751360967755318,
        0.0033744731917977333,
        0.00946501363068819,
        0.003697626292705536,
        -0.009586832486093044,
        -0.014906602911651134,
        -0.0070663932710886,
        0.02989502064883709,
        0.016435446217656136,
        -0.009170456789433956,
        0.0017953868955373764,
        0.007183648180216551,
        -0.005388244055211544,
        -0.008759044110774994,
        0.01623283140361309,
        -0.01641274429857731,
        -0.020639954134821892,
        -0.026993395760655403,
        -0.0336555577814579,
        0.01003899984061718,
        0.007967885583639145,
        -0.01633387617766857,
        -0.013613306917250156,
        0.01825759746134281,
        -0.011640835553407669,
        -0.004976541269570589,
        -0.01689896732568741,
        -0.004638016223907471,
        -0.05493239313364029,
        0.04937664046883583,
        -0.026499534025788307,
        -0.023477602750062943,
        -0.023494333028793335,
        -0.011341883800923824,
        0.034665267914533615,
        0.04697341099381447,
        0.018059825524687767,
        -0.035687029361724854,
        -0.02530108578503132,
        -0.027743659913539886,
        0.019072407856583595,
        0.008870013989508152,
        0.007076059468090534,
        0.017829300835728645,
        -0.0010701027931645513,
        0.0018080724403262138,
        0.03359585627913475,
        -0.03099150024354458,
        0.043217308819293976,
        -0.031380169093608856,
        -0.0015519876033067703,
        -0.034867528825998306,
        -0.00021104472398292273,
        -0.02640184573829174,
        -0.013627196662127972,
        0.031189383938908577,
        -0.004536718595772982,
        -0.020357223227620125,
        -0.026086360216140747,
        -0.0018438161350786686,
        0.015873050317168236,
        0.023269452154636383,
        -0.0084405317902565,
        -0.016630345955491066,
        -0.00338953360915184,
        0.006817493122071028,
        -0.01097489707171917,
        0.037312816828489304,
        -0.0044525396078825,
        0.0186566524207592,
        -0.014309381134808064,
        -0.02013605274260044,
        0.009650042280554771,
        0.02254585362970829,
        -0.02741321735084057,
        0.0027961842715740204,
        -0.011876524426043034,
        0.01345186959952116,
        0.0030104925390332937,
        0.009790516458451748,
        -0.005888426676392555,
        0.014456909149885178,
        -0.0013392374385148287,
        -0.0071503580547869205,
        0.002591392258182168,
        -0.029780134558677673,
        -0.008690670132637024,
        -0.014117932878434658,
        0.011228103190660477,
        -0.0034335439559072256,
        0.01485278457403183,
        -0.031549468636512756,
        -0.015285946428775787,
        0.02086716704070568,
        -0.016866348683834076,
        -0.008351081050932407,
        -0.024074368178844452,
        0.014941091649234295,
        -0.03254830092191696,
        -0.026279013603925705,
        0.018220510333776474,
        0.037554286420345306,
        -0.034098975360393524,
        0.04560892656445503,
        -0.03242466226220131,
        0.0038803888019174337,
        0.022580118849873543,
        0.017167307436466217,
        0.03934936970472336,
        0.021758737042546272,
        0.011357501149177551,
        -0.06185917183756828,
        -0.02408881112933159,
        -0.00783889926970005,
        -0.022120172157883644,
        0.01362360268831253,
        0.038034092634916306,
        0.010789010673761368,
        0.02193855307996273,
        -0.020988229662179947,
        0.03507218509912491,
        0.012140018865466118,
        0.05176457762718201,
        -0.0029858381021767855,
        -0.00017710990505293012,
        0.00261754565872252,
        -0.002227174350991845,
        0.016542959958314896,
        0.005663464777171612,
        -0.015883173793554306,
        -0.0022235822398215532,
        0.006047595292329788,
        -0.021762609481811523,
        0.009107180871069431,
        0.022393526509404182,
        -0.026053307577967644,
        -0.02533075585961342,
        0.052495457231998444,
        -0.010156392119824886,
        -0.002990871202200651,
        -0.00021191409905441105,
        0.01833917573094368,
        0.011720441281795502,
        0.00811119843274355,
        -0.004005966708064079,
        0.005613739136606455,
        0.040690500289201736,
        7.266413740580902e-05,
        0.029000554233789444,
        0.047897178679704666,
        0.01944325864315033,
        0.01294518169015646,
        -0.0035958208609372377,
        0.02093246579170227,
        -0.0056505585089325905,
        0.0005662991316057742,
        0.0018122897017747164,
        0.006212290376424789,
        0.009040309116244316,
        -0.06097553297877312,
        0.012534011155366898,
        9.83696518233046e-05,
        -0.02719058096408844,
        -0.011740597896277905,
        0.027704617008566856,
        -0.0034713472705334425,
        0.0159674733877182,
        0.008377999998629093,
        0.002657032571732998,
        0.000559078122023493,
        0.0017711854306980968,
        0.007859312929213047,
        0.023604735732078552,
        -0.01846700720489025,
        0.0083575788885355,
        0.036868445575237274,
        -0.0316140241920948,
        0.003799671772867441,
        -0.024310700595378876,
        0.03668023645877838,
        0.0027004347648471594,
        -0.01990889571607113,
        0.04697974771261215,
        -0.024741413071751595,
        -0.017645910382270813,
        0.006391115952283144,
        -0.004410304594784975,
        0.051145248115062714,
        0.0068054646253585815,
        -0.000805799150839448,
        -0.013012687675654888,
        -0.02517949976027012,
        0.010162711143493652,
        0.029810458421707153,
        -0.03530855476856232,
        0.03503495454788208,
        0.00037226133281365037,
        -0.008553802967071533,
        -0.03495047241449356,
        0.0019891096744686365,
        -0.008813858032226562,
        0.008230450563132763,
        0.043283555656671524,
        0.013083099387586117,
        -0.006603039335459471,
        0.03177448362112045,
        0.012863216921687126,
        -0.020727450028061867,
        -0.029676644131541252,
        0.011337734758853912,
        0.01242375373840332,
        0.03399832174181938,
        -0.00140091753564775,
        0.04917752370238304,
        -0.01232414972037077,
        0.012228156439960003,
        -0.0014211918460205197,
        0.0032146377488970757,
        0.008723859675228596,
        -0.01702716574072838,
        0.007672818843275309,
        0.014108761213719845,
        0.0035619733389467,
        0.03157193586230278,
        0.025801504030823708,
        0.006316280458122492,
        0.007080269046127796,
        0.0070493705570697784,
        -0.05314388871192932,
        -0.006563151720911264,
        -0.011153656989336014,
        -0.025047732517123222,
        -0.015257889404892921,
        -0.016550850123167038,
        0.012824829667806625,
        -0.017458058893680573,
        0.0031745582818984985,
        0.00359556102193892,
        0.014022169634699821,
        -0.005091049242764711,
        -0.002113636350259185,
        -0.019644666463136673,
        -0.013838600367307663,
        -0.01755717396736145,
        0.009140831418335438,
        0.0006338852690532804,
        0.0525178536772728,
        0.04661392420530319,
        -0.011250127106904984,
        0.02408509887754917,
        0.00947967916727066,
        0.019724048674106598,
        -0.011343210004270077,
        -0.00026313806301914155,
        -0.023563100025057793,
        -0.0009773843921720982,
        -0.0009714109473861754,
        0.0265020914375782,
        -0.039250824600458145,
        0.006018404383212328
      ],
      "title": "\"If I Had Another Job, I Would Not Accept Data Annotation Tasks\": How Syrian Refugees in Lebanon Train AI"
    },
    {
      "id": "gai-eng_corpus-item006",
      "count": 6,
      "created": "2025-07-06T05:07:15.621662",
      "text": "Copyright and Artificial Intelligence Part 3: Generative AI Training, Pre-Publication Version INTRODUCTION This Part of the Copyright Office's Report on Copyright and Artificial Intelligence addresses the use of copyrighted works in the development of generative AI systems. The groundbreaking technologies involved draw on massive troves of data, including copyrighted works, to enable the extraordinary capabilities they now offer to the public. Do any of the acts involved require the copyright owners' consent or compensation? And to the extent they do, how can that feasibly be accomplished? These issues are the subject of intense debate. Dozens of lawsuits are pending in the United States, focusing on the application of copyright's fair use doctrine. Legislators around the world have proposed or enacted laws regarding the use of copyrighted works in AI training, whether to remove barriers or impose restrictions. The stakes are high, and the consequences are often described in existential terms. Some warn that requiring AI companies to license copyrighted works would throttle a transformative technology, because it is not practically possible to obtain licenses for the volume and diversity of content necessary to power cutting-edge systems. Others fear that unlicensed training will corrode the creative ecosystem, with artists' entire bodies of works used against their will to produce content that competes with them in the marketplace. The public interest requires striking an effective balance, allowing technological innovation to flourish while maintaining a thriving creative community. Pursuant to the Register of Copyrights' statutory responsibility to \"[c]onduct studies\" and \"[a]dvise Congress on national and international issues relating to copyright,\" the Office published a Notice of Inquiry (NOI) in August 2023 posing a series of questions about copyright and AI. These included technical questions about how copyrighted works are collected, curated and used in training AI models, legal questions about the application of the fair use doctrine, and factual questions about existing or potential licensing arrangements. Of the more than 10,000 comments received in response to the NOI, the overwhelming majority addressed one or more of these questions. The Office refers to these comments throughout the discussion below. This Part of the Report proceeds as follows: Section II provides a technical overview of how generative AI systems are developed and deployed, as relevant to the copyright analysis. Section III identifies points in the development of generative AI systems where copying or other acts implicating copyright rights may occur. Section IV analyzes how the fair use doctrine may apply to those acts. Section V examines the practicality and advisability of various licensing options. Without opining on specific cases, we provide an analytical framework for identifying relevant facts and policy considerations. In so doing, we draw on substantial experience advising Congress, the courts, and the public on the fair use doctrine. The Office's analysis is necessarily limited to current circumstances and publicly available information. We recognize that the technology and markets involved are rapidly evolving, and courts and policymakers are at early stages in their considerations. As with other Parts of this Report, we will continue to monitor developments to determine whether any conclusions should be revisited. Finally, we note that other parts of the U.S. government are also engaged on these important issues. In addition to ongoing activities in the courts and Congress, the White House is developing an AI Action Plan to advance America's AI leadership and has received public comments, including on the subject of intellectual property. TECHNICAL BACKGROUND This section describes how and why copyrighted works are used in the development of generative AI models. We begin by explaining how machine learning is applied to create generative AI models, using language models as an example. We then turn to the data required to train generative models and the nature of its use by developers. We describe different phases of training and the relationship between trained models and their training data. Finally, we address the deployment of models in generative AI systems, which may have a variety of purposes and incorporate software or processes intended to augment or restrict their behavior. Machine Learning Machine learning is a field of artificial intelligence focused on designing computer systems that can automatically learn and improve based on data or experience, without relying on explicitly programmed rules. The basic technique involves creating a statistical model using examples of inputs and expected outputs, called \"training data,\" along with a metric of how well the model performs. For example, machine learning can model the relationship between a company's advertising expenditures and product sales. The training examples would be past expenditure and sales data, while the performance metric would be the difference between predicted and actual sales. By measuring its performance on training examples and using that as feedback to make adjustments, the model \"learns\" from the data. The goal is to develop a model that does not simply memorize training data, but reflects patterns or inferences that extend to new, or unseen situations, a concept called \"generalization.\" Generative AI relies on a subset of machine learning that builds models using neural networks. Broadly speaking, neural networks are mathematical functions that map, or transform, input data to output data. These functions are described by a general structure and large collections of numbers, called parameters, which define the mapping of inputs to outputs. With billions of parameters, collectively referred to as the network's \"weights,\" modern neural networks are capable of computing highly complex transformations, such as the conversion of text to video. When a neural network is first created, its weights are assigned random numbers, and it will not convert inputs to meaningful outputs. By repeatedly exposing the network to training examples, measuring its performance on those examples, and making small adjustments to the weights in a direction that improves performance—sometimes analogized to tweaking and turning \"knobs and dials\"—the network approximates or \"learns\" how to transform inputs into expected outputs. Accordingly, while code defines the basic structure of a neural network, it is the weights that reflect patterns learned from the training data, and which are most likely to be treated as proprietary by developers or draw the scrutiny of copyright owners. After training, some developers use weights directly in their own products, while others distribute them to the public for use or further training. Generative Language Models Given the line: \"[i]t was the best of times, it was the worst of times, it was the age of wisdom, it was the age of . . .,\" many would be able to guess that the next word is \"foolishness.\" Even if one is not familiar with A Tale of Two Cities, the context indicates that the next word is likely to be an antonym of \"wisdom.\" This is not an unusual task for humans—we can all sometimes finish another's sentences. This task can also be mathematically modeled. A statistical model of language can be represented by the probability of the next word given all the preceding words or \"context.\" By using a model to select a probable next word based on context, and then repeating the process, an AI system can take a short prompt and generate a continuing stream of language. As Professor Murry Shanahan noted: [W]e might give [a large language model] the prompt 'Twinkle twinkle,' to which it will most likely respond 'little star.' On one level, we are asking the model to remind us of the lyrics of a well-known nursery rhyme. But in an important sense what we are really doing is asking it the following question: Given the statistical distribution of words in the public corpus, what words are most likely to follow the sequence 'Twinkle twinkle'? To which an accurate answer is 'little star.' In practice, models estimate probabilities for \"tokens\" rather than words themselves. These are numbers that are pre-assigned or \"indexed\" to particular words, pieces of words, or punctuation marks. Because neural networks are mathematical functions, text must be converted to a numerical format for processing. Tokens simply bridge the two formats, providing the unit of analysis for the model (i.e., what it takes as an input and predicts as an output). Example of text converted to a sequence of tokens prior to input. Currently, generative language models are typically trained with a technique called \"generative pre-training.\" During generative pre-training, text examples serve as both the input and expected output, with performance measured by how well the model predicts each next token (output) based on preceding tokens (input). Consider a training example beginning: \"There are few people in England, I suppose, who have more true enjoyment of music than myself, or a better natural taste. If I had ever learnt, I should have been a great proficient . . .\" Generative pre-training would generate predictions for each token in the example (except the first, which has no prior context), evaluate those predictions compared to the correct tokens (i.e., the ones that appeared in the training example), and then make small adjustments to the model's weights to increase the likelihood of the correct tokens. In other words, pre-training would adjust the model weights to increase the likelihood of the word \"people\" following the phrase \"there are few,\" and so on for each token throughout the length of the training example. This process is then repeated across many examples or batches of examples—some with similar introductions, e.g., \"There are few sights sadder than a ruined book . . .\"—with the goal of learning a general model of language that can then be adapted for specific tasks. Several years ago, researchers realized that by scaling this process—in other words, pre-training language models with more parameters, on more data, and with more computing power—it was possible to develop general purpose models that could perform well on a variety of diverse language-based tasks without the need for additional task-specific training. Simply providing these models with natural language directions and then using them to iteratively predict each next token led to surprisingly good results. For example, early pre-trained models could answer SAT analogy questions and translate English sentences to French with prompting alone (e.g., \"Q: what is the French translation of {sentence} A:\"). Although we have been discussing language models, the same general principles apply to generative models for other types of content such as images, video, and audio. For example, image models can be trained using a combination of text and image tokens and a similar next-token prediction objective. The text tokens come from descriptive captions for the images (whether human-authored or computer-generated) and provide context for iteratively predicting the image tokens. Like language models, generative models for other types of content demonstrate sophisticated abilities when their training is scaled to large numbers of examples. Training Data Below we discuss the characteristics that developers look for in training data, how they acquire it, and how they curate it for use in training. Data Characteristics The developers of generative AI models may consider many factors when compiling data for training. These include the quantity of data, its quality, and the ultimate purpose(s) of the model. Quantity. Generative AI models \"are well-known for requiring . . . millions or billions of works for training purposes.\" When not bottlenecked by other factors, such as computing power, increasing the quantity of training data typically increases a model's \"performance,\" that is, its ability to make accurate predictions on test data not seen during training. That performance has, so far, been associated with the ability of generative AI models to perform well on downstream tasks. The scaling phenomenon has created a strong demand for data. Some researchers have even suggested that, if current trends continue, language model training will soon exhaust the stock of publicly available text. It is an open question, however, how much data an AI developer needs, and the marginal effect of more data on a model's capabilities. Not everyone agrees that further increases in data and test performance will necessarily lead to continued real world improvements in utility. Developers have also begun exploring techniques for training competitive models with less data. For example, researchers from Cornell trained a generative image model, Common Canvas, on approximately 70 million Creative-Commons-licensed images. They claim the model has \"comparable performance\" to Stability AI's Stable Diffusion 2, even though it was trained on a substantially smaller dataset. Quality. The performance of models also depends heavily on the quality of the data used to train them. As reflected in the saying \"garbage in, garbage out,\" poor quality training data can lead to poor quality outputs. Recent research from major developers suggests that quality may even be a more important consideration than quantity. Some assessments of quality are more objective than others. Text scraped from the internet often contains error messages or other content with limited or negative training value. Images may have inaccurate or misleading labels, such as a picture of an angry dog labeled as a \"wolf,\" or they may be highly compressed with significant information loss and distortion. Otherwise high-quality content may be watermarked, which has been described as \"a big problem\" for scraped image data. Other assessments are more subjective. Books, encyclopedias, academic papers, and legal opinions are generally considered high-quality sources of text because they are edited, factually rich, and cover diverse topics. Works in the public domain may be older, leading to worse performance on modern language tasks, while other readily available sources may reflect biases or contain \"toxic\" content. Purpose. The purpose for which a model is developed also governs the selection of data for training. Developers often seek to align the content of their training data with the expected use of the model. For example, a language model for legal work would benefit from extensive training on legal documents, and a language model for medical diagnostics would benefit from training on medical papers. Likewise, an image model trained primarily on outdoor, natural images of land and seascapes is unlikely to perform as well on indoor or abstract images, such as quilt designs, posters, or cartoons. When training foundation models (i.e., large models trained for a wide variety of use cases), developers use diverse training materials. According to Meta, for a model to \"realistically emulate all facets of human language,\" it is necessary to use data \"reflecting a broad range of speech—from casual banter, to literary prose, to scientific jargon.\" Public reporting on major technology companies has highlighted efforts to collect materials covering very specific content. In one instance, the developer of a generative video model apparently sought videos for \"doing boxing,\" \"hitting a pinata,\" \"cracking neck,\" and \"jaywalking.\" If a model is intended to be general-purpose, able to generate videos of domains as varied as cross-country skiing, tropical fish, and modern dance, it will likely perform best if it has been trained on least some examples from each of those domains. Acquisition and Curation Training data can be acquired in various ways from a variety of sources. One common practice is downloading \"publicly available\" data from the internet. This can mean using automated tools to systematically \"scrape\" data from online sources, such as deploying stream-ripping software to download millions of video or subtitle files from YouTube. Or it can mean downloading pre-existing databases, such as an entire copy of Wikipedia using one of the regularly provided backups offered by the site. One particularly common source of training data is text scraped by web crawlers, often obtained from Common Crawl. Some developers have also turned to well-known pirate sources, such as shadow libraries with large collections of full, published books. Developers may also incorporate training data from licensed or non-public sources. Some own or have access to data acquired through interactions with customers or users. They may also license data from third parties, such as traditional publishers, intermediaries, and specialized data providers. Developers may find such material particularly desirable because it may not be available to competitors, is reliably high-quality, or promotes particular characteristics during training. Regardless of its source, raw data typically undergoes a curation process to prepare it for training. Because processing data on a massive scale is resource intensive, some developers rely, in whole or in part, on datasets that were initially collected and curated by third parties. Examples of curation include filtering, cleaning, and compiling data. Filtering. Filtering is a common practice, especially for data scraped from the internet, which often includes content that is undesirable for training. Developers may use automated techniques to remove explicit, watermarked, mislabeled, or low-quality content, or to identify \"aesthetic\" or high-quality subsets. Other reasons for filtering include deduplication, which may have the effect of reducing memorization, discussed below in Section II.D.2, and compliance with legal regimes. For example, Getty Images states that when it licenses works for use in a commercial text-to-image model, it \"curates a dataset that includes content that has been released for commercial use in respect of rights of publicity, privacy, trademark, and other intellectual property rights.\" Cleaning. Documents that are not filtered may nevertheless benefit from some form of automated processing or \"cleaning.\" Text scraped from the internet may contain excerpts with limited or negative training value, such as those related to navigation (\"next\" buttons), calls to action (\"Read more…\"), or social media counters (\"likes\"). Rather than excluding the entire document, these undesirable portions can be removed. In some instances, this may include copyright-related information such as the author or owner of the work. Compiling. During curation, it is common to compile multiple datasets into a larger dataset with desirable properties and diverse coverage. For example, the developers of the Pile—a dataset that has been used to train a number of generative language models—created the final dataset by sampling from 22 subsets. These included PubMed Central, an archive of nearly five million biomedical journal articles, to \"benefit potential downstream applications in the medical domain,\" and Books3, a dataset of full-length books, for \"long-range context modeling research and coherent storytelling.\" During this process, developers sometimes \"up-sample\" or weight certain desired subsets, like Wikipedia, meaning they configure the sampling process to select examples from those subsets more often than others, resulting in greater representation and duplicates in the final dataset. Training Training is the procedure that uses data (e.g., text or images) to develop generative AI models. As previously discussed, this requires identifying a formal measure or \"objective\" for how well the model performs, and then repeatedly adjusting the model's parameters based on that objective as the model is exposed to training data. Two aspects of the training process are particularly relevant to the copyright analysis: training phases and memorization. Training Phases The training of generative AI models is rarely a single event, but an iterative process that may be stopped at any point and continued with different data, a different objective, or even a different actor guiding the process. For example, when training its Intelligence Foundation Language Models, Apple started with lower-quality, bulk web-crawl data before shifting to a mixture with higher-quality, longer, and licensed data over several stages. After Meta trained the Llama 3 models, it publicly released their weights, which were then further trained by third parties to create new models, such as Perplexity's Sonar and Nvidia's Nemotron. Thus, broad references to a model's \"training\" may obscure which data was used, for what purpose, and by whom. Some commenters drew a distinction between two phases called \"pre-training\" and \"post-training\" or \"fine-tuning.\" OpenAI described the pre-training for language models as the step \"in which a massive amount of computing power and data is spent to teach the model the broad foundations of language, grammar, and reasoning,\" and post-training as the step \"where the pre-trained model is further trained on a (relative to pre-training) smaller amount of carefully curated data of specific tasks, like summarization or text classification.\" While commonly used, this terminology can be misleading. The term \"pre-training\" often distinguishes a type of training focused on accurately predicting examples from a large dataset. Thus, a third-party may engage in \"continued pre-training\" on a model that has been trained already, and there may be multiple pre-training phases with different data. The term may also imply that it is merely a preliminary stage with minor importance. Yet pre-training often requires orders of magnitude more data and computing power than other training; and it is the stage responsible for many of the sophisticated capabilities of generative AI models. OpenAI's research papers introducing GPT-2 and GPT-3 made the point that by pre-training on a massive quantity of data, a model could perform well on a variety of tasks without additional training. \"Post-training\" or \"fine-tuning\" may refer to a variety of activities conducted for different purposes. Some techniques focus on adapting a general-purpose model to perform narrowly defined tasks or generate specific content. Others maintain the general-purpose nature of the model but focus on improving its ability to follow instructions or generate outputs that \"align\" with human preferences or intent. The upshot is that broad labels like \"pre-training,\" \"post-training,\" and \"fine-tuning\" do not fully convey the purpose, necessity, or impact of any particular training. What an AI developer does with specific training data, and why, is necessarily case-specific. Memorization The extent to which models retain or \"memorize\" training data, which would then travel with the model in subsequent distributions, was disputed by commenters. Some AI companies asserted that \"[t]here is no copy of the training data — whether text, images, or other formats — present in the model itself.\" OpenAI characterized contrary arguments as based on \"a common and unfortunate misperception of the technology,\" and argued that model weights are just \"large strings of numbers\" that reflect \"statistical relationship[s]\" among the training tokens. But others pointed to \"numerous examples\" of models generating \"verbatim, near identical, or substantially similar outputs,\" arguing that they can \"embody the expressive works they were trained on.\" News/Media Alliance stated that \"regardless of the exact technical processes employed,\" such behavior \"has the same effect as memorization and retention.\" Seeking to reconcile these positions, A. Feder Cooper and James Grimmelmann explain that \"the problem is that the [statistical] 'patterns\" learned by a model can be highly abstract, highly specific, or anywhere in between.\" Where the learned pattern is highly specific, \"the pattern is the memorized training data.\" Put another way, training involves comparing model outputs with examples and making small adjustments to the model's weights so that it is more likely to generate outputs closer to those examples. While the goal may be to learn abstract patterns across training examples, the process does not appear to be inherently restricted to a particular level of abstraction. In some cases, memorization may even be useful, with models exhibiting a \"Goldilocks phenomenon; [they] are most useful when they memorize just the right amount, neither too little nor too much.\" OpenAI and other commenters acknowledged the potential for some memorization, but described it as rare, unintended, difficult to detect, and inconsistent with the purpose of training—\"a bug, not a feature.\" For example, Meta cited a study finding that one language model had a memorization rate of approximately one percent. Given the scale of the training datasets, however, even one percent may not be trivial. Considerable research has been done on the extent to which and reasons why models memorize data. A variety of factors appear to influence the extent of memorization, including the number of model parameters, the presence of duplicates in training data, training repeatedly on the same example, whether an example is unusual or an \"outlier,\" at what point an example is seen during training, and how broadly memorization is defined. Deployment In practice, users do not interact directly with the statistical models powering generative AI. Instead, these models are deployed in larger AI systems, which process and control the information flowing into and out of the models, connect them with other software tools, and provide a more convenient user interface. The choices made during this deployment can have substantial impacts on what models can do and what material they use. The same AI model can be deployed in systems that perform very different tasks. OpenAI and Anthropic advertise their models' use for everything from keyword extraction and classifying customer support tickets at scale, to document summarization and translation, to fully generative tasks like writing a class lesson plan or rap lyrics. Although language models are particularly flexible, there are diverse use cases for other types of models as well. The nature of the model's deployment can also affect what materials it uses when generating outputs. Techniques have been developed to enable models to retrieve content from outside their training data when the system is responding to a specific request. Researchers affiliated with Facebook coined the term \"retrieval-augmented generation,\" or \"RAG,\" to describe this process. Many models use search engines for RAG, meaning they can generate queries that will be executed by the system, with the top results returned to the model in the form of an expanded prompt. For example, given the question \"What show won the Outstanding Drama award at the 2024 Emmys?\", the generative AI assistant Claude can generate several queries such as \"2024 emmy awards outstanding drama winner,\" send those queries to a third-party search engine (Brave Search), pull the full-text of the top results—articles from CBS, Billboard, and others—and answer the user's question using the retrieved text as additional context Beyond training and content retrieval, there are techniques developers can use to enhance models' capabilities during deployment. Recently, advanced systems have begun to employ processes that allow language models to \"think\" and \"act\" before responding to user prompts. They \"think\" by generating text that verbally reasons through a problem before answering, and they \"act\" by generating text that directs the system to take actions. OpenAI's Deep Research can independently run from five to thirty minutes on a question, iteratively searching, copying, and analyzing various sources. In addition to augmenting models' outputs, systems can also constrain them. The developers of generative AI models and systems may employ a variety of \"guardrails\" to prevent them from generating objectionable content. External filters can intercept prompts before they reach the generative model, or intercept model outputs before they reach the user. \"Safety prompting\" uses hidden system prompts to reduce the likelihood of generating undesirable outputs. Alignment training is a type of continued model training designed to bring its behavior in line with human preferences or values. None of these approaches is infallible, however. The line between desired and undesired behavior is often subjective, and users can intentionally, or sometimes unintentionally, bypass or degrade guardrails. The implementation and efficacy of guardrails against copyright-infringing outputs has already been the subject of litigation. An additional point about deployment is that developers exert varying degrees of control over trained models, and the decisions shaping a model's use can be made by different actors. Some companies, like OpenAI and Anthropic, retain control over their models by deploying them on cloud services, providing access through consumer-facing products or an application programing interface (\"API\"), which lets third parties develop products without accessing or controlling the model directly. Others, like Apple, have designed models for \"on-device\" use, which involves distributing weights to end users via embedded software or software updates. And some major companies, including Meta, Microsoft, and Google, have released \"open\" models to the public, meaning that their downloadable weights can be shared, used, retrained, or deployed by anyone. According to Hugging Face, the weights for one version of Meta's Llama 3 have been downloaded over 6 million times in the last month. PRIMA FACIE INFRINGEMENT The Copyright Act grants copyright owners a set of exclusive rights: to reproduce, distribute, publicly perform, and publicly display their works, as well as the right to prepare derivative works. Establishing a prima facie case of infringement requires two elements: \"(1) ownership of a valid copyright, and (2) copying of constituent elements of the work that are original.\" Creating and deploying a generative AI system using copyright-protected material involves multiple acts that, absent a license or other defense, may infringe one or more rights. Data Collection and Curation The steps required to produce a training dataset containing copyrighted works clearly implicate the right of reproduction. Developers make multiple copies of works by downloading them; transferring them across storage mediums; converting them to different formats; and creating modified versions or including them in filtered subsets. In many cases, the first step is downloading data from publicly available locations, but whatever the source, copies are made—often repeatedly. Most commenters agreed with or did not dispute that copying during the acquisition and curation process implicates the reproduction right As Professors Pamela Samuelson, Christopher Jon Sprigman, and Matthew Sag explained: \"the process of training Generative AI models is generally preceded by massive amounts of web scraping that results in the creation of locally stored copies of millions or billions of copyrighted works.\" Although some commenters noted that data may be discarded after the training process, that does not affect the infringement analysis. Moreover, public reporting indicates that major developers often maintain training datasets for use in future projects. Training The training process also implicates the right of reproduction. First, the speed and scale of training requires developers to download the dataset and copy it to high-performance storage prior to training. Second, during training, works or substantial portions of works are temporarily reproduced as they are \"shown\" to the model in batches. Those copies may persist long enough to infringe the right of reproduction, depending on the model at issue and the specific hardware and software implementations used by developers. Third, the training process—providing training examples, measuring the model's performance against expected outputs, and iteratively updating weights to improve performance—may result in model weights that contain copies of works in the training data. If so, then subsequent copying of the model weights, even by parties not involved in the training process, could also constitute prima facie infringement. As discussed in the Technological Background, the extent to which models memorize training examples is disputed. When, however, a specific model can generate verbatim or substantially similar copies of a training example, without that expression being provided externally in the form of a prompt or other input, it must exist in some form in the model's weights. When a model takes the prompt \"Ann Graham Lotz\" and outputs an image that is nearly identical to a portrait found in the training data, the expression in that image clearly comes from the model. As A. Feder Cooper and James Grimmelmann put it, \"a model is not a magical portal that pulls fresh information from some parallel universe into our own.\" In such instances, there is a strong argument that copying the model's weights implicates the right of reproduction for the memorized examples. Like other digital files that encode or compress content using mathematical representations, the content need not be directly perceivable to constitute a copy. The relevant question is whether the work is \"fixed\" and \"can be perceived, reproduced, or otherwise communicated . . . with the aid of a machine or device.\" Since model weights are lists of numbers that do not change (barring further training), they are fixed, and because memorized works can be generated and displayed using software, those works can be perceived or reproduced with the aid of a machine. Model weights that have memorized protectable expression from training data may also infringe the derivative work right. Some commenters asserted that model weights are necessarily abstractions or transformations of all the original training data. NMPA, for example, stated that \"[u]ltimately, the model becomes an abstract agglomeration of its training material capable of generating (i.e., communicating) verbatim copies of works within the training set, many of which are copyrighted. Such qualities fall squarely within the Copyright Act's definition of a derivative work.\" Others argued that models cannot be derivative works because they do not contain training examples—they only learn from them through an abstraction process. Citing Authors Guild for this point, TechNet asserted that models \"do not represent any protected aspects of the original works to users.\" Courts that have addressed infringement claims regarding model weights have reached varying conclusions. In Kadrey v. Meta Platforms, the court described allegations that the Llama models themselves were infringing derivative works as \"nonsensical.\" In that case, however, the complaint did not allege that the models could \"spit[] out actual copies of their protected works\" or outputs that are \"similar enough … to be infringing derivative works.\" In Andersen v. Stability AI, by contrast, the court denied a motion to dismiss filed by a third party that was not involved in the training process but had downloaded and used an already-trained model. It found sufficient allegations that copies or protected elements remained, in some format, within the model. The court distinguished Kadrey on the ground that the \"necessary allegations regarding the products' training and operations, [were] materially different.\" The Office agrees with this distinction. Whether a model's weights implicate the reproduction or derivative work rights turns on whether the model has retained or memorized substantial protectable expression from the work(s) at issue. As discussed above, the use of those works in preparing a training dataset and training a model implicates the reproduction right, but copying the resulting weights will only infringe where there is substantial similarity. RAG RAG also involves the reproduction of copyrighted works. Typically, RAG works in one of two ways. In one, the AI developer copies material into a retrieval database, and the generative AI system can later access that database to retrieve relevant material and supply it to the model along with the user's prompt. In the other, the system retrieves material from an external source (for example, a search engine or a specific website). Both methods involve making reproductions, including when the system copies retrieved content at generation time to augment its response. We note that RAG is an important feature of many AI products, and that RAG-related uses are of particular concern for news media stakeholders. Outputs Generative AI models sometimes output material that replicates or closely resembles copyrighted works. Users have demonstrated that generative AI can produce near exact replicas of still images from movies, copyrightable characters, or text from news stories. Such outputs likely infringe the reproduction right and, to the extent they adapt the originals, the right to prepare derivative works. Some commenters noted that, depending on the content type and the audience, they may implicate the public display and public performance rights as well. These infringement issues, including enforcement challenges and the allocation of potential liability, will be addressed in a later Part of this Report. FAIR USE To the extent that acts involved in developing and deploying a generative AI model constitute prima facie infringement, the primary defense available is fair use. Fair use is a judge-made doctrine now codified in Section 107 of the 1976 Copyright Act. It provides that \"the fair use of a copyrighted work . . . is not an infringement of copyright\" and lists four non-exclusive factors that must be considered in determining whether a particular use is fair: (1) the purpose and character of the use, including whether such use is of a commercial nature or is for nonprofit educational purposes; (2) the nature of the copyrighted work; (3) the amount and substantiality of the portion used in relation to the copyrighted work as a whole; and (4) the effect of the use upon the potential market for or value of the copyrighted work. These statutory factors are not to be applied mechanically. Rather, they \"set forth general principles, the application of which requires judicial balancing, depending upon relevant circumstances.\" Fair use is, fundamentally, an \"equitable rule of reason.\"191 It is an affirmative defense, with the defendant bearing the burden of proof. In approaching fair use claims involving new technologies, courts have sought to further copyright's \"basic purpose\" of promoting progress by striking a balance between protecting authors' exclusive rights in their works and enabling others to build upon those works. The comments the Office received in response to the NOI were sharply divided on the applicability of fair use. On one side, commenters painted a dire picture of what unlicensed training would mean for artists' livelihoods. The Copyright Alliance warned that \"the widespread unauthorized ingestion of copyrighted works would certainly appear to cause immeasurable harm to creators and copyright owners—both by destroying existing, nascent, and to-be-developed licensing markets and by flooding the market with low-quality substitutional material.\" One creator wrote that \"[t]he unregulated use of AI tools by companies and individuals is actively threatening my ability to get jobs in my field. It makes me feel sick that all the art I posted online to build my career, can be stolen at any time and used without my permission.\" Many of these commenters argued that the use of copyrighted works to create new expressive works that compete with or serve as substitutes for the originals cannot be considered fair. AAP compared it to compelling authors to subsidize their competition. Rightsify stated, \"[t]here is no legal precedent for the massive scraping of data for the purposes of creating data sets that can be commercially exploited to potentially create competing works.\" Others contended that the unauthorized copying of expressive works in AI training adds nothing new while usurping an emerging market for works as training materials. On the other side, many warned that requiring AI companies to license works in training data would stifle development of a critical technology, entrench the power of those companies that are capable of acquiring or already own sufficient data, and impair national competitiveness. As summarized by the venture capital firm a16z, \"imposing the cost of actual or potential copyright liability on the creators of AI models will either kill or significantly hamper their development . . . . The result will be far less competition, far less innovation, and very likely the loss of the United States' position as the leader in global AI development.\" Stability AI called it \"doubtful\" that generative AI would be possible without the fair use defense and maintained that \"[t]he U.S. has established global leadership in AI due, in part, to a robust, adaptable, and principles-based fair use doctrine that balances creative rights with open innovation.\" These commenters saw the use of copyrighted works to train AI models as consistent with fair use precedent. Some asserted that fair use generally favors technological advancements, particularly where \"intermediate copying\" facilitates the development of new technologies. Authors Alliance stated that \"[i]n the vast majority of cases, the use of copyrighted works to train AI models constitutes fair use\" because it is done as an intermediate step in producing non-infringing content and serves the public benefit by reducing bias in datasets and improving performance of AI models. Meta asserted that AI training does not harm rightsholder interests because \"the purpose and effect of training is not to extract or reproduce the protectable expression in training data, but rather to identify language patterns across a broad body of content.\" Factor One The first fair use factor \"focuses on whether an allegedly infringing use has a further purpose or different character, which is a matter of degree, and the degree of difference must be weighed against other considerations.\" Courts typically stress two main elements: transformativeness and commerciality. Some courts have also evaluated whether the defendant had lawful access to the work. Identifying the Use \"The fair use provision, and the first factor in particular, requires an analysis of the specific 'use' of a copyrighted work that is alleged to be an 'infringement . . . [as t]he same copying may be fair when used for one purpose but not another.' In Andy Warhol Foundation v. Goldsmith (\"Warhol\"), the photographer Lynn Goldsmith challenged the Foundation's unauthorized licensing of a screenprint of the musician Prince that Andy Warhol had created based on her copyrighted photograph. The Court's fair use analysis was based on the licensing of the screenprint rather than its initial creation decades before. On the first factor, it found that the licensing use had the purpose of display in a magazine, which was \"substantially the same purpose\" as Goldsmith's original photo. As described above, copyrighted works are used in different ways during the development and deployment of generative AI models. The use of a work in initial pretraining, for instance, may be distinct from its use in subsequent training or RAG. A number of commenters opined that the fair use analysis requires treating these different uses separately. One observed that \"[e]ven if a base model is deemed [noninfringing], downstream fine-tuned or aligned models may have a substantively different fair-use analysis.\" The Office agrees that different uses during AI development and deployment require separate consideration. But while it is important to identify the specific act of copying during development, compiling a dataset or training alone is rarely the ultimate purpose. Fair use must also be evaluated in the context of the overall use. Transformativeness Legal Framework In assessing transformativeness, the question is \"whether the new work merely 'supersedes the objects' of the original creation, or instead adds something new, with a further purpose or different character, altering the first with new expression, meaning, or message. . . .\" Such a use is less likely to substitute for the original in the marketplace and more likely to advance the purposes of copyright. In Warhol, the Supreme Court clarified the concept of transformativeness. The Court explained that while adding new expression can be relevant to evaluating whether a use has a different purpose and character, it does not necessarily make the use transformative. Even significant alterations will not be enough if the use ultimately serves a purpose similar to that of the original, and may instead produce a derivative work and demonstrate the \"need for licensing.\" The Court explained that \"a use that has a distinct purpose is justified because it furthers the goal of copyright, namely, to promote the progress of science and the arts, without diminishing the incentive to create.\" Such justification may be found when the copying \"is reasonably necessary to achieve the user's new purpose.\" For example, where a work is targeted for parody, criticism, or commentary, there is a need to use that particular work to effectively accomplish that purpose. Using a work to communicate a new meaning or message unrelated to commenting on the work itself, however, does not provide such a justification. The Warhol Court further emphasized that both transformativeness and justification are matters of degree. \"[T]he first factor (which is just one factor in a larger analysis) asks 'whether and to what extent' the use at issue has a purpose or character different from the original.\" As the Court previously stated in Campbell v. Acuff-Rose, \"the more transformative the new work, the less will be the significance of other factors, like commercialism, that may weigh against a finding of fair use.\" The degree to which a use is transformative can inform the analysis of market harm under the fourth factor, because less transformative uses are more likely to serve as market substitutes. Further, although transformativeness often leads to a finding of fair use, not every transformative use is a fair one. Beyond these general principles, case law provides additional guideposts. Uses that merely change the medium, or spare the user inconvenience, are not transformative. By contrast, copying to make available information about the content of the works copied can be transformative where it does not provide substitutes for those works. For example, in Google Books, the Second Circuit found that scanning books to create a full-text searchable database to provide information about the books' contents served a \"highly transformative purpose.\" Copying a work in order to remove functional impediments to competition may also be transformative even where the use enables the creation of competing works. In Google LLC v. Oracle America, Inc., the Supreme Court concluded that \"reimplementation\" of copied code was transformative because it \"furthered the development of computer programs\" by enabling programmers to use their existing skills in a new mobile platform. Similarly, the Second Circuit held in Sega v. Accolade that copying computer code to learn the functional requirements for hardware-compatible games served a legitimate purpose that increased the \"number of independently designed video game programs offered for use with the [hardware].\" Commenters' Views Commenters disagreed as to whether or to what extent the use of copyrighted works in the development of AI systems is transformative. Many viewed the process of generative AI training as highly transformative. They saw the statistical analysis of works in machine learning as far removed in purpose and character from that of the original works. The University Library of the University of California, Berkeley stated that \"training [a] model to predict or classify aspects of copyright-protected inputs is a distinct purpose, and one that is highly transformative from the original 'consumptive' purpose.\" Professors Samuelson, Sag, and Sprigman asserted that \"[d]eriving uncopyrightable abstractions and associations from the training data and then using that knowledge to confect new digital artifacts is not just transformative, it is highly transformative.\" Several commenters described the use of copyrighted works to train AI models as fundamentally different from the purposes of those works because it is \"non-expressive.\" For example, Anthropic asserted that \"[t]o the extent copyrighted works are used in training data, it is for analysis (of statistical relationships between words and concepts) unrelated to any expressive purpose of the work.\" Google stated that because training is a process for \"deconstructing existing works for the purposes of modeling mathematically how language works,\" it serves a different purpose than the \"communicative, expressive purpose for which these works were created.\" Another commenter opined that the difficulty in determining whether a model has been trained on a work is evidence that it is not intended to replicate the expressive material in its training data. Some compared AI training to human learning, as evidence that it was productive and transformative. A few commenters, citing Warhol for the proposition that a justification for a use may support its transformativeness, argued that the mass use of works is justified as important or necessary to the development of AI technology. IBM for example observed that \"[t]he countless scientific, societal, and economic benefits that foundation models can provide more than justify the reproductions of copyrighted material in their training datasets.\" On the other side, many disagreed with the proposition that using copyrighted works in AI training is transformative. Some described such use as similar to non-transformative processes like compression, where the expressive elements of the works are simply represented in a different way. Others compared an AI model to a device loaded with copyright-infringing content: \"Unlike a camera or VCR, generative AI is 'pre-loaded' by the developer with copyrighted content, and unlike a camera or VCR, AI uses that copyrighted content to generate its own (uncopyrightable) synthetic content.\" They asserted that copying for AI training is unjustified because no individual work is necessary to train AI, and other means of acquisition, such as licensing, are available. A number of commenters opined that when analyzing the purpose and character of an AI developer's use of copyrighted material, courts should not view the training process in isolation but consider the ultimate use of the model. In addition, one commenter observed that \"[d]ifferent stages like pre-training and fine-tuning could . . . raise distinct considerations under the first fair use factor\" as \"[f]ine-tuning . . . usually narrows down the model's capabilities and might be more aligned with the original purpose of the copyrighted material.\" Several commenters disputed the characterization of training on copyrighted works as \"non-expressive.\" As an initial matter, the MPA observed that courts have never said there is a \"non-expressive use\" doctrine: \"The relevant inquiry is not whether the 'use' is 'expressive' or 'non-expressive'; rather, it asks whether the 'use' is transformative, as one consideration in the four-factor analysis.\" Others rejected the claim that AI training uses only the ideas or facts embodied in a work. In the words of the Authors Guild, \"AI companies seek out published books for [training] precisely because of their expressive content, as high-quality, professionally authored works are vital to enabling an LLM to produce outputs that mimic human language, story structure, character development, and themes.\" AAP asserted that \"Gen AI training . . . does not extract the ideas, facts, or concepts being conveyed by an author, it solely extracts the exact expressive choices made to convey those ideas—i.e., the words an author used, and the order in which they were placed.\" These commenters further argued that the cases cited in support of the concept of non-expressive use relate to computer programs and are distinguishable from the use of expressive works in generative AI training. Analysis As discussed above, Warhol requires examining not just the immediate act of copying but its ultimate goal. Accordingly, whether copying a work to compile a training dataset is transformative depends on whether the dataset will be used for a transformative purpose. In the Office's view, training a generative AI foundation model on a large and diverse dataset will often be transformative. The process converts a massive collection of training examples into a statistical model that can generate a wide range of outputs across a diverse array of new situations. It is hard to compare individual works in the training data—for example, copies of The Big Sleep in various languages—with a resulting language model capable of translating emails, correcting grammar, or answering natural language questions about 20th-century literature, without perceiving a transformation. The purpose of creating works of authorship is to disseminate them for human enjoyment and education. Many AI models, however, are meant to perform a variety of functions, some of which may be distinct from the purpose of the copyrighted works they are trained on. For example, a language model can be used to help learn a foreign language by chatting with users on diverse topics and offering corrective feedback. But transformativeness is a matter of degree, and how transformative or justified a use is will depend on the functionality of the model and how it is deployed. On one end of the spectrum, training a model is most transformative when the purpose is to deploy it for research, or in a closed system that constrains it to a non-substitutive task. For example, training a language model on a large collection of data, including social media posts, articles, and books, for deployment in systems used for content moderation does not have the same educational purpose as those papers and books. On the other end of the spectrum is training a model to generate outputs that are substantially similar to copyrighted works in the dataset. For example, a foundation image model might be further trained on images from a popular animated series and deployed to generate images of characters from that series. Unlike cases where copying computer programs to access their functional elements was necessary to create new, interoperable works, using images or sound recordings to train a model that generates similar expressive outputs does not merely remove a technical barrier to productive competition. In such cases, unless the original work itself is being targeted for comment or parody, it is hard to see the use as transformative. Many uses fall somewhere in between. The use of a model may share the purpose and character of the underlying copyrighted works without producing substantially similar content. Where a model is trained on specific types of works in order to produce content that shares the purpose of appealing to a particular audience, that use is, at best, modestly transformative. Training an audio model on sound recordings for deployment in a system to generate new sound recordings aims to occupy the same space in the market for music and satisfy the same consumer desire for entertainment and enjoyment. In contrast, such a model could be deployed for the more transformative purpose of removing unwanted distortion from sound recordings. Because generative AI models may simultaneously serve transformative and non-transformative purposes, restrictions on their outputs can shape the assessment of the purpose and character of the use. As described above, developers can apply training techniques or deployment guardrails so that the model rejects requests for excerpts of copyrighted works or even refuses to generate expressive works. Where such restrictions are effective, the system will be less capable of fulfilling the purpose of the original works, and their use in training may be more transformative. The use of copyrighted works by RAG requires separate consideration. Unlike pre-training where a large, diverse dataset is used to train a model for a wide variety of tasks, RAG retrieves individual works because they are relevant to a user's prompt, for the purpose of enhancing the response. The use of RAG is less likely to be transformative where the purpose is to generate outputs that summarize or provide abridged versions of retrieved copyrighted works, such as news articles, as opposed to hyperlinks. In providing this analysis, the Office rejects two common arguments about the transformative nature of AI training. As noted above, some argue that the use of copyrighted works to train AI models is inherently transformative because it is not for expressive purposes. We view this argument as mistaken. Language models are trained on examples that are hundreds of thousands of tokens in length, absorbing not just the meaning and parts of speech of words, but how they are selected and arranged at the sentence, paragraph, and document level—the essence of linguistic expression. Image models are trained on curated datasets of aesthetic images because those images lead to aesthetic outputs. Where the resulting model is used to generate expressive content, or potentially reproduce copyrighted expression, the training use cannot be fairly characterized as \"non-expressive.\" Nor do we agree that AI training is inherently transformative because it is like human learning. To begin with, the analogy rests on a faulty premise, as fair use does not excuse all human acts done for the purpose of learning. A student could not rely on fair use to copy all the books at the library to facilitate personal education; rather, they would have to purchase or borrow a copy that was lawfully acquired, typically through a sale or license. Copyright law should not afford greater latitude for copying simply because it is done by a computer. Moreover, AI learning is different from human learning in ways that are material to the copyright analysis. Humans retain only imperfect impressions of the works they have experienced, filtered through their own unique personalities, histories, memories, and worldviews. Generative AI training involves the creation of perfect copies with the ability to analyze works nearly instantaneously. The result is a model that can create at superhuman speed and scale. In the words of Professor Robert Brauneis, \"Generative model training transcends the human limitations that underlie the structure of the exclusive rights.\" Commerciality The commerciality inquiry relates to the potential unfairness of using copyrighted works to obtain a financial benefit while forgoing payment. Because even paradigmatic fair uses, such as news reporting or criticism, are often done for profit, \"the crux of the profit/nonprofit distinction is not whether the sole motive of the use is monetary gain but whether the user stands to profit from exploitation of the copyrighted material without paying the customary price.\" The Office's NOI asked how to assess commerciality in the context of generative AI, particularly in circumstances when curating datasets or training on those datasets may be done for noncommercial or research purposes, but the dataset or model is later adapted to commercial use. Several commenters warned against considering such practices as noncommercial and described them as \"data laundering.\" News/Media Alliance stated that \"in light of concerning practices of . . . initially nonprofit models that transition into commercial entities or assist them in building competitive, commercial products, the Office should be careful in drawing any kind of a bright line between commercial and noncommercial uses.\" The Office also asked whether it made a difference if the funding for non-commercial research uses came from for-profit companies. While one commenter stated that funding from a commercial source \"may be evidence of a commercial purpose,\" particularly if done as part of a \"data laundering\" arrangement, others believed that it made no difference. Because there are distinct acts and often multiple actors involved in the creation of AI systems, identifying the use with particularity is critical here too. The creation and distribution of a training dataset, the copying of that dataset for training, and the copying and distribution of model weights for use in a system may be conducted by different entities, each of whose activities may or may not be considered \"commercial.\" Accordingly, in assessing whether the transfer of training datasets, synthetic data, or model weights is obscuring a commercial benefit and constitutes \"data laundering,\" the financial relationships between the actors are relevant. Moreover, commerciality does not turn solely on whether an organization is designated as \"profit\" or \"nonprofit,\" but whether the use itself furthers commercial purposes. A for-profit company with a substantial research arm could train a model with a novel architecture or training technique and release a research paper without commercializing the model. It could also \"open source\" the resulting model weights (i.e., provide them to the public for free), leaving it to others to experiment or build products with them. Although these activities could indirectly further the financial interests of the company, the connection between the copying and any commercial gain may be too attenuated to render the use commercial. Similarly, the nonprofit status of an organization should not in itself preclude a finding of commerciality. Nonprofits may engage in commercial activity by directly monetizing datasets or models through licensing or subscription-based products. Such direct monetization would be commercial notwithstanding an organization's corporate structure or charitable goals. In short, the analysis should not turn on the status of any individual entity but on the reality of whether the specific use in question serves commercial or nonprofit purposes. Unlawful Access A number of commenters contended that the first factor analysis should also take into account whether the AI developer had lawful access to the works used in training. They reported that it is common for training datasets to include pirated works or works accessed by circumventing paywalls. Some concluded that the \"[i]f generative AI developers know or should have known that their systems are ingesting works that have been made available illegally, these acts would reflect bad faith or unclean hands.\" Professors Samuelson, Sprigman, and Sag, however, cautioned that \"context matters[,]\" and \"[i]t would be unwise to elevate lawful access to a per se rule.\" In the Office's view, the knowing use of a dataset that consists of pirated or illegally accessed works should weigh against fair use without being determinative. Courts have expressed some uncertainty about whether good or bad faith generally is relevant to the fair use analysis. The cases in which they have done so, however, involved defendants who used copyrighted works despite the owners' denial of permission. Training on pirated or illegally accessed material goes a step further. Copyright owners have a right to control access to their works, even if someone seeks to obtain them in order to make a fair use. Gaining unlawful access therefore bears on the character of the use. Factor Two The second factor, the nature of the copyrighted work, \"calls for recognition that some works are closer to the core of intended copyright protection than others.\" The use of more creative or expressive works (such as novels, movies, art, or music) is less likely to be fair use than use of factual or functional works (such as computer code). The unpublished nature of a work can also weigh against a fair use determination. Those commenters who discussed the second factor asserted that it will often weigh against fair use because training datasets usually include expressive works, even if they contain less creative or unprotectable material as well. While some noted that datasets may include unpublished works, most works will have been published, which \"modestly supports a fair use argument.\" Several observed, however, that the second factor rarely plays a substantial role in the overall fair use balancing. As generative AI models are regularly trained on a variety of works—both expressive and functional, published as well as unpublished—the facts will vary depending on the model and works at issue. Language models are often trained on highly creative works like novels, alongside those with more factual or functional content, like computer code or scholarly articles. Where the works involved are more expressive, or previously unpublished, the second factor will disfavor fair use. Factor Three On the third factor, the question is whether “’the amount and substantiality of the portion used in relation to the copyrighted work as a whole,’ . . . are reasonable in relation to the purpose of the copying.” This factor “harken[s] back to the first [factor]” because “[t]he extent of permissible copying varies with the purpose and character of the use.” It also bears on the fourth factor insofar as more extensive copying can increase the risk that the use will serve as a market substitute for the original. Relevant considerations may include how much of each work is used; the reasonableness of the amount in light of the purpose of the use; and the amount made accessible to the public. The Amount Used The Supreme Court has said that courts assessing the amount and substantiality must consider both the quantity of material used and its quality and importance. Copying even a small portion of a work may weigh against fair use where it is the \"heart\" of the work. In general, \"[t]he larger the amount, or the more important the part, of the original that is copied, the greater the likelihood that the secondary work might serve as an effectively competing substitute for the original, and might therefore diminish the original rights holder's sales and profits.\" Downloading works, curating them into a training dataset, and training on that dataset generally involve using all or substantially all of those works. Such wholesale taking ordinarily weighs against fair use. Reasonableness in Light of Purpose Copying an entire work may weigh less heavily against a finding of fair use, however, where it is reasonable in relation to a transformative purpose. In several cases, courts have found mass copying of entire works to be justified when it enabled transformative uses, such as to develop search engines or plagiarism detection software. In Google Books, Google's scanning of millions of books was excused in part because \"not only is the copying of the totality of the original [books] reasonably appropriate to Google's transformative purpose [of creating a search engine of books], it is literally necessary to achieve that purpose.\" The Ninth Circuit similarly found that copying entire images was reasonable in relation to creating a visual search engine: \"If Arriba only copied part of the image it would be more difficult to identify it, thereby reducing the usefulness of the visual search engine.\" Commenters disagreed about the need to use entire copyrighted works in AI training. Some believed that because the most powerful generative AI models need massive amounts of data, it is \"reasonable for developers to try to maximize the amount of data these models ingest in order to increase the public benefit of these tools.\" Others disputed either the amount of data needed or the justification for taking it. NMPA argued that AI models' insensitivity to any particular copyrighted work make the third factor analysis different from search engine cases like Google Books: \"Even if copying more portions of more works results in an AI model that is incrementally more commercially competitive, that is very different from the binary necessity for making complete copies in [Google Books].\" More fundamentally, several commenters argued that scale should not affect the fair use analysis. In the words of one rightsholder association, \"Fair use should not provide a 'volume discount.'\" The Office agrees that the use of entire copyrighted works is less clearly justified in the context of AI training than it was for Google Books or a thumbnail image search. Those services made information available about the content of the works copied, making the extent of the copying definitionally necessary for full-text search to work. Generative AI, by contrast, is not limited to providing information about the works in the training dataset. Moreover, there may be cases where a more targeted round of training has more limited data requirements; in such circumstances, the developer may be able to reduce the amount taken from individual works without compromising the training goal. Nevertheless, the use of entire works appears to be practically necessary for some forms of training for many generative AI models. While for large, general-purpose models, there is no need to copy any amount of any specific work, research supports commenters' assertions that internet-scale pre-training data, including large amounts of entire works, may be necessary to achieve the performance of current-generation models. To the extent there is a transformative purpose, the use of entire works on that scale could be reasonable. The Amount Made Available to the Public In several cases where the defendant made non-public, intermediate copies, courts have concluded that the question is \"not so much 'the amount and substantiality of the portion used' in making a copy, but rather the amount and substantiality of what is thereby made accessible to a public for which it may serve as a competing substitute.\" In Sony v. Connectix and Sega v. Accolade, the Ninth Circuit held that although defendants made, respectively, complete copies of a game console's basic input/output system and a video game in order to access their functional requirements, this carried \"very little weight\" when the ultimate material accessible to the public (a console emulator and an original video game) did not include the works' protectible expression. A few courts have extended this focus on outputs beyond the context of functional computer code. In Google Books, described by the Second Circuit as \"test[ing] the boundaries of fair use,\" although Google made complete copies of books, the third factor nevertheless did not weigh against Google because only carefully-limited \"snippets\" incapable of substituting for the original works were made available to the public. And in a recent decision about copying legal summaries to train a (non-generative) AI search tool, the court found that factor three favored the defendant because its use did not make copyrighted material available to the public. In contrast, where a defendant copied television broadcasts and allowed users to view ten-minute clips, with no restrictions on the number they could view, the Second Circuit found that the third factor clearly weighed against fair use. Professors Samuelson, Sag, and Sprigman described this line of cases as showing that \"making complete literal copies [for generative AI training] . . . is reasonable as an intermediate technical step in an analytical process that does not lead to the communication of the underlying original expression to a new audience.\" The Copyright Alliance disagreed, contending that the reverse engineering cases were specific to the use of functional code, and that Google Books served a more clearly transformative purpose than generative AI training, in that it provided information about the works used rather than generating new outputs to compete with those works. Moreover, Google Books had \"significant safeguards\" to reduce the risk that the copies could serve as substitutes. In the Office's view, while there are meaningful distinctions from the intermediate copying cases, their logic suggests that the third factor may weigh less heavily against generative AI training where there are effective limits on the trained model's ability to output protected material from works in the training data. As in the intermediate copying cases, generative AI typically do not make all of what was copied available to the public. Most outputs from generative AI systems do not contain any protected expression from their training data, and models can be deployed in ways that entirely obscure outputs from users or result in non-expressive outputs. Where a model can output expression, however, the question is whether, like Google Books, the AI developer has adopted adequate safeguards to limit the exposure of copyrighted material. At least for some \"memorized\" works, generative AI users can potentially obtain far more protectible expression than the snippets made available in Google Books. Commenters disagree about how much effort this requires. They do not dispute that it happens. But many generative AI companies with chatbot and other public-facing services employ guardrails and other methods to prevent potentially infringing outputs. These include input filters that block user prompts likely to result in generations that reproduce copyrighted content; training techniques designed to make infringing outputs less likely; internal system prompts that instruct it not to generate names of copyrighted characters or create images in the style of living artists; and output filters that block copyrighted content from being displayed. Although there are factual disputes over the efficacy of these guardrails, where they do prevent the generation of infringing content, the third factor will weigh less heavily against fair use. In sum, AI developers ordinarily copy entire works and make use of their expressive content for training, weighing against fair use. But in cases where there is a transformative purpose, and where there is a need to train on a large volume of works to effectively generalize, the copying of entire works may be reasonable. This is especially true where little or none of the copied material will be made accessible to the public, whether due to training techniques or choices made in deployment. In those circumstances, the third factor may not weigh against fair use. Factor Four The fourth and final statutory factor is \"the effect of the use upon the potential market for or value of the copyrighted work.\" \"The enquiry must take account not only of harm to the original but also of harm to the market for derivative works.\" The Supreme Court has twice described this factor as \"undoubtedly the single most important element of fair use,\" although its importance \"will vary, not only with the amount of harm, but also with the relative strength of the showing on the other factors.\" Although the copyright owners might \"bear some initial burden of identifying relevant markets,\" they \"need not present empirical data of their own in connection with [the] asserted affirmative defense.\" This section evaluates different ways in which the use of copyrighted works for generative AI can affect the market for or value of those works, including through lost sales, market dilution, and lost licensing opportunities. It also addresses broader claims that the public benefits of unlicensed training might shift the fair use balance. Lost Sales The first harm to consider is \"actual or potential market substitution\"—that is, whether a market for the original work is supplanted \"so as to deprive the rights holder of significant revenues because of the likelihood that potential purchasers may opt to acquire the copy in preference to the original.\" Courts consider not only the harm from a particular use but also whether there would be a \"substantially adverse impact\" on the market if that use were to become \"unrestricted\" and \"widespread.\" Commenters offered competing perspectives on whether or how the outputs of generative AI can substitute for the originals. Several asserted that use of copyrighted works for training was clearly substitutional insofar as the model generates copies of the work. The National Association of Broadcasters provided an example of \"nearly word for word\" copies of a local station's news stories being reproduced by a generative AI system without permission from the station or its owner, \"illustrat[ing] how AI-generated 'news' has the potential to substitute for and supplant the market for copyrighted broadcast content on which the AI systems have been trained.\" Other commenters argued that the substitution that may occur is broader than the harm cognizable under the fourth factor. As Meta put it, \"while it is possible (at least in theory) for Generative AI to create works 'of the same type' that compete in the overall market with the originals, this is not the kind of substitution that implicates the fourth fair use factor.\" The Authors Alliance likewise contended that the effect on the market \"is unlikely to be significant based on the lack of a substitutional effect between the individual works themselves and the generative AI systems based on AI models that use them as training materials.\" There are instances, however, where the use of works in generative AI training can lead to a loss in sales. The use of pirated collections of copyrighted works to build a training library, or the distribution of such a library to the public, would harm the market for access to those works. And where training enables a model to output verbatim or substantially similar copies of the works trained on, and those copies are readily accessible by end users, they can substitute for sales of those works. A potential loss of sales is particularly clear in the case of works specifically developed for AI training. There is a thriving industry focused on developing training datasets that improve the ability of language models to follow instructions, format and structure outputs, use tools, act consistently with human values, or improve domain performance. Where the content of those datasets is copyrightable, or the datasets themselves evince human selection and arrangement of data, and the datasets are primarily or solely targeted at AI training, widespread unlicensed use would likely cause market harm. Uses involving the retrieval of copyrighted works by RAG can also result in market substitution. As described above, RAG augments AI model responses by retrieving relevant content during the generation process, resulting in outputs that may be more likely to contain protectable expression, including derivative summaries and abridgments. A user for whom the augmented response \"satisf[ies] the . . . need\" for the original work will not pay to obtain it in the marketplace. Market Dilution A number of commenters contended that courts should consider the harms caused where a generative AI model's outputs, even if not substantially similar to a specific copyrighted work, compete in the market for that type of work. Pointing to copyright's underlying goals of incentivizing creation, the Copyright Alliance argued that \"with generative AI, the harm is often to a creator's overall body of work or even the market more broadly. These harms all impact the creator's incentives, and they should be considered under a factor-four analysis.\" Professor David Newhoff stated, \"[G]enerative AI—if it does not produce market substitutes—primarily represents potential harm to authors and future authorship. . . . [T]he consideration in the context of 'training' should be expansive and doctrinal—namely that a potential threat to 'authorship' cannot, by definition, 'promote the progress' of 'authorship.'\" And the Association of American Publishers asserted that \"[i]f a copyrighted work is reproduced to train a Gen AI model that will generate works that compete in the market with the copyrighted work, it will clearly reduce the value of that copyrighted work.\" Other commenters argued that the fourth factor analysis considers only harm to markets for the specific copyrighted work. In the words of one, \"if the [fourth factor] inquiry were to extend to whether the AI system competes in the market for a general class of works, it could have unintended and potentially detrimental consequences. This broader scope would potentially stifle innovation and creativity in AI development, as it could effectively ban the use of the technology altogether.\" While we acknowledge this is uncharted territory, in the Office's view, the fourth factor should not be read so narrowly. The statute on its face encompasses any \"effect\" upon the potential market. The speed and scale at which AI systems generate content pose a serious risk of diluting markets for works of the same kind as in their training data. That means more competition for sales of an author's works and more difficulty for audiences in finding them. If thousands of AI-generated romance novels are put on the market, fewer of the human-authored romance novels that the AI was trained on are likely to be sold. Royalty pools can also be diluted. UMG noted that \"[a]s AI-generated music becomes increasingly easy to create, it saturates this already dense marketplace, competing unfairly with genuine human artistry, distorting digital platform algorithms and driving 'cheap content oversupply' - generic content diluting human creators' royalties.\" Market harm can also stem from AI models' generation of material stylistically similar to works in their training data. As the Office noted in Part 1 of this Report, many commenters raised concerns about AI outputs that imitate a creator's style, which copyright does not protect as a separate element. Even when the output is not substantially similar to a specific underlying work, stylistic imitation made possible by its use in training may impact the creator's market. In the words of the Writers Guild of America, because AI systems can be prompted to imitate a writer's style, applying fair use would force writers \"to compete with AI-generated scripts trained on their work, without their authorization, and without fair compensation.\" This threat is more acute because of the technology's ability to produce works so similar in style \"that the average person cannot discern a difference in the marketplace[,] . . . creat[ing] direct competition with the creators whose works have been used to train the model.\" Lost Licensing Opportunities Lost revenue in actual or potential licensing markets can also be an element of market harm. Because, in theory, copyright owners could accept payment for any uses of their works, the relevant markets are those that are \"traditional, reasonable, or likely to be developed.\" A licensing market need not be long-standing or exhaustive, however, to be cognizable. Licensing is core to the business model of many content industries, and several industry representatives professed their willingness and ability to license works for AI training. Many commenters stated that individual and collective licenses for AI use were already in existence or under development. As of the end of 2023, they reported that AI developers were licensing copyrighted works in a number of sectors, including music, vocal recordings, and news reports. Commenters highlighted public licensing deals between OpenAI and the Associated Press (news) and Shutterstock (images), Getty Image's collaborations with Nvidia and Bria, and the collaboration between vAIsual and music/audio broker Rightsify. They suggested that further licensing was expected, particularly in sectors well-positioned to accommodate expanded voluntary licensing, like music and academic publishing. Since the comments were submitted, considerable activity has taken place. Recent public reporting reflects AI licensing for images and audio-visual works, academic and non-fiction publishing, and news publishing, as well as various content aggregators offering or facilitating collective licensing of training materials. A number of commenters disputed that current licensing activity demonstrates the feasibility of broad implementation of voluntary licensing. They argued that licensing cannot provide the quantity, diversity, or type of data that many AI systems require; that licensing such data would be prohibitively expensive and available only to certain developers and for certain copyrighted works; and that the practical challenges of identifying and contacting copyright owners would make full licensing impossible. Although licensing markets are still developing and factual contexts vary, available information shows that markets exist or are \"reasonable\" or \"likely to be developed,\" for certain copyright sectors, types of training or uses, and models. Direct licensing is most common and most promising with respect to corporate entities with catalogs of high-quality and easily identifiable content. For example, content controlled by large stock photography companies, national news outlets, and major record companies or film studios may be more easily licensable. Such content likely has a higher training value because it is high-quality and curated, and the centralization of rights makes it easier to license without incurring substantial volume-related transaction costs. Yet, it is also unclear that markets are emerging or will emerge for all kinds of works at the scale required for all kinds of models. There are copyright sectors where licensing infrastructure does not yet exist and may be difficult to build, and the amount of training data needed to produce state-of-the-art models may vary by content type or type of training. Administrative or transactional costs can pose particular challenges when works are created outside of professional creative industries or are not intended to be monetized, or when ownership is diffuse. Transaction costs in some cases might exceed the value of the works for training and render direct licensing infeasible. As both the creative industries and AI technologies develop further, data needs and licensing markets will continue to evolve. Where licensing markets are available to meet AI training needs, unlicensed uses will be disfavored under the fourth factor. But if barriers to licensing prove insurmountable for parties' uses of some types of works, there will be no functioning market to harm and the fourth factor may favor fair use. Public Benefits As part of the fourth factor, some courts have evaluated the public benefits that the defendant's use is likely to produce, considering how these benefits relate to the goals of copyright and their relative importance. A number of commenters identified public benefits from unlicensed generative AI training. OpenAI, for example, stated that generative AI promises to \"augment human capabilities, thereby fostering human creativity.\" Meta has asserted in litigation that its open-source models enable \"platforms built on Llama, to bring innovative and, in some cases, potentially life-saving services and technologies to market.\" Several commenters maintained that limiting training content would negatively affect model performance, leading to bias and inaccuracy. On the other hand, others asserted that unlicensed use of copyrighted works to train AI injure the public by impeding the growth of the creative economy and authors' ability to earn livelihoods. DCN stated that generative AI systems' use of news articles appropriates their value and \"may make it impossible for publishers to continue to create, develop, and publish new articles and other materials, which is surely not in the public interest.\" Others maintained that the benefits of high-quality AI could be achieved with fully-licensed datasets. Commenters cited several examples of AI tools trained on licensed or public domain content, such as Adobe's Firefly (an image generator), Boomy (a music generator), Getty Images' AI image generator, and Stability AI's Stable Audio (a music generator). In the Office's view, there are strong claims to public benefits on both sides. Many applications of generative AI promise great benefits for the public, as does the production of expressive works. While the sheer volume of production itself does not necessarily serve copyright's goals, commenters identified a wide range of potential benefits weighing in favor and against training on unlicensed copyrighted works. With regard to the fair use analysis, however, the Office cannot conclude that unlicensed use of copyrighted works for training offers copyright-related benefits that would change the fair use balance, apart from those already considered. The copying involved in AI training threatens significant potential harm to the market for or value of copyrighted works. Where a model can produce substantially similar outputs that directly substitute for works in the training data, it can lead to lost sales. Even where a model's outputs are not substantially similar to any specific copyrighted work, they can dilute the market for works similar to those found in its training data, including by generating material stylistically similar to those works. The assessment of market harm will also depend on the extent to which copyrighted works can be licensed for AI training. Voluntary licensing is already happening in some sectors, and it appears reasonable or likely to be developed in others—at least for certain types of works, training, and models. Where licensing options exist or are likely to be feasible, this consideration will disfavor fair use under the fourth factor. Weighing the Factors It is for the courts to weigh the statutory factors together \"in light of the purposes of copyright,\" with no mechanical computation or easy formula. How much each factor adds to the balance, and in which direction, will depend on the facts and circumstances of the particular case. We observe, however, that the first and fourth factors can be expected to assume considerable weight in the analysis. Different uses of copyrighted works in AI training will be more transformative than others. And given the volume, speed and sophistication with which AI systems can generate outputs, and the vast number of works that may be used in training, the impact on the markets for copyrighted works could be of unprecedented scale. As generative AI involves a spectrum of uses and impacts, it is not possible to prejudge litigation outcomes. The Office expects that some uses of copyrighted works for generative AI training will qualify as fair use, and some will not. On one end of the spectrum, uses for purposes of noncommercial research or analysis that do not enable portions of the works to be reproduced in the outputs are likely to be fair. On the other end, the copying of expressive works from pirate sources in order to generate unrestricted content that competes in the marketplace, when licensing is reasonably available, is unlikely to qualify as fair use. Many uses, however, will fall somewhere in between. Competition Among Developers Some commenters and scholars have raised concerns about how the application of fair use will affect the competitive ecosystem. In the words of the Federal Trade Commission (\"FTC\"), \"the evolution of the [fair use] doctrine could influence the competitive dynamics of the markets for AI tools and for products with which the outputs of those tools may compete.\" They warn that requiring AI companies to license copyrighted works for use in training would entrench power in the largest and best-resourced companies and content owners. Andreessen Horowitz asserted that \"treating AI model training as an infringement of copyright would inure to the benefit of the largest tech companies—those with the deepest pockets and the greatest incentive to keep AI models closed off to competition.\" R Street similarly contended that if training is not fair use, \"[o]nly large entities, like tech giants, that have the resources to navigate the licensing landscape or have already amassed vast amounts of data might be able to compete effectively in the AI space.\" Other commenters disagreed. ASCAP argued that AI training licensing \"need not pose an insurmountable obstacle to smaller AI developers\" and can be \"accomplished in numerous ways—e.g., grants or public funding—that do not exploit individual creators.\" Ed Newton-Rex suggested \"a revenue share between the content rights-holder and the AI provider, which can be achieved without any upfront payment,\" adding that \"small teams and small companies are already putting in place such models, disproving the argument that they will be shut out by licensing.\" While concerns about the effects of licensing on competition among AI companies should not be discounted, we do not believe they alter the fair use analysis. Licensing will always be easier for those with deeper pockets, and the more works to be licensed, the greater the effect. To the extent broader competition issues are at stake, they can more appropriately be dealt with by antitrust laws and the agencies empowered to enforce them. As the FTC acknowledged, \"conduct that may be consistent with the copyright laws nevertheless may violate Section 5 [of the Federal Trade Commission Act],\" including actions taken by large companies to entrench their positions in AI markets. International Approaches Other countries are also grappling with the legal issues surrounding use of copyrighted works to train AI models. Several have enacted exceptions allowing for text and data mining (\"TDM\") that are potentially applicable to AI training. TDM methods predate the current forms of generative AI. They are not necessarily \"generative\" in the sense of producing new expressive material but involve some of the same steps, particularly in the creation and curation of datasets. Jurisdictions with specific TDM exceptions include the European Union (EU), Japan, and Singapore. In the EU, the 2019 Directive on Copyright in the Digital Single Market (DSM Directive) directs member states to provide exceptions for \"reproductions and extractions\" of copyrighted material for use in TDM, in certain circumstances. Article 3 of the DSM Directive applies only to TDM activities by \"research organisations and cultural heritage institutions in order to carry out, for the purposes of scientific research, text and data mining of works or other subject matter to which they have lawful access.\" Article 4 is broader and applies to TDM activities by any actor for any purpose, but conditions the availability of the exception on lawful access and respecting opt-outs by copyright owners. In 2024, the EU adopted the Artificial Intelligence Act (\"EU AI Act\"), which references the DSM Directive's TDM exceptions in the context of generative AI. Recital 105 acknowledges that TDM techniques \"may be used extensively in [the context of training AI models] for the retrieval and analysis of such content, which may be protected by copyright and related rights.\" Article 53 obligates AI model providers to establish policies for complying with Union law and to identify and comply with copyright owner opt-outs under the DSM Directive's Article 4 TDM exception. There continues to be controversy, however, over how the TDM exceptions apply to uses involving generative AI and whether and how the opt-out provision will work. Discussions continue at both the EU level and in member states, and so far there is little case law on point. At this stage, it remains to be seen how that opt-out provision will be implemented by individual EU member states. In other jurisdictions as well, various limitations or conditions have been included in TDM exceptions. Singapore's version requires lawful access to the work and limits the use of copies to the purpose of computational data analysis. Copies may only be supplied to others for the purposes of verifying results or collaborative research. Japan's TDM exception allows the use of a copyrighted work for AI development or other forms of data analysis as long as the use is not to \"personally enjoy…the thoughts or sentiments expressed in that work.\" The exception does not apply if \"the action would unreasonably prejudice the interests of the copyright owner in light of the nature or purpose of the work or the circumstances of its exploitation.\" In its 2024 AI guidelines, Japan's Copyright Office explained that \"enjoyment\" refers to \"the act of obtaining the benefit of having the viewer's intellectual and emotional needs satisfied through using the copyrighted work,\" citing examples such as reading literary works, appreciating musical works, and executing works of computer programming. Generating material similar to the original works can be \"for enjoyment,\" and if a user's purpose is even partly for enjoyment, the exception does not apply. Similarly, \"reproducing a copyrighted database work for the purposes of data analysis, such as AI training for which licenses for data analysis are available in the marketplace,\" is not covered. UK law contains a narrower exception, dating back to 1988, that permits copying to \"carry out a computational analysis of anything recorded in the work for the sole purpose of research for a non-commercial purpose,\" but only if the copier has lawful access to the work. As part of its recent consultation on Copyright and Artificial Intelligence, the government has inquired into the application of this exception to AI and sought comments on introducing a TDM exception subject to copyright owner opt-outs, similar to the approach in the EU. This proposal has proved quite controversial, with commenters warning that it would impose burdensome transaction costs for both copyright owners and AI developers. Other countries have approached the legal status of AI training through the lens of fair use. In Israel, the copyright law includes a provision closely modeled on section 107 of the U.S. Copyright Act. In December 2022, the Ministry of Justice released an Opinion on the uses of copyrighted materials for machine learning, concluded that the use of copyrighted materials in machine learning datasets and training process is, in most but not all cases, fair use. It cautioned, however, that the Opinion \"does not apply to [machine learning]-based products, but only to the learning process itself. The infringing status of the product will be examined ad-hoc based on extant copyright rules and standards, and this Opinion does not grant products an a-priori safe harbor.\" In Korea, the Ministry of Culture, Sports and Tourism and the Korea Copyright Commission in 2023 released A Guide on Generative AI and Copyright. The guide recognizes that there is \"an ongoing debate within academia on the applicability of the fair use rule\" and observed that until \"several related court precedents accumulate,\" the \"applicability of the fair use defense will remain unclear,\" leaving open the possibility that \"using a work for AI training without permission from the copyright holder\" may constitute infringement. Approaches to generative AI and copyright matters in the People's Republic of China are developing, and it is not yet clear how the use of copyrighted works in training will be treated. The Copyright Act does not have an express exception for text and data mining activities or AI training. Article 24 of the Act contains a list of enumerated exceptions, including a new open-ended exception covering \"other circumstances as provided in laws and administrative regulations.\" With respect to litigation, one recent case held an AI platform provider contributorily liable for infringements occurring when users uploaded protected content into models available via the platform, which generated infringing copies. While there have been other cases involving infringing output, it appears that courts have yet to consider a copyright infringement claim against a foundation model developer based on the use of copyright protected works to train a foundation model. Meanwhile, press reporting on the annual work report from the Supreme People's Court indicates that the issue of intellectual property and AI is an area of ongoing attention. China has also issued at least two administrative measures providing guidance on generative AI services, including compliance requirements for training data. Avenues for supporting and developing the AI sector were topics receiving significant press coverage in relation to the March 2025 National People's Congress. Finally, a few countries are considering statutory approaches to compensation. In Brazil, a pending bill would require AI companies to compensate rightsholders for the use of their works in training. The draft directs the parties to discuss compensation in a manner that allows rightsholders to negotiate effectively either directly or collectively, calculate compensation that reasonably and proportionally considers the AI agent's size and the potential competition impacts; and preserves freedom of agreement. In 2024, Spain opened public commentary on a Draft Royal Decree which would establish an extended collective licensing mechanism for the mass exploitation of protected works in the development of AI models, although the proposal was subsequently withdrawn. In the NOI, we asked \"[a]re there any statutory or regulatory approaches that have been adopted or are under consideration in other countries that relate to copyright and AI that should be considered or avoided in the United States? How important a factor is international consistency in this area across borders?\" A number of commenters suggested that harmonization would be valuable to AI developers and copyright owners. Several addressed AI legislation elsewhere, particularly regarding TDM, transparency, and permissions signaling, but they did not call for the United States to emulate these approaches. Meta reported that \"[c]ountries around the world have adopted express and broad text- and data-mining (TDM) or fair use exceptions, creating similarly enabling environments for technological advancement and investment.\" UMG noted that the TDM exceptions in Japan and Singapore were enacted before the rise of generative AI, observing that \"[w]hatever their historical merit, generative AI poses threats that render them obsolete and damaging for the creative community, the music industry, and the general integrity of intellectual property law.\" A number of commenters discussed the EU framework, particularly to criticize its opt-out provisions. Some stressed that copyright is by its nature fundamentally an opt-in system of exclusive rights, or asserted that requiring opt-outs would be burdensome. NMPA cautioned against the creation of \"a patchwork of international exemptions with varying opt-out requirements\" which would be \"difficult if not impossible for most rightsholders to navigate.\" Others raised concerns about the persistence of opt-outs given the frequency of metadata stripping and their limited usefulness when works are obtained from unauthorized sources. One commenter noted that the feasibility of opt-out regimes may vary by model or type of work. Additionally, some commenters argued that the United States is treaty-bound to prohibit the unlicensed use of copyrighted works for AI training. CISAC, for example, maintained that extending fair use to cover generative AI training \"violates the 'three-step test'\" in various copyright treaties to which the United States is a party. Another stakeholder argues that an opt out-based exception is unworkable and inconsistent with treaty obligations. These are still early days, and it remains to be seen how exceptions elsewhere will be applied or what new ones will be developed. Already, however, a few common elements can be observed. Governments and courts are endeavoring to differentiate among the different acts involved in assembling data, training models, and producing outputs. Many of the relevant provisions distinguish between uses for scientific, analytical, or educational purposes and other uses, notably for enjoyment purposes. And several condition eligibility for exceptions on lawful access to works in the training data. As other countries determine their approaches to generative AI training, the Copyright Office will continue to monitor developments to assess the implications for U.S. copyright policy. LICENSING FOR AI TRAINING To the extent that some uses of copyrighted works to train AI models will require licensing, what forms of licensing can best accommodate the interests of both copyright owners and AI companies? This section sets out different options and considers their benefits and challenges. The NOI asked several questions on this topic, including whether direct or collective voluntary licensing is feasible in some or all creative sectors, what legal, technical, or practical issues there might be, and whether Congress should consider establishing a compulsory licensing or extended collective licensing (ECL) system. Commenters provided extensive information in response, with a range of views. Below we first discuss voluntary licensing issues and then the possibility of government intervention. Voluntary Licensing Voluntary licenses, negotiated in the free market, enable parties to set terms tailored to the specific uses of the works. These agreements can be negotiated on an individual (direct) or collective basis. Collective voluntary licensing agreements are often administered by thirdparty organizations (typically called \"collective management organizations\" or \"CMOs\"), authorized by multiple copyright owners to negotiate on their behalf and collect and distribute royalties. As discussed above, voluntary licensing of copyrighted works for use in AI training is increasingly taking place. As of the end of 2023, commenters reported that AI developers and copyright owners had entered into license agreements in several sectors, and more individual and collective licensing has occurred since. But questions remain about the extent to which voluntary licensing is feasible for different types of works and fully able to meet the needs of the AI industry. Apart from the impact on the actual or potential market for copyrighted works, discussed above in the context of fair use, commenters focused on three main topics: (1) the feasibility of voluntary licensing; (2) the ability to provide meaningful compensation; and (3) possible legal impediments to collective licensing. Feasibility of Voluntary Licensing Many commenters, generally representing technology interests, expounded upon logistical, financial, and other challenges involved in voluntary licensing, including whether a sufficient quantity and variety of works can be licensed at the scale necessary to train high-quality models. They asserted that the cost of licensing copyrighted works for AI training would create an insurmountable obstacle. For example, a16z stated that, \"under any licensing framework that provided for more than negligible payment to individual rights holders, AI developers would be liable for tens or hundreds of billions of dollars a year in royalty payments,\" which would serve as a barrier to AI development and innovation. Several commenters expressed concern about the financial impact of a licensing requirement on researchers in particular, including those \"who want to try to solve the many problems associated with AI (such as detecting 'deep fakes,' preventing 'hallucinations,' 'unlearning' information, and reducing computing's energy demands).\" Meta also pointed to the potential impact on open-source licensing of AI models, arguing that \"no company could afford to pay licensing fees based on third-party uses of that company's models, and even tracking how models were used would be impracticable.\" Commenters also cited practical challenges in securing licenses for the volume and variety of works potentially needed for AI training. R Street stated that \"[t]he process of identifying, negotiating and securing licenses for every individual piece of content in a dataset would be resource-intensive. These increased costs could be passed on to consumers or could deter companies from pursing certain AI-driven projects altogether.\" According to several commenters, these problems would be compounded by the difficulty in determining ownership of many of the works in training datasets, a necessary predicate to entering into licensing negotiations. For example, Meta contended that \"it would be impossible for AI developers to license the rights to other critical categories of works—like internet reviews and other examples of casual, vernacular text—both because it would be impossible to locate the owners of such works, and administratively impossible to negotiate licenses with each of them.\" It asserted that even collective licensing would create \"massive administrative problems.\" Commenters representing copyright owner and creator interests, on the other hand, argued that the costs or difficulty of obtaining licenses for the volume of works required for AI training is not an excuse for failing to do so. They contended that obtaining licenses is simply a cost of doing business, and one that AI companies can afford, especially where their commercial products depend on the use of copyrighted works. Authors Guild stated, \"Arguments that it is too expensive do not justify the use [without permission]. AI companies are spending millions and even billions on development and computing power. Why should the authors' contribution be free for the taking when generative AI is nothing without the works it is trained on?\" In the Copyright Alliance's view, \"[t]he idea that just because it may be harder to get consent from copyright owners when large volumes of works are being used, it is therefore not infringement, would simply incentivize infringers to illegally copy more as a means for avoiding infringement—that cannot possibly be the law.\" These commenters also disputed the factual premise that voluntary licensing is infeasible. Getty Images asserted that \"[l]icenses to scaled quantities of content and metadata required to train Generative AI Models are already readily available,\" and \"[t]he claim by some developers that there is no way to get consent from copyright holders given the quantity of materials needed to train AI Models is simply untrue.\" It stated that \"[t]here is an established market for training data, and there is a growing body of high-quality Generative AI Models that have been trained on content licensed for that purpose.\" Commenters also pointed out that AI licensing deals are already occurring, pointing to a growing number of examples of fully licensed models in certain sectors and for certain purposes. Some AI developers describe their companies, products, and models as relying exclusively on owned or licensed data, and at least one organization, Fairly Trained, has established mechanisms to certify such claims. Fully licensed training datasets have supported the production of AI models and products capable of producing text, images, and music. Of these, music models are the most common to be certified by Fairly Trained. AI companies and supporters stressed that current licensing activity does not demonstrate the feasibility of voluntary licensing at scale across all contexts. For example, a16z stated that \"[t]he fact that large rights owners are willing to strike deals is irrelevant, as such deals would only permit use of a small amount of the content needed to adequately train AI systems.\" Meta asserted that \"it would be impossible for any market to develop that could enable AI developers to license all of the data their models need,\" noting that \"[g]enerative AI models need not only a massive quantity of content, but also a large diversity of content,\" and deals with individual rightsholders \"would provide AI developers with the rights to only a miniscule fraction of the data they need to train their models.\" Meta also disputed the viability of fully licensed models, contending that \"there is no evidence that licensed or public domain data is sufficient to build a useful state-of-the-art Generative AI model capable of competing with available alternatives.\" It noted, however, that \"[u]ltimately, whether it is possible to train a competent Generative AI model using only public domain or licensed data will depend on a number of fact-specific considerations, including the medium of the model's output.\" Some commenters stressed that voluntary licensing would be especially challenging for smaller stakeholders on both sides. Daniel Gervais stated that \"[i]t is simply not reasonable to expect a user, especially a smaller one, to identify every right holder in every copyrighted work they want to use (even assuming they can determine what is and is not a protected work) and then locate and contact those rightsholders one by one. Nor does it make business sense for even large rightsholders to have an army of licensing agents dealing with potentially thousands of small-scale users around the world, not to mention currency and linguistic barriers.\" Others expressed concern that smaller copyright owners would have reduced bargaining power and would either be overlooked in licensing deals or would receive substandard terms. A number of commenters supported voluntary collective licensing as a way of reducing transaction costs and facilitating bulk licensing. SGA called collective licensing \"the most cost-effective and efficient manner of authorizing the ingestion of copyrighted works into generative AI systems.\" Authors Guild opined that \"collective licensing could solve the problem of how to license a mass number of works to AI developers for AI training on behalf of individual creators and small business on an industry-by-industry basis.\" News/Media Alliance asserted that \"[w]hile collective licensing should not be required, and individual licensing always permitted, voluntary collective licensing may well prove useful by providing the ability to aggregate smaller publishers, thereby reducing transaction costs and facilitating more efficient licensing and distribution for a greater number of licensors.\" And Recording Academy said that while \"direct licensing should be the default approach,\" \"where direct licensing is inefficient or inaccessible with respect to independent songwriters and artists who lack the resources and leverage to successfully enter into such agreements,\" \"voluntary collective licensing may prove beneficial.\" Commenters largely agreed that the quantity, quality, and type of data needed will vary among AI models, depending on their structure and intended use. And the industries from which copyrighted works are drawn reflect varied market realities, each with different licensing customs and practices. For example, while \"[i]t is true that, in some modalities (e.g. text), you still need a very large amount of data to train the best models . . . it is by no means certain that this will always be the case.\" Ability to Provide Meaningful Compensation Commenters were divided as to whether or not copyright owners can be compensated meaningfully for licensing their works for AI training. Some contended that it would not only be cost prohibitive for AI developers to pay copyright owners in the aggregate, but that compensation to any individual copyright owner would be negligible due to the volume of works typically used for training. Hugging Face deemed this a \"worst of both worlds\" scenario, stating that \"such a deal would be costly enough to exclude any but the very largest companies from training new models, while still providing negligible additional income to the original data creators.\" On the other side, commenters argued that these statements ignore the value of compensation accrual over time, which can add up to meaningful amounts. In the words of the Copyright Alliance, \"[t]he notion that licensing should not be required because these royalties may be small would turn copyright, and many other licensing models, on its head.\" These commenters asserted that AI training can have a positive economic impact on copyright owners, motivating the creation of new works, with one declaring that \"[t]he economic consequences of requiring licenses will be to bolster creators, the U.S. economy, and our culture.\" Another suggested that if AI companies struggle to compensate rightsholders in the near-term, rightsholders can negotiate licenses that forgo up-front payments or traditional royalties in exchange for later shares in revenues as the companies grow. The quality of training data may also affect potential compensation, and some have observed that quality for training purposes may correspond with works' commercial value in other contexts. Licensors touted their products as attractive to AI companies because they can provide data that is newly released, high-quality, curated, and clean. An AI developer might, for example, use licensed material because it is \"diverse and high quality [and] long-context\" and give it higher weight in training than other data. Because data quality and model quality are correlated, AI firms seeking to offer higher model quality than their competitors may turn to licensing; this has resulted in what some have described as a multi-billion dollar race. Possible Legal Impediments to Collective Licensing Some commenters raised concerns that copyright owners banding together to negotiate collective licenses could have antitrust implications. One contended that \"collective licensing is inherently anticompetitive and existing [CMOs] for music have repeatedly demonstrated their tendency to use their collective power to the detriment of both their licensees and their constituent authors.\" To avoid such concerns, several commenters urged adoption of an antitrust exemption allowing collective licensing of copyrighted works for AI training. Others believed that statutory change was premature, or suggested first seeking guidance from the Department of Justice. Statutory Approaches There was little support among commenters for statutory approaches to licensing, whether compulsory licenses or ECL. Compulsory Licensing Compulsory licenses are established by law and allow use of a copyrighted work without the consent of the copyright owner. They apply to specific uses, users, and works, and require compliance with certain statutory and regulatory requirements, such as making royalty payments and related filings. Compulsory licenses in the United States have in the past been adopted where Congress determined that the free market was incapable of supporting effective or efficient voluntary licensing. Because such licenses obviate the need to engage in negotiations, they can be an efficient mechanism in situations with high transaction costs to permit a publicly beneficial use of copyrighted works while providing remuneration to copyright owners. At the same time, they generally require a substantial administrative apparatus. Rate setting and distribution proceedings involve significant sums and are often contentious. Participants may spend large amounts on legal fees and proceedings can take years to reach final resolution. Many licenses have also required the promulgation of voluminous and complex regulations. The Office has historically been wary of compulsory licenses as \"a derogation of the author's right to control the use and distribution of his or her work,\" urging that they \"should be enacted only in exceptional cases, when the marketplace is incapable of working.\" As we have previously observed, \"once a compulsory license is implemented it becomes deeply embedded in industry practices and—even when its original rationale is lost in time—is difficult to undo. That alone should counsel caution in all but the most manifest instances of market failure.\" Compulsory licenses \"should be provided only if shown to be required by a clear public interest outweighing the reasons for protecting the author's rights\" and \"should not go any further than is shown to be necessary in the public interest.\" Congress has expressed similar views. Most commenters who addressed this issue opposed or raised concerns about the prospect of compulsory licensing. Those representing copyright owners and creators argued that the compulsory licensing of works for use in AI training would be detrimental to their ability to control uses of their works, and asserted that there is no market failure that would justify it. A2IM and RIAA described compulsory licensing as entailing \"below-market royalty rates, additional administrative costs, and . . . restrictions on innovation.\" The Copyright Alliance said that it \"undermines the Constitutional purposes and goals of federal copyright law and destroys the existing incentives for copyright owners to create and disseminate a diverse array of creative works to the public.\" And NMPA saw it as \"an extreme remedy that deprives copyright owners of their right to contract freely in the market, and takes away their ability to choose whom they do business with, how their works are used, and how much they are paid.\" Moreover, in the view of Authors Guild, \"there is no indication that AI licensing markets have failed or are likely to do so.\" Commenters from the technology sector asserted that AI training is a noninfringing use and should not be subject to any licensing regime, whether voluntary or compulsory. As with voluntary licensing, they argued that it is not logistically feasible and would result in only meager royalty payments due to the volume of works used. For example, a16z contended that a compulsory licensing scheme \"would prove administratively impossible to implement\" largely due to \"scale,\" noting that \"[f]or a very significant portion of those [\"billions of pieces of text from millions of individual websites\" used for training], it is essentially impossible to identify who the relevant rights holders are, and thus there would be no viable way to get statutory royalties to the proper parties.\" Authors Alliance added that compulsory licensing is \"logistically infeasible because of the scale and complexity of the training datasets needed to train AI models.\" Some cautioned that compulsory licensing is inflexible and \"will not be able to keep up with the pace of development of generative AI, and may end up hurting both copyright holders and AI developers alike.\" Extended Collective Licensing ECL is another approach, which has been adopted in some European countries in other contexts. ECL typically involves a CMO being authorized to license all copyrighted works within a particular class of works for specific uses, binding all copyright owners in that class unless they opt out and choose to negotiate separately. This permits users to license numerous disparate works by copyright owners (including individual authors or small businesses) who have not affirmatively joined a CMO. To obtain such authorization, the CMO usually must demonstrate that it represents a substantial number of copyright owners of works in that class and may also be required to satisfy other criteria. Unlike compulsory licenses, with rates and terms set by the government, the licenses issued by a CMO under an ECL system are negotiated with users in the free market. In this way, an ECL system functions like voluntary collective licensing, but with the government regulating the overall system and exercising some degree of oversight. The ECL option received more support from commenters than a compulsory license, although views were mixed. Supporters generally envisioned ECL only for specific types of works, and not as a solution for all AI training. Several suggested that ECL could be well-suited to the needs of visual artists. Authors Guild proposed a twofold ECL system, distinguishing between past and future uses, and between professional creatives and other members of the public. Opposition came primarily from copyright owners who favored a purely voluntary licensing approach, but also from commenters who opposed all licensing obligations. Some viewed ECL as presenting similar concerns to compulsory licensing or practically infeasible due to scale. Others confined their opposition to the works in their own sectors on the grounds that a voluntary licensing market already exists. Opting Out A number of commenters addressed the possibility of a statutory \"opt-out\" mechanism, allowing copyright owners to signal the withholding of their works from AI training. Such an approach has been adopted in the EU as part of its text and data mining exception, as described above. Copyright owners rejected the idea of any opt-out approach. They asserted that it would be antithetical to current law, unduly burdensome, impossible to utilize after training occurs, and difficult to implement. News/Media Alliance stated that \"existing law is 'opt in'\" and that \"[c]hanging this presumption under U.S. law would require the adoption of an additional exception under the law, a major undertaking that is not warranted under present circumstances.\" And National Writers Union contended that \"[a]n opt-out approach is not a feasible option for some creative workers and copyright owners,\" as \"[t]ools like technical flags and metadata can be prohibitive for those unfamiliar with digital technologies and people with impairments that impact their ability to utilize these tools.\" Commenters also discussed a variety of potential opt-out methods, such as using metadata, databases, watermarking, technical flags, and website terms of service. While some in the technology sector identified certain approaches as \"effective,\" \"simple,\" or \"ideal,\" many raised concerns, pointing to the ease with which metadata can be removed or the inability of copyright owners to use a platform-level flag, like robots.txt, if they do not control the platform. Copyright Alliance further asserted that robots.txt \"has significant limitations because it is only effective to the extent it is recognized and respected, and it was not designed to be targeted to scraping for generative AI ingestion.\" Moreover, it said that robots.txt \"would also prevent a search engine from scraping and categorizing the work,\" and that \"[a] copyright owner may want their work to be scraped for search engine purposes—so they can be found on the internet—but not for AI ingestion.\" Those commenters with a positive view of opt outs said they could be beneficial to \"support[ing] open development of generative AI datasets and pre-trained models by a broader range of actors,\" \"foster[ing] international consistency with regimes such as the EU directive on Copyright in the Digital Single Market and proposed AI Act,\" and empowering creators to share their works freely without fear of objectionable use, while creating \"a default of permissiveness that promotes an overall more open creative environment.\" Several asserted that voluntary measures adopted by AI companies allowing copyright owners to opt out of training have merit, but did not advocate for an opt-out system to be established by law. Analysis and Recommendations In assessing any form of licensing, it is important to recognize the wide variations in works and uses involved in AI training. Feasibility will depend on the types of works needed, the licensing practices of the relevant industries, the design of the AI system, and its intended uses. For instance, licensing a music model that can produce rudimentary jingles is different from licensing a state-of-the-art LLM that can compete on advanced reasoning benchmarks. And sophisticated commercial entities will be easier to find and negotiate with than individual non-professionals. As discussed above, a number of voluntary direct and collective licensing agreements for using copyrighted works in AI training have emerged over the past several years, with others in development. Some AI systems have now been trained exclusively on licensed or public domain works. These developments demonstrate that voluntary licensing may be workable, at least in certain contexts—particularly where training is focused on valuable content that can be licensed in relatively high volumes (e.g., popular music and stock photography), or in fields where the number of copyright owners is limited. The Office recognizes, however, that practical challenges remain in many areas. The growing licensing market does not itself establish that voluntary licensing is feasible at scale for all AI training needs. To the extent that the remaining gaps cannot reasonably be filled, alternative solutions may be needed. As to compensation, further market developments may provide more insight on the extent to which licensing agreements can effectively compensate copyright owners for the use of their works in AI training. The agreements that already exist indicate that mutually agreeable compensation terms can be negotiated in some situations, although it remains to be seen how they scale. Compensation structures based on a percentage of revenue or profits, without large up-front cash outlays, may be an attractive alternative for smaller developers looking to enter the market. As to concerns voiced by commenters about the affordability for academic researchers, we note that the research projects they identify may well qualify as fair use and therefore would not require licenses. And the amount of monetary compensation that some copyright owners will accept may depend on contractual conditions regarding control of the use of their works. As discussed above, there appears to be strong interest among those representing copyright owners and creators in developing voluntary collective licensing for the AI context. Collective licensing can play a significant role in facilitating AI training, reducing what might otherwise be thousands or even millions of transactions to a manageable number. The aggregation of rights could be mutually beneficial, such as where transaction costs might otherwise exceed the value of using a work or where copyright owners might be difficult to find. Although collective licensing presents its own logistical and organizational challenges, it affords copyright owners and licensees flexibility to tailor agreements to their needs. Multiple CMOs can each license different types of copyrighted works on terms that make sense for that particular creative industry and AI model. As to antitrust concerns, courts have found that there is nothing intrinsically anticompetitive about the collective, or even blanket, licensing of copyrighted works, as long as certain safeguards are incorporated—such as ensuring that licensees can still obtain direct licenses from copyright owners as an alternative. Although antitrust law is beyond the scope of the Office's expertise, we believe that greater clarity would be valuable. We encourage the Department of Justice to provide guidance, including on the benefit of an antitrust exemption in this context. We agree with commenters that a compulsory licensing regime for AI training would have significant disadvantages. A compulsory license establishes fixed royalty rates and terms and can set practices in stone; they can become inextricably embedded in an industry and become difficult to undo. Premature adoption also risks stifling the development of flexible and creative market-based solutions. Moreover, compulsory licenses can take years to develop, often requiring painstaking negotiation of numerous operational details. For those sectors where voluntary licensing may prove unworkable or infeasible, ECL would be a less intrusive approach. It would permit copyright owners to choose to license separately, while enabling full coverage of the entire sector for AI training. Allowing authorized CMOs to negotiate rates and terms and establish policies and procedures, subject to government oversight would provide flexibility, rather than freezing rates in the statute or setting them through judicial or administrative proceedings. As to the possibility of an opt-out mechanism, the Office agrees that requiring copyright owners to opt out is inconsistent with the basic principle that consent is required for uses within the scope of their statutory rights. But to the extent that Congress may consider an exception or limitation for AI training in the future, the ability to opt out could preserve some ability to block unwanted uses or negotiate terms. Nevertheless, significant concerns have been raised about the effectiveness and availability of opt-outs, which would need to be addressed. Finally, we note that the law, technology, and markets for training are relatively nascent, and there is a dynamic interplay between them. To begin with, the current licensing market may be distorted by the unsettled legal questions about fair use. While some AI companies may have licensed works for training to avoid uncertainty or obtain access to high-quality or otherwise-unavailable materials, other licensing activities may be inhibited by reliance on fair use. As courts begin to resolve pending cases, greater legal clarity may lead to greater collaboration on technical and market-based solutions. Similarly, new model architectures and techniques may be developed to facilitate training using fewer unlicensed works without sacrificing quality. Whether companies devote resources toward such solutions may in turn be influenced by the shifting incentives created by legal and licensing developments. In light of the foregoing, at this point in time, the Office recommends allowing the licensing market to continue to develop without government intervention. If market failures are shown as to specific types of works in specific contexts, targeted intervention such as ECL should be considered. CONCLUSION Throughout its history, copyright law has adapted to new technology, furthering its progress while preserving incentives for creative activity. This has enabled our nation's creative and technology industries to become global leaders in their fields. While the use of copyrighted works to power current generative AI systems may be unprecedented in scope and scale, the existing legal framework can address it as in prior technological revolutions. The fair use doctrine in particular has served to flexibly accommodate such change. We believe it can do so here as well. In applying current law, we conclude that several stages in the development of generative AI involve using copyrighted works in ways that implicate the owners' exclusive rights. The key question, as most commenters agreed, is whether those acts of prima facie infringement can be excused as fair use. The fair use determination requires balancing multiple statutory factors in light of all relevant circumstances. Although it is not possible to prejudge the result in any particular case, precedent supports the following general observations: Various uses of copyrighted works in AI training are likely to be transformative. The extent to which they are fair, however, will depend on what works were used, from what source, for what purpose, and with what controls on the outputs—all of which can affect the market. When a model is deployed for purposes such as analysis or research—the types of uses that are critical to international competitiveness—the outputs are unlikely to substitute for expressive works used in training. But making commercial use of vast troves of copyrighted works to produce expressive content that competes with them in existing markets, especially where this is accomplished through illegal access, goes beyond established fair use boundaries. For those uses that may not qualify as fair, practical solutions are critical to support ongoing innovation. Licensing agreements for AI training, both individual and collective, are fast emerging in certain sectors, although their availability so far is inconsistent. Given the robust growth of voluntary licensing, as well as the lack of stakeholder support for any statutory change, the Office believes government intervention would be premature at this time. Rather, licensing markets should continue to develop, extending early successes into more contexts as soon as possible. In those areas where remaining gaps are unlikely to be filled, alternative approaches such as extended collective licensing should be considered to address any market failure. In our view, American leadership in the AI space would best be furthered by supporting both of these world-class industries that contribute so much to our economic and cultural advancement. Effective licensing options can ensure that innovation continues to advance without undermining intellectual property rights. These groundbreaking technologies should benefit both the innovators who design them and the creators whose content fuels them, as well as the general public. Finally, as in prior Parts of this Report, the Office recognizes that facts on the ground are evolving at a rapid pace. We will continue to monitor developments in technology, case law, and markets, and to offer further assistance to Congress as it considers these issues.",
      "word_count": 21204,
      "character_count": 138271,
      "vector": [
        0.17687319219112396,
        -0.16437296569347382,
        0.11567337810993195,
        0.02712571620941162,
        0.025707583874464035,
        0.030438028275966644,
        -0.055704522877931595,
        0.021711386740207672,
        0.003478143597021699,
        -0.0021592797711491585,
        -0.03427712619304657,
        0.11721686273813248,
        -0.019512837752699852,
        0.029008004814386368,
        0.045359447598457336,
        0.08477366715669632,
        -0.07270513474941254,
        0.07118792086839676,
        -0.07979802787303925,
        -0.05402566120028496,
        0.03094673529267311,
        -0.04141104593873024,
        0.08482646197080612,
        0.12093065679073334,
        -0.031653061509132385,
        0.0409570038318634,
        -0.08652198314666748,
        -0.10020877420902252,
        0.0030708208214491606,
        0.07233032584190369,
        0.02108253724873066,
        0.0011358512565493584,
        0.029200877994298935,
        -0.06441379338502884,
        -0.018619852140545845,
        -0.06384593993425369,
        0.05239846184849739,
        0.007469158619642258,
        -0.08506441861391068,
        -0.08240733295679092,
        -0.0033085481263697147,
        0.01646234840154648,
        -0.0030809270683676004,
        -0.016123762354254723,
        0.0944647267460823,
        0.019692085683345795,
        0.022366425022482872,
        -0.007878122851252556,
        0.012947553768754005,
        -0.01616719365119934,
        0.052122436463832855,
        0.0539265014231205,
        -0.04664897546172142,
        0.00570165179669857,
        0.04341154545545578,
        -0.01901151053607464,
        0.011676984839141369,
        0.0007368098013103008,
        -0.03380498290061951,
        0.0031289285980165005,
        -0.08251353353261948,
        0.048047345131635666,
        -0.034535251557826996,
        -0.017503412440419197,
        -0.0808759555220604,
        0.03900459036231041,
        -0.014924237504601479,
        -0.09363704174757004,
        -0.0625353530049324,
        0.003057591151446104,
        0.0124662509188056,
        0.03150590509176254,
        -0.0026170313358306885,
        -0.0015115410787984729,
        -0.022510943934321404,
        0.023663729429244995,
        -0.02627630904316902,
        0.01943463459610939,
        0.009542085230350494,
        0.008330176584422588,
        0.07634226977825165,
        -0.02548529952764511,
        0.014890914782881737,
        -0.01415918581187725,
        -0.00899132527410984,
        -0.01530181709676981,
        -0.04415895789861679,
        0.00015760716632939875,
        -0.0006004361202940345,
        -0.005252725910395384,
        0.006402924191206694,
        -0.13998885452747345,
        -0.025750480592250824,
        -0.13997630774974823,
        0.029631784185767174,
        0.02094367705285549,
        -0.09136317670345306,
        0.057389747351408005,
        -0.04815918579697609,
        0.012166467495262623,
        0.002070448361337185,
        0.020378386601805687,
        -0.04377780482172966,
        0.041757918894290924,
        -0.021926159039139748,
        0.0059555452316999435,
        -0.027747878804802895,
        0.04876724258065224,
        -0.09019657969474792,
        0.014154159463942051,
        -0.01592562533915043,
        0.022401830181479454,
        -0.05660261958837509,
        0.006157632917165756,
        0.02793731540441513,
        0.07136105000972748,
        -0.005032410845160484,
        0.06312142312526703,
        0.03956177458167076,
        -0.019395748153328896,
        -0.027731405571103096,
        0.007117999717593193,
        0.0397881343960762,
        0.010093306191265583,
        -0.0285190362483263,
        -0.008457724936306477,
        0.009058637544512749,
        -0.013073576614260674,
        0.007374892011284828,
        -0.0719408318400383,
        -0.04264242202043533,
        0.0697023794054985,
        -0.021110955625772476,
        -0.005475384648889303,
        -0.05121034383773804,
        -0.05230742692947388,
        0.01655614748597145,
        0.02696467749774456,
        -0.03979551047086716,
        0.035692017525434494,
        -0.0024401904083788395,
        0.04397505521774292,
        0.019564712420105934,
        0.0014001511735841632,
        -0.04336518049240112,
        -0.03746883571147919,
        0.027914585545659065,
        -0.012991311959922314,
        0.007261375896632671,
        0.009130103513598442,
        0.037613555788993835,
        0.009482079185545444,
        0.014767976477742195,
        0.03121493197977543,
        0.012045169249176979,
        -0.029761556535959244,
        0.0049795121885836124,
        -0.0058160084299743176,
        0.0038357586599886417,
        0.0498572513461113,
        0.011844659224152565,
        0.038549941033124924,
        -0.009876927360892296,
        0.026768099516630173,
        -0.018052805215120316,
        0.013977086171507835,
        -0.04481831192970276,
        0.008541814051568508,
        0.07057053595781326,
        0.01678835041821003,
        -0.03002893179655075,
        0.07863219082355499,
        0.06261856853961945,
        -0.03419523313641548,
        0.012731149792671204,
        -0.06558190286159515,
        -0.010380348190665245,
        0.07347944378852844,
        -0.00942352693527937,
        0.03450913354754448,
        0.017703138291835785,
        0.010765377432107925,
        0.009810220450162888,
        -0.009037638083100319,
        -0.03201610967516899,
        -0.014613577164709568,
        0.0028974576853215694,
        -0.02931280806660652,
        0.0009970087558031082,
        0.011415823362767696,
        -0.007772762328386307,
        0.00014228538202587515,
        0.06138141453266144,
        0.06964585185050964,
        -0.0018856680253520608,
        -0.020371321588754654,
        -0.06934791058301926,
        0.01185525581240654,
        -0.012908470816910267,
        0.011445542797446251,
        -0.019707024097442627,
        -0.06863235682249069,
        -0.02380451373755932,
        0.0054457527585327625,
        -0.0475444495677948,
        -0.00024772106553427875,
        0.0008239069720730186,
        0.004220065660774708,
        -0.017279010266065598,
        0.039386097341775894,
        -0.0330074243247509,
        0.0009057569550350308,
        0.011923478916287422,
        -0.0026484113186597824,
        -0.0658811554312706,
        0.018049221485853195,
        0.044672347605228424,
        0.050479162484407425,
        0.12626731395721436,
        -0.01966557465493679,
        0.03827549144625664,
        0.004195814486593008,
        -0.03374161943793297,
        -0.012759058736264706,
        -0.00787829328328371,
        -0.04848667234182358,
        0.0453011691570282,
        0.029017945751547813,
        -0.023860912770032883,
        0.00982142798602581,
        -0.005173546727746725,
        0.03621205314993858,
        -0.002539663342759013,
        -0.0023099947720766068,
        0.04522169381380081,
        -0.009004072286188602,
        -0.03500082716345787,
        0.0331273190677166,
        0.0632883608341217,
        -0.028523188084363937,
        -0.007213250268250704,
        -0.0176374614238739,
        -0.03523322194814682,
        -0.0006077332072891295,
        -0.034197740256786346,
        -0.010106709785759449,
        -0.024968866258859634,
        -0.042916033416986465,
        -0.020917613059282303,
        0.03291240707039833,
        0.02717651054263115,
        0.0238484013825655,
        -0.054089244455099106,
        0.001443582703359425,
        0.05805801972746849,
        -0.0026947977021336555,
        -0.002910205628722906,
        -0.02964635193347931,
        -0.04550487548112869,
        -0.006068688817322254,
        0.0117866275832057,
        0.017820054665207863,
        0.014230487868189812,
        0.017169293016195297,
        -0.037947215139865875,
        0.027025088667869568,
        -0.019562970846891403,
        -0.016672056168317795,
        0.0032866597175598145,
        -0.06769713014364243,
        -0.02536073513329029,
        -0.006973408628255129,
        0.0060587078332901,
        0.040088899433612823,
        0.018687626346945763,
        0.02302149124443531,
        -0.03512212634086609,
        0.03810800984501839,
        -0.008245783858001232,
        -0.05271555110812187,
        -0.06807228177785873,
        -0.01361329760402441,
        0.0274115651845932,
        -0.023897463455796242,
        0.009745177812874317,
        -0.02774093486368656,
        0.05096188932657242,
        0.028181780129671097,
        0.0380917452275753,
        -0.020833682268857956,
        -0.00512869143858552,
        -0.01858873851597309,
        0.014110453426837921,
        -0.013863703235983849,
        -0.016173850744962692,
        0.020718684419989586,
        -0.09331505745649338,
        0.004038827959448099,
        0.10185008496046066,
        0.04314996674656868,
        -0.0464920699596405,
        0.027809204533696175,
        0.006774371024221182,
        0.005027275066822767,
        0.009898716583848,
        -0.00551973981782794,
        -0.01574377715587616,
        -0.02340218983590603,
        -0.056863006204366684,
        -0.0020986099261790514,
        -0.005120478570461273,
        -0.020736565813422203,
        0.00046108290553092957,
        0.044068802148103714,
        -0.027939246967434883,
        0.002546109724789858,
        -0.0163101926445961,
        0.046355921775102615,
        0.007286722306162119,
        0.017600126564502716,
        0.0010294710518792272,
        0.029027344658970833,
        0.0069085098803043365,
        0.01483585499227047,
        -0.02969028614461422,
        -0.04503442719578743,
        -0.02915785275399685,
        -0.017401086166501045,
        -0.019836246967315674,
        -0.004385008942335844,
        -0.017625711858272552,
        -0.0044216858223080635,
        0.035113073885440826,
        0.015764102339744568,
        -0.03357137367129326,
        -0.010739445686340332,
        -0.010428902693092823,
        -0.016214806586503983,
        0.04758477956056595,
        0.024147633463144302,
        0.07707803696393967,
        0.008316748775541782,
        0.031586114317178726,
        -0.03092397376894951,
        0.007163404952734709,
        0.037565331906080246,
        0.024172615259885788,
        -0.03137550875544548,
        -0.00658022053539753,
        0.041935034096241,
        0.005602170247584581,
        0.00898753572255373,
        0.015844272449612617,
        -0.00777760474011302,
        0.009904180653393269,
        0.01595948450267315,
        -0.0016010834369808435,
        -0.006459890864789486,
        0.01660488173365593,
        -0.03890542685985565,
        -0.027951516211032867,
        -0.00030495398095808923,
        -0.00671157194301486,
        0.07182282209396362,
        -0.012515624053776264,
        0.004256323911249638,
        0.011960812844336033,
        0.051344748586416245,
        -0.008856069296598434,
        -0.008130081929266453,
        -0.016309957951307297,
        0.0027354953344911337,
        -0.010717871598899364,
        -0.0014223918551579118,
        -0.013795463368296623,
        -0.02786034345626831,
        0.022849619388580322,
        -0.015635240823030472,
        0.046188369393348694,
        0.0194094255566597,
        -0.017772860825061798,
        -0.028466109186410904,
        0.05541962757706642,
        0.016636688262224197,
        0.04718848690390587,
        0.01931830868124962,
        0.08589199185371399,
        -0.05580948293209076,
        0.002614292548969388,
        0.03350686654448509,
        0.022840509191155434,
        0.0014199153520166874,
        0.04186621680855751,
        0.0021382756531238556,
        -0.08002597093582153,
        -0.01239392813295126,
        0.04786106199026108,
        0.0075941793620586395,
        -0.005554831121116877,
        0.035996921360492706,
        0.028742743656039238,
        0.005872849375009537,
        0.015570765361189842,
        -0.060087431222200394,
        0.03978973627090454,
        -0.012638546526432037,
        0.05948429927229881,
        0.007826687768101692,
        -0.025419658049941063,
        0.006605605129152536,
        -0.0235123448073864,
        0.020979495719075203,
        -0.05108560621738434,
        -0.026307547464966774,
        -0.006254624575376511,
        -0.029152877628803253,
        0.005718381144106388,
        0.010262200608849525,
        -0.039892639964818954,
        -0.004281901754438877,
        0.008383902721107006,
        0.04351815581321716,
        0.01684727892279625,
        0.006708221044391394,
        0.03704175353050232,
        0.014113559387624264,
        -0.03966069966554642,
        -0.029532916843891144,
        0.008120449259877205,
        0.027364231646060944,
        -0.03305821120738983,
        -0.022530244663357735,
        0.023979471996426582,
        0.02550836093723774,
        0.015160327777266502,
        -0.016484709456562996,
        -0.01952100545167923,
        -0.030710875988006592,
        -0.00014076147635933012,
        0.0012973090633749962,
        0.01417909748852253,
        -0.009737929329276085,
        -0.016040930524468422,
        0.0051995133981108665,
        -0.005182140506803989,
        -0.004258404485881329,
        0.025313647463917732,
        -0.0453975610435009,
        0.010455172508955002,
        0.014938530512154102,
        -0.02084820158779621,
        0.034764405339956284,
        -0.06668689846992493,
        -0.049206703901290894,
        0.0002540397399570793,
        -0.006561697460711002,
        0.04850425571203232,
        -0.027840575203299522,
        -0.009571283124387264,
        -0.02745853364467621,
        0.04580896347761154,
        0.009931744076311588,
        0.04253016412258148,
        -0.03961366042494774,
        0.06674415618181229,
        0.02944498136639595,
        0.041522156447172165,
        0.019703585654497147,
        0.0013923115329816937,
        -0.005233450327068567,
        -0.014692205004394054,
        0.005196057725697756,
        0.04368191212415695,
        -0.03383445739746094,
        -0.007021451834589243,
        0.023102575913071632,
        -0.006250707898288965,
        -0.042239852249622345,
        -0.019149847328662872,
        -0.037776026874780655,
        -0.02934771217405796,
        -0.007515288423746824,
        0.02553200162947178,
        0.0336831659078598,
        0.03227218985557556,
        -0.038793694227933884,
        -0.006196259055286646,
        -0.033999815583229065,
        0.012173312716186047,
        0.0026491680182516575,
        0.007145623676478863,
        -0.009586765430867672,
        0.0009596836753189564,
        0.028308024629950523,
        0.00588610814884305,
        -0.0043081012554466724,
        0.037915583699941635,
        -0.014700879342854023,
        -0.020232733339071274,
        -0.04911712184548378,
        -0.04456228017807007,
        -0.006429873872548342,
        -0.028792476281523705,
        -0.03542890399694443,
        0.006618778221309185,
        -0.020845290273427963,
        -0.030470697209239006,
        -0.012308647856116295,
        0.03429169952869415,
        0.02394496090710163,
        0.011031378991901875,
        0.014369390904903412,
        0.008453522808849812,
        0.00027932104421779513,
        -0.0004422639904078096,
        -0.004423132631927729,
        0.024781428277492523,
        -0.003009054809808731,
        0.024054307490587234,
        0.011890321038663387,
        -0.007721868343651295,
        -0.02514079585671425,
        0.03007342293858528,
        -0.03555312752723694,
        0.012185933068394661,
        -0.011284212581813335,
        -0.03298354148864746,
        -0.024174585938453674,
        0.03766881301999092,
        -0.0076195355504751205,
        0.02875964157283306,
        0.016382645815610886,
        0.036315567791461945,
        -0.04822640120983124,
        -0.014317883178591728,
        -0.014526743441820145,
        -0.00459060026332736,
        -0.013460865244269371,
        -0.027014508843421936,
        -0.025775175541639328,
        -0.005571204237639904,
        -0.011699755676090717,
        -0.01087564043700695,
        -0.017187610268592834,
        -0.057979732751846313,
        -0.00467345118522644,
        0.0013557749334722757,
        0.03358010947704315,
        0.0280703566968441,
        0.004252305720001459,
        0.008313246071338654,
        -0.0004608980962075293,
        -0.0008595086983405054,
        0.01041735615581274,
        -0.022014254704117775,
        -0.03604945167899132,
        -0.005257629789412022,
        -0.02361595258116722,
        -0.010472245514392853,
        0.013071216642856598,
        0.007189364172518253,
        0.008775741793215275,
        0.005436698440462351,
        -0.047578364610672,
        -0.0633663535118103,
        -0.03177889809012413,
        -0.030227532610297203,
        0.007145915646106005,
        0.0025659517850726843,
        0.04643838480114937,
        0.002709299558773637,
        -0.016793837770819664,
        0.005691327154636383,
        0.026455463841557503,
        -0.00553175201639533,
        -0.023963414132595062,
        0.010531255975365639,
        0.0480605885386467,
        0.007957232184708118,
        0.0036506212782114744,
        -0.007287490181624889,
        -0.032150138169527054,
        -0.04315241426229477,
        0.048521168529987335,
        -0.022982396185398102,
        0.032945092767477036,
        -0.003939965274184942,
        -0.03101246990263462,
        0.028145188465714455,
        -0.011203372851014137,
        0.030733460560441017,
        0.0094516696408391,
        -0.009567332454025745,
        0.009062804281711578,
        0.05485003814101219,
        -0.0016483011422678828,
        -0.05478769913315773,
        -0.04755233973264694,
        0.007491772994399071,
        -0.018066974356770515,
        -0.03779197111725807,
        0.0010490808635950089,
        0.030725419521331787,
        -0.018072864040732384,
        0.028968462720513344,
        0.024882441386580467,
        0.0076081836596131325,
        0.0034714462235569954,
        -0.006075944285839796,
        0.0008839336223900318,
        0.03292721137404442,
        0.029614603146910667,
        0.006182096898555756,
        -0.011197694577276707,
        0.027503101155161858,
        0.014265679754316807,
        0.00965922698378563,
        -0.05131633207201958,
        -0.02639501541852951,
        0.01763257570564747,
        -0.009912291541695595,
        -0.0001498569909017533,
        0.008327579125761986,
        0.007423917297273874,
        0.017862195149064064,
        0.0015432593645527959,
        0.05929083004593849,
        0.03438630700111389,
        -0.005798089783638716,
        0.011315572075545788,
        -0.03942107781767845,
        0.042745187878608704,
        0.0037819843273609877,
        0.019703475758433342,
        -0.014334220439195633,
        0.009662025608122349,
        0.03528827801346779,
        0.010620096698403358,
        0.038729771971702576,
        0.025171924382448196,
        0.024875588715076447,
        -0.014269066974520683,
        0.0494576059281826,
        0.0036222953349351883,
        -0.024278605356812477,
        -0.03294942528009415,
        0.022039400413632393,
        -0.02746349759399891,
        0.01593971997499466,
        0.022991135716438293,
        -0.04578428342938423,
        0.014040562324225903,
        -0.021896937862038612,
        -0.04201234132051468,
        -0.03208602964878082,
        0.015547708608210087,
        -0.03612753003835678,
        0.028826922178268433,
        -0.025990620255470276,
        -0.037188608199357986,
        0.021061835810542107,
        -0.01778050698339939,
        0.044819287955760956,
        0.002356507582589984,
        -0.021546004340052605,
        -0.007273372262716293,
        -0.0035163015127182007,
        0.05096608027815819,
        0.0053774272091686726,
        0.0017410978907719254,
        -0.000686413433868438,
        0.011172253638505936,
        0.013608573004603386,
        -0.023574942722916603,
        0.003967644646763802,
        0.015124141238629818,
        0.013570860028266907,
        -0.0025967659894376993,
        0.008340633474290371,
        -0.060476500540971756,
        -0.018272465094923973,
        0.0018215435557067394,
        -0.03188339248299599,
        0.027711588889360428,
        -0.02293349988758564,
        -0.02082493156194687,
        -0.01989566534757614,
        0.03073028102517128,
        -0.012167795561254025,
        0.01659858599305153,
        -0.024230124428868294,
        0.02079828828573227,
        0.015668708831071854,
        0.009681425988674164,
        0.004335826728492975,
        -0.0026962689589709044,
        0.04122781753540039,
        0.0020301907788962126,
        0.010601654648780823,
        -0.03124115988612175,
        -0.02952282503247261,
        -0.02612038142979145,
        0.01626334711909294,
        0.00417666882276535,
        0.0044278958812355995,
        -0.0008665344212204218,
        -0.011784479953348637,
        0.02421213500201702,
        0.012340263463556767,
        0.019040578976273537,
        -0.029821669682860374,
        -0.004474747460335493,
        -0.003976359963417053,
        -0.008706876076757908,
        0.02320019342005253,
        -0.04985801875591278,
        0.014082103967666626,
        -0.011522600427269936,
        0.0553232803940773,
        0.001398663385771215,
        0.03309888392686844,
        -0.007249683141708374,
        -0.015036873519420624,
        -0.029427235946059227,
        0.01588178426027298,
        0.0228520929813385,
        0.04626097530126572,
        0.02668166533112526,
        -0.005271099042147398,
        -0.0065237549133598804,
        -0.01669827662408352,
        0.005807535722851753,
        -0.01638154499232769,
        0.007177521474659443,
        -0.03681768849492073,
        -0.015017621219158173,
        -0.013765362091362476,
        0.020824335515499115,
        -0.01726202853024006,
        -0.042079709470272064,
        0.00921933725476265,
        0.008444172330200672,
        -0.010204453021287918,
        0.03643957898020744,
        0.010489389300346375,
        -0.029167456552386284,
        0.01254489365965128,
        0.010751907713711262,
        -0.01980426348745823,
        -0.0340580977499485,
        0.007093327585607767,
        0.03863542154431343,
        0.0003633478481788188,
        -0.02543380856513977,
        0.01241261325776577,
        -0.02302399091422558,
        -0.006472126580774784,
        0.015000518411397934,
        0.017179105430841446,
        -0.033723171800374985,
        -0.011932546272873878,
        0.02028193138539791,
        0.009756829589605331,
        0.024261651560664177,
        -0.01124375220388174,
        0.018808983266353607,
        -0.017302783206105232,
        -0.0004973287577740848,
        0.01325534749776125,
        0.006752545479685068,
        0.02125827968120575,
        -0.010566765442490578,
        -0.02562512271106243,
        0.012494963593780994,
        -0.007012289948761463,
        0.018551383167505264,
        -0.01989280804991722,
        -0.006729203276336193,
        -0.009645829908549786,
        -0.017297783866524696,
        -0.022857123985886574,
        -0.018726564943790436,
        -0.01781594380736351,
        0.016939375549554825,
        0.026531554758548737,
        0.011839134618639946,
        0.03864087536931038,
        -0.007376379799097776,
        0.0014027405995875597,
        0.02843485027551651,
        -0.005534388590604067,
        -0.018922002986073494,
        0.01444520615041256,
        -0.005158941727131605,
        -0.01916668564081192,
        0.023312222212553024,
        -0.020631829276680946,
        0.012643493711948395,
        0.017085453495383263,
        0.012684289366006851,
        -0.00911398883908987,
        0.03238918259739876,
        0.004541285801678896,
        -0.0044351136311888695,
        0.015126489102840424,
        0.020641101524233818,
        -0.020788423717021942,
        -0.006232427433133125,
        0.0029390703421086073,
        -0.03573068231344223,
        0.029553543776273727,
        0.021558457985520363,
        0.0155084989964962,
        -0.018165910616517067,
        -0.014335895888507366,
        -0.008810067549347878,
        -0.019234005361795425,
        0.004027224145829678,
        -0.0032282553147524595,
        0.0042984685860574245,
        -0.011586892418563366,
        0.02928050234913826,
        -0.01271874364465475,
        0.0018943656468763947,
        -0.029019730165600777,
        0.026175348088145256,
        0.009727406315505505,
        0.019641796126961708,
        -0.0073060933500528336,
        0.014345730654895306,
        0.00027866801247000694,
        0.01741821877658367,
        -0.04205065593123436,
        -0.016921155154705048,
        -0.009756398387253284,
        -0.02268444560468197,
        -0.04689592868089676,
        0.004300813190639019,
        -0.02533133700489998,
        0.027403708547353745,
        -0.019586946815252304,
        -0.015491721220314503,
        -0.010387417860329151,
        0.010025902651250362,
        -0.01074561569839716,
        0.03045688010752201,
        -0.038120973855257034,
        0.01868060603737831,
        -0.005460603162646294,
        -0.006153847556561232,
        0.004289708565920591,
        0.0005632344400510192,
        0.022709259763360023,
        -0.014255328103899956,
        -0.03189768269658089,
        0.01892351172864437,
        0.0123688830062747,
        0.013422928750514984,
        0.0052765971049666405,
        -0.009638275019824505,
        -0.027026057243347168,
        0.007569015491753817,
        -0.047497060149908066,
        -0.042184460908174515,
        -0.0006345775327645242,
        0.018830273300409317,
        -0.03150199353694916,
        0.007131034974008799,
        0.010838482528924942,
        0.005176587030291557,
        0.023587603121995926,
        0.01737826131284237,
        0.013648436404764652,
        0.003830461762845516,
        -0.002939527155831456,
        -0.043223850429058075,
        -0.021917913109064102,
        0.02026023529469967,
        0.006215117406100035,
        0.019783347845077515,
        -0.012280537746846676,
        0.04083744436502457,
        -0.02592690847814083,
        -0.004375246353447437,
        0.03346048668026924,
        0.027581755071878433,
        0.037413809448480606,
        -0.03483932092785835,
        -0.01160250511020422,
        0.02180849201977253,
        0.005771490279585123,
        -0.014129113405942917,
        -0.03099227510392666,
        -0.01698262058198452,
        -0.02276379056274891,
        -0.0033430145122110844,
        -0.026897398754954338,
        -0.021000778302550316,
        0.009141881950199604,
        -0.02095598727464676,
        -0.03341284394264221,
        0.03909805044531822,
        -0.013332447037100792,
        -0.0019135596230626106,
        0.005899680778384209,
        0.0065479339100420475,
        0.03185959532856941,
        -0.0304083414375782,
        0.022330325096845627,
        -0.012290970422327518,
        0.016970323398709297,
        0.0007429118850268424,
        0.0257175974547863,
        0.005684923380613327,
        -0.02977180853486061,
        0.005747611168771982,
        0.003998189698904753,
        0.0209827721118927,
        -0.05293401703238487,
        0.014228586107492447,
        -0.004833119921386242,
        -0.003909326158463955,
        -0.010219797492027283,
        -0.06426109373569489,
        -0.014012793079018593,
        0.009129364974796772,
        -0.015597213990986347,
        0.004414637107402086,
        0.02343958057463169,
        -0.008148987777531147,
        0.00834999606013298,
        0.027448389679193497,
        0.0517127588391304,
        -0.012076102197170258,
        -0.02093007043004036,
        -0.020298980176448822,
        -0.004508058540523052,
        0.006063414271920919,
        0.005390993319451809,
        0.015869369730353355,
        -0.017967207357287407,
        0.0050938487984240055,
        -0.022540070116519928,
        0.04592745006084442,
        0.024220596998929977,
        -0.016903525218367577,
        0.010614938102662563,
        -0.03474823758006096,
        -0.0009145468939095736,
        -0.004312239587306976,
        -0.02567925676703453,
        0.031817033886909485,
        -0.003337196307256818,
        0.012297568842768669,
        -0.0073993271216750145,
        -0.0071971723809838295,
        0.018244901672005653,
        0.030913854017853737,
        0.0025107809342443943,
        -0.025232607498764992,
        -0.009532323107123375,
        0.005677920766174793,
        0.0006594170117750764,
        -0.00651908153668046,
        0.013190429657697678,
        0.010514369234442711,
        0.007385469041764736,
        0.022443188354372978,
        -0.009459041059017181,
        0.006557822693139315,
        0.013928478583693504,
        -0.02136586420238018,
        -0.024567589163780212,
        0.01233766134828329,
        0.013782515190541744,
        -0.013293442316353321,
        -0.0036499048583209515,
        0.01446247287094593,
        -0.012064091861248016,
        0.053206752985715866,
        -0.0027880785055458546,
        -0.0022406710777431726,
        0.03310408070683479,
        -0.019067253917455673,
        0.006684364750981331,
        0.016146600246429443,
        0.011285883374512196,
        0.0015709275612607598,
        0.019761187955737114,
        0.009106547571718693,
        0.008174673654139042,
        0.02394014224410057,
        -0.03438998758792877,
        -0.009989507496356964,
        -0.004768727347254753,
        -0.012538903392851353,
        0.027160609140992165,
        0.0029627771582454443,
        0.02066636085510254,
        -0.03185896575450897,
        -0.030098015442490578,
        -0.0472080260515213,
        0.01130683720111847,
        0.016053901985287666,
        0.03315168246626854,
        -0.017661385238170624,
        -0.011473683640360832,
        0.010713502764701843,
        0.0030598437879234552,
        -0.007716385647654533,
        0.04142118990421295,
        0.03898122161626816,
        0.010429777204990387,
        0.0228117648512125,
        -0.009353340603411198,
        -0.022961994633078575,
        0.022260475903749466,
        -0.011253830045461655,
        -0.02389177866280079,
        -0.040665339678525925,
        -0.007642047479748726,
        0.012256931513547897,
        -0.0010091677540913224,
        0.033879347145557404
      ],
      "title": "Copyright and Artificial Intelligence Part 3: Generative AI Training, Pre-Publication Version"
    },
    {
      "id": "gai-esp_corpus-item001",
      "count": 7,
      "created": "2025-07-06T05:33:11.560327",
      "text": "Propuesta de Agenda Nacional de la Inteligencia Artificial para México 2024-2030 Glosario En la era digital los términos y sus definiciones evolucionan rápidamente, y es común que un término tenga varias definiciones. Para este documento se tomaron en cuenta definiciones de Organismos Internacionales de los cuales México forma parte y participó en su redacción y adopción, artículos académicos, así como, documentos normativos de distintos órdenes de gobierno. Capacitación cruzada - Es un proceso de capacitación de empleados para que realicen múltiples trabajos en una organización. En la capacitación cruzada los empleados aprenden a realizar diferentes trabajos dentro de la organización, además del suyo. (Pancardo Pérez et al., 2011) Ciudadanía digital - Refiere al conjunto de derechos y responsabilidades que las personas tenemos en el entorno digital. (Argentina, n.d.) Complementariedad - El proceso de aprender nuevas habilidades o de enseñar nuevas habilidades a los trabajadores (Cambridge University, 2024) Reconversión - El proceso de aprender nuevas habilidades para poder hacer un trabajo diferente, o de capacitar a personas para hacer un trabajo diferente. (Cambridge University, 2024) Conexión significativa - Se refiere al acceso a banda ancha a velocidades que permitan el uso intensivo de datos en actividades simultáneas (clases en línea, teletrabajo, etc.), dispositivos de acceso adecuados para usos relevantes y habilidades digitales básicas. (Rojas, 2024) Energía limpia - Energía generada de fuentes renovables (Nance, 2018, 104) Energía renovable - Son un tipo de energías derivadas de fuentes naturales que llegan a reponerse más rápido de lo que pueden consumirse. (ONU, n.d.) Energía eficiente - Se refiere a la producción o el consumo de energía que es eficiente en términos de reducción del desperdicio y mejora del uso de la misma. El concepto se asocia a menudo con la eficiencia energética, que es la práctica de utilizar menos energía para realizar la misma función o tarea. (Universidad de Sao Paulo, 2015) Derechos ambientales - Derecho de todo ser humano a que se le respete, proteja, promueva y garantice un medio ambiente libre de contaminación, que fomente su sano desarrollo y bienestar, así como la preservación y restauración del equilibrio ecológico (UNAM, n.d.) Derechos humanos - Derechos inherentes a todos los seres humanos, sin distinción alguna de raza, sexo, nacionalidad, origen étnico, lengua, religión o cualquier otra condición (ONU, n.d.). Además de los derechos humanos relacionados con el sistema nervioso central y periférico, así como con la actividad mental de las personas y la información que de estos se derive. Discriminación algorítmica - Se refiere al fenómeno en el cual los algoritmos de inteligencia artificial y aprendizaje automático perpetúan o incluso amplifican los prejuicios y sesgos humanos existentes en los datos con los que son entrenados. (Dialnet, n.d.) Habilidades blandas o socioemocionales - Habilidades que las personas utilizan para comunicarse, resolver problemas, liderar, empatizar y pensar de forma creativa. (UNESCO, n.d.) Habilidades digitales - Son la suma de conocimientos, capacidades, destrezas, actitudes y estrategias que se requieren para el uso de las tecnologías e Internet. (UNESCO, 2021) Identidad digital - Representación digital de la información conocida acerca de una persona, un grupo o una organización concreta. (ITU, n.d.) Infraestructura Pública Digital (DPI, por sus siglas en inglés) - Es un conjunto de sistemas digitales compartidos, seguros e interoperables, basados en tecnologías abiertas, para ofrecer un acceso equitativo a los servicios públicos o privados a escala social. (WEF, 2024) Inteligencia Artificial (IA) - Para fines de este documento, se retoma el texto de la OECD \"Recommendation of the Council on Artificial Intelligence\", por el que se conceptualiza a las tecnologías basadas en IA como un sistema basado en máquinas que, con objetivos explícitos o implícitos, infiere, a partir de la entrada que recibe, cómo generar salidas tales como predicciones, contenidos, recomendaciones o decisiones que pueden influir en entornos físicos o virtuales. Los distintos sistemas de IA varían en sus niveles de autonomía y capacidad de adaptación tras su despliegue. (OECD, 2023) Interdisciplinario - Se refiere al trabajo de cooperación e integración entre dos o más disciplinas y su enfoque es la obtención de síntesis que traspasen los límites de las disciplinas participantes. (UCL, n.d.) Modelos de lenguaje - Representación matemática compleja del lenguaje que se basa en cantidades muy grandes de datos y permite a los ordenadores producir un lenguaje que parece similar al que podría decir un ser humano. (Cambridge Dictionary, n.d.) Multiactor - Es una modalidad de cooperación internacional, en la cual se complementan los esfuerzos y competencias del sector público, con el sector empresarial y/o la sociedad civil y/o la academia, buscando resultados en la implementación de iniciativas que tengan por propósito mejorar las condiciones de vida de las personas y la comunidad, en el marco de las agendas de desarrollo. (agcidChile, n.d.) Multisectorial - Que afecta a varios sectores, especialmente en el ámbito de la economía. (RAE, 2023) Nearshoring - Se refiere a la externalización de trabajo a un país adyacente con un nivel equivalente de desarrollo económico; por ejemplo, cuando se transfieren puestos de trabajo de centros de atención telefónica de EE.UU. a Canadá. Como tal, puede contrastarse con la deslocalización, la subcontratación de trabajo a un país lejano con un nivel inferior de desarrollo económico. (Oxford Reference, n.d.) Neutralidad tecnológica - Fomentar de manera proactiva la libertad de elección de todos los usuarios y consumidores, sean públicos o privados, de la alternativa tecnológica que mejor convenga a sus necesidades y circunstancias. (IFT, 2019) Nube - La computación en nube es un modelo que permite el acceso ubicuo, cómodo y bajo demanda a un conjunto compartido de recursos informáticos configurables (por ejemplo, redes, servidores, almacenamiento, aplicaciones y servicios) que pueden ser rápidamente aprovisionados y liberados con un mínimo esfuerzo de gestión o interacción con el proveedor de servicios. Este modelo de nube se compone de cinco características esenciales, tres modelos de servicio y cuatro modelos de despliegue. (Mell, n.d.) Población Económicamente Activa (PEA) - Todas las personas en edad de trabajar, o que contaban con una ocupación durante el período de referencia o no contaban con una pero estaban buscando emplearse con acciones específicas. (INEGI, 2002) Powershoring - Se refiere a la descentralización de la producción hacia países que ofrecen energía limpia, segura, barata y abundante y cercanos a los grandes centros de consumo, además de otras virtudes para atraer inversiones industriales. (Arbache, 2022) Sandbox regulatorio - Un enfoque regulatorio típicamente resumido por escrito y publicado que permite experimentar de manera dinámica modelos de innovaciones con plazos detextinados bajo la supervisión de los reguladores. (UNSGSA, 2024) Seguridad ciudadana - Es el proceso de establecer, fortalecer y proteger el orden civil democrático, eliminando las amenazas de violencia en la población y permitiendo una coexistencia segura y pacífica. (UNDP, 2014) Seguridad nacional - La condición indispensable para garantizar la integridad y la soberanía nacional; libre de amenazas al Estado, en busca de construir una paz duradera y fructífera. (Gobierno de México, 2020) Seguridad pública - Conforme a los preceptos legales en México, es la función compartida entre la Federación, los estados y los municipios, cuyo propósito es asegurar la protección de los bienes y derechos de las personas, así como promover condiciones propicias para la convivencia pacífica y el desarrollo tanto individual como colectivo de la sociedad. Esta función implica la prevención, persecución y sanción de las infracciones y delitos, así como la reintegración social de los infractores. (Cámara de Diputados de México, 2009) (Centro de Estudios Sociales y de Opinión Pública, 2006) Soberanía tecnológica - La capacidad de un estado o una federación de estados para proporcionar las tecnologías que considere críticas para su bienestar, competitividad y capacidad de acción, y para poder desarrollarlas o adquirirlas de otras áreas económicas sin depender unilateralmente de una estructura. (Edler et al., 2020) Código abierto - Software desarrollado y mantenido mediante una colaboración abierta, y disponible (generalmente sin costo alguno) para que cualquiera lo use, examine, altere y redistribuya como quiera. (Raymond, n.d.) Código certificado - Se refiere a aquel que ha sido firmado digitalmente utilizando un certificado de firma de código. (Gitlan, 2024) Sostenibilidad - Lo que permite satisfacer las necesidades del presente sin comprometer la habilidad de las futuras generaciones de satisfacer sus necesidades propias. (ONU, n.d.) Transdisciplinario - Es un término utilizado en la literatura académica para describir un enfoque de investigación que integra conocimientos de diferentes disciplinas e implica la colaboración entre investigadores de diversos campos para abordar problemas complejos e interdisciplinarios. Este enfoque se caracteriza por su fluidez y naturaleza contextual, ya que implica cambios de perspectivas y metodologías para satisfacer las necesidades de la pregunta de investigación y las partes interesadas involucradas. La transdisciplinariedad se distingue de la interdisciplinariedad en que va más allá de la integración del conocimiento de diferentes disciplinas y apunta a crear algo completamente nuevo, a menudo desafiando ideologías disciplinarias y adoptando una perspectiva holística. (Hendricks, 2018) Educación dual - Es una modalidad de enseñanza y de aprendizaje que se realiza en dos lugares distintos; la institución educativa y la empresa, que se complementan mediante actividades coordinadas. (Araya Muñoz, 2008, 46) Educación continua - Una concepción de la educación, como un proceso permanente a lo largo de la vida, que involucra a la persona de manera integral y que se relaciona con cualquier tipo de actividad productiva en el ser humano. (Andrade Paco et al., 2009, 59) RESUMEN EJECUTIVO Este documento es un esfuerzo colaborativo de expertos del sector público y privado, academia, sociedad civil organizada, organismos internacionales y autónomos, y público en general, coordinado por la Alianza Nacional de Inteligencia Artificial (ANIA) en beneficio de toda la población mexicana. Las recomendaciones aquí emitidas reflejan un compromiso sólido y multifacético para orientar el desarrollo y uso - de forma ética y responsable - de la inteligencia artificial en México hacia un futuro sostenible e inclusivo. Las recomendaciones se integran bajo un marco de referencia con políticas públicas, regulaciones específicas y estrategias de gobernanza que subrayan un enfoque colaborativo y multiactor que involucre a todos los sectores de la sociedad. Capítulo 1: Describe el marco contextual e identifica un marco de políticas públicas en relación a una Estrategia de Inteligencia Artificial para el país, con un enfoque multisectorial. Destaca la importancia de la Inteligencia Artificial para el futuro de México y subraya la necesidad de acciones estratégicas para aprovechar su potencial y al mismo tiempo mitigar riesgos. Capítulo 2: Establece un marco de referencia para la elaboración de recomendaciones de política pública, regulación y gobernanza, en aras de garantizar y proteger los derechos humanos y ambientales con un enfoque transdisciplinario. Capítulo 3: Se detallan las recomendaciones que surgen de las discusiones y reflexiones sostenidas durante las sesiones de grupos de trabajo multidisciplinarios entre septiembre y diciembre de 2023. Estas discusiones se centraron en las mejores prácticas en política pública digital aplicables al contexto mexicano, así como los marcos de recomendaciones de organismos internacionales y se dividen en las siguientes temáticas: i) Políticas Públicas y Derechos; ii) Educación y Mercados Laborales; iii) Ciberseguridad y Gestión de Riesgos, iv) Género, Inclusión y Responsabilidad Social; v) Infraestructura y Datos; e vi) Innovación, Investigación e Industria. Capítulo 4: Se refiere a las recomendaciones en materia regulatoria para la Inteligencia Artificial en México. Las recomendaciones de regulación tomaron como punto de partida un análisis interdisciplinario de las políticas existentes, las propuestas legislativas en curso y las consideraciones éticas y jurídicas que están dando forma al futuro de esta tecnología en el país. Como la protección de la privacidad, la equidad en el acceso y uso de las tecnologías basadas en IA, la transparencia algorítmica y la responsabilidad en su implementación, la gobernanza y el valor de los datos. Capítulo 5: Aborda las recomendaciones relacionadas a la gobernanza efectiva y democrática de la Inteligencia Artificial en el país, siendo esta indispensable para asegurar el uso ético, responsable, transparente y beneficioso para la sociedad. Las recomendaciones de gobernanza identificadas en este documento buscan mecanismos institucionales, políticas y estrategias que el país está implementando para supervisar y regular el desarrollo, uso y aplicación de esta tecnología. Considera la creación de comités multiactor, multisectoriales, interdisciplinarios y transdisciplinarios, así como, la colaboración con el sector privado, la academia y la sociedad civil. En este documento se recogen análisis y propuestas del reporte del estado de preparación de México en inteligencia artificial, *Readiness Assessment Methodology* (RAM por sus siglas en inglés), realizado por la Organización de las Naciones Unidas para la Educación, la Ciencia y la Cultura (UNESCO), para el cual uno de los insumos relevantes fueron las mesas de trabajo organizadas bajo el marco de colaboración con la ANIA. Esta metodología apoya a sus Estados Miembro a implementar la Recomendación sobre Ética de la Inteligencia Artificial (IA) al identificar brechas institucionales y regulatorias, permitiendo adaptar el apoyo para garantizar un ecosistema ético de IA y complementando la Evaluación de Impacto Ético a nivel micro. Finalmente el documento concluye con la necesidad de contar con una visión integral del país en materia digital. Señala que para poder implementar las recomendaciones vertidas en este documento, es imperante contar con la continua participación de todos los actores del ecosistema digital del país, tener una estrecha coordinación institucional de los distintos órganos de gobierno y la adecuación de estructuras que permitan materializar estas recomendaciones. MARCO CONTEXTUAL El dinamismo en el campo de la ciencia de la Inteligencia Artificial durante los últimos años ha marcado un antes y un después en la conversación global sobre tecnología y su impacto en la sociedad. En 2022, la Fundéu RAE destacó su relevancia al elegir \"Inteligencia Artificial\" como las palabras del año, un indicativo del creciente interés por esta tecnología emergente. Este interés no ha hecho más que intensificarse en 2023, año en el que la IA fue el foco de importantes debates y eventos a nivel mundial, incluyendo el \"Proceso de IA de Hiroshima\" (ANIA, 2023), la \"Declaración de Bletchley\" (ANIA, 2023), el \"Decreto de Joe Biden sobre Inteligencia Artificial Segura y Confiable\" (La Revolución De La Inteligencia Artificial: El Decreto De Joe Biden, 2023), el \"AI Act\" de la Unión Europea (AI Act | Shaping Europe's Digital Future, 2024), la \"Declaración de Santiago\" (Ministerio de Ciencia Tecnología, Conocimiento e Innovación de Chile, 2023), el \"Global Partnership on Artificial Intelligence Summit 2023\" en Nueva Delhi (Global Partnership on Artificial Intelligence, 2023), la \"Reunión Anual del Foro Económico Mundial en Davos\" (WEF, n.d.), y el \"Summit de IA\" para el Bien Común de la Unión Internacional de Telecomunicaciones (ITU). Estos eventos destacan la importancia central de la IA en las agendas globales, tanto que el New York Times designó al año 2023 como \"el año de la Inteligencia Artificial\" (Nieto, 2023). Esto es indicativo de una tendencia que promete mantenerse y expandirse aún más en los años siguientes. La importancia de la IA y sus aplicaciones se refleja también en sus proyecciones económicas. De acuerdo con el Dr. Ryan Abbot, se espera que para 2030, la tecnología basada en la IA contribuya con hasta 15.7 billones de dólares a la economía global (Inteligencia Artificial: ¿Una Amenaza Para El Empleo En México?, 2023), una cifra que supera la producción actual combinada de China e India, resaltando el inmenso potencial de esta tecnología para transformar las economías a nivel mundial. Resulta relevante destacar que la IA no eliminará empleos *per se*; más bien, los transformará y podrá traer beneficios a aquellas personas que puedan acceder a esta y otras tecnologías emergentes. De acuerdo con un análisis del Foro Económico Mundial (WEF, por sus siglas en inglés), se estima que para el año 2025, 85 millones de empleos podrían ser reemplazados por la automatización pero se crearán 97 millones de nuevas oportunidades laborales. (WEF, 2020) Según el informe de Goldman Sachs (2023), la Inteligencia Artificial y la automatización tienen el potencial de impactar 300 millones de trabajos a nivel global. Se estima que 18% de las tareas laborales podrían ser automatizadas a través de la IA, observándose un mayor impacto en los mercados desarrollados en comparación con los mercados emergentes. En la Unión Europea, este porcentaje se incrementará 24%, mientras que en Estados Unidos llegará a 25% (BriggsKodnani, 2023). A nivel regional, la adopción de tecnologías de Inteligencia Artificial está ganando impulso en América Latina y el Caribe (ALC), donde los gobiernos, las empresas, la academia y la sociedad civil están reconociendo cada vez más su potencial para impulsar el crecimiento económico, educativo y social con la finalidad de mejorar la calidad de vida de las personas, especialmente aquellas más vulnerables (como mujeres, adultos mayores, comunidades indígenas, personas con discapacidad, niños, niñas y adolescentes). Un estudio del Programa de las Naciones Unidas para el Desarrollo (PNUD) sugiere que, para 2030, la IA podría contribuir al Producto Interno Bruto (PIB) de la región en hasta 5.4% (Opp, 2024). A través de proyectos innovadores en sectores como la salud digital, la educación adaptativa y la agricultura inteligente. La tecnología basada en la IA se está posicionando como un catalizador de cambio y progreso en la región. Se anticipa que la tecnología basada en la IA se convierta en un pilar fundamental para el desarrollo económico, la innovación, la competitividad, la sociedad y la reducción de desigualdades a nivel global. El avance de esta disciplina y su debida adopción en México representa una oportunidad significativa para impulsar la economía nacional y optimizar las cadenas de suministro, colocando al país en una posición favorable en el panorama tecnológico internacional. En México, la IA está emergiendo como una prioridad en diversas agendas (sector público, sector privado, académico, organismos autónomos y sociedad civil organizada), con un creciente reconocimiento de su importancia para la competitividad y la productividad. En el Índice Latinoamericano de Inteligencia Artificial 2023 (ILIA), México obtuvo un puntaje de 48.55, posicionando al país como el quinto de la región, por debajo de Chile, Brasil, Uruguay y Argentina. México presenta una infraestructura tecnológica en línea con el promedio latinoamericano, resaltando avances en tecnología 5G pero enfrentando desafíos en el acceso y uso de internet. En términos de datos, el país supera la media regional, brindando oportunidades para fortalecer la investigación y desarrollo. (CEPAL, 2023) En el ámbito del talento, México se destaca en alfabetización en IA; sin embargo, esto ha tenido un mayor impacto al centro del país (CDMX y EDOMEX) - lo cual representa una brecha geográfica de habilidades tecnológicas de todo tipo- licenciados en computación y habilidades disruptivas (CEPAL, 2023). Aunque la comunidad de investigación es madura, se acerca al promedio de impacto de la IA en Latinoamérica. En Investigación y Desarrollo, México sobresale en patentes pero enfrenta deficiencias en productividad, calidad de código abierto y adopción empresarial de la IA. Mientras que en gobernanza, el país está por debajo del promedio, careciendo de una estrategia actualizada a pesar de participar en estándares internacionales y contar con regulaciones de protección de datos. (CEPAL, 2023) Por otro lado, Oxford Insights publica anualmente el Índice de Preparación de la IA del Gobierno, evaluando el desempeño de 193 países. México tuvo un crecimiento inicial en 2021 pero su puntuación ha disminuido desde entonces debido a la falta de continuidad de la política pública en materia digital, pasando de 52.62 a 50.37 en 2023. De 2021 a 2023 México perdió 13 lugares, ubicándose en el puesto 68 (Oxford Insights, 2023). Aunque mostró cierto avance en la integración de la IA en servicios públicos, este progreso se ha estancado (Anexo 1.9) La adopción de las tecnologías basadas en la IA muestra una tendencia al alza. El \"Global AI Adoption Index 2022\" señala que 31% de las empresas en México han implementado activamente la IA (IBM Global AI Adoption Index 2022, 2022). Además, una encuesta realizada por la Asociación de Internet y Knowsy AI indica que 55% de los usuarios de internet en México perciben la IA como una herramienta útil, mientras que 22% expresa preocupaciones sobre sus posibles impactos negativos (El Economista, 2023). Estas cifras reflejan una dualidad presente tanto en México como a nivel global: un entusiasmo por la innovación y el desarrollo tecnológico, junto con una cautela hacia los riesgos éticos, económicos, sociales, de dependencia tecnológica y de ciberseguridad que estos avances podrían conllevar. La ubicación estratégica de México, podría convertirlo en un destino clave para empresas que buscan trasladar parte de su producción, así como se ve reflejado en la estrategia de *nearshoring*, pero necesita contar con la infraestructura digital (tecnología de almacenamiento y procesamiento de datos) capacidades y habilidades adecuadas para su desarrollo. En este contexto, maximizar los beneficios requiere establecer una visión nacional compartida y desarrollar estrategias específicas que transformen esa visión en acciones concretas mediante políticas públicas, nuevas leyes o actualización de varias y una gobernanza que involucre a múltiples actores. El presente documento provee recomendaciones con el objetivo de facilitar y estructurar una Agenda de Inteligencia Artificial que permita a México potenciar la innovación, desarrollo y uso de las tecnologías basadas en IA para el bien común, salvaguardando los derechos de las personas y del medio ambiente. Propone aportar a la administración (2024-2030) una visión general y actualizada de la IA, esperando que esta pueda ser considerada en el Plan Nacional de Desarrollo y la Estrategia Digital Nacional para hacer frente a la revolución tecnológica que está dando forma al siglo XXI. OBJETIVO DEL DOCUMENTO Establecer un marco de referencia que promueva la integración de la Inteligencia Artificial como un motor de la inclusión y el desarrollo social, económico y educativo del país, la investigación científica, el desarrollo tecnológico, la innovación y emprendimiento ético, responsable y equitativo. Nuestro enfoque se centra en la elaboración de recomendaciones de política pública, regulación y gobernanza, en aras de garantizar y proteger los derechos humanos y ambientales. Esto se logrará mediante una adecuada gestión de los riesgos asociados con los casos de uso de las tecnologías basadas en IA, aplicando principios de ética y responsabilidad social que promuevan la transparencia y la rendición de cuentas en todas las etapas del desarrollo de estas tecnologías, desde su diseño, hasta su despliegue y uso en el país. En ese sentido y para cumplir con el objetivo macro, el 23 abril del año pasado se lanzó desde el Senado de la República, la Alianza Nacional de Inteligencia Artificial (ANIA), un mecanismo multiactor que reconoce y fortalece el ecosistema de tecnologías emergentes e inteligencia artificial en México desde una perspectiva integral, plural y multidisciplinaria; a través de estas acciones específicas: 1. Generación de un diagnóstico y propuestas de regulación, política pública y modelo de gobernanza. Para lograr este objetivo se realizaron tres sesiones de seis diferentes mesas de trabajo: a. Políticas Públicas y Derechos b. Educación y Mercados Laborales c. Ciberseguridad y Gestión de Riesgos d .Género, Inclusión y Responsabilidad Social e.Infraestructura y Datos f. Innovación e Industria 2. Concientización y capacitación en IA 3. Documentación casos de uso de IA en México 4. Colaboración internacional La Alianza Nacional de Inteligencia Artificial está poniendo en marcha un nuevo modelo de gobernanza, integrando líderes tecnológicos, iniciativa privada, la academia, sociedad civil, organismos internacionales, autónomos, gobierno, legisladores y reguladores nacionales e internacionales, para identificar una visión de país bajo un marco de referencia como se indica en la siguiente figura - \"Marco de referencia de la IA para el bien común\". Este documento es un esfuerzo colaborativo de expertos del sector público y privado, academia, sociedad civil organizada, organismos internacionales, y público en general, coordinado por la Alianza Nacional de Inteligencia Artificial, en colaboración con la UNESCO, en beneficio de toda la población mexicana. RECOMENDACIONES DE POLÍTICA PÚBLICA Las recomendaciones que se desarrollan a continuación surgen de las reflexiones compartidas durante las diferentes sesiones de las mesas de trabajo coordinadas por la ANIA, en acompañamiento de la UNESCO. Estos diálogos y reflexiones, se centraron en las mejores prácticas en materia de política digital aplicables al contexto mexicano; así como los marcos de recomendaciones de organismos internacionales de los cuales México forma parte, tales como la \"Recomendación sobre la Ética de la Inteligencia Artificial de la Organización de las Naciones Unidas para la Educación, la Ciencia y la Cultura (UNESCO); y los Principios de la Organización para la Cooperación y el Desarrollo Económicos (OCDE). POLÍTICA PÚBLICA Y DERECHOS Objetivo 3.1.1: Incorporar acciones de política pública en Inteligencia Artificial como parte del Plan Nacional de Desarrollo (PND), la Estrategia Digital Nacional (EDN), y el Plan de Cumplimiento de las Metas de Desarrollo Sostenible 2030, definiendo una hoja de ruta por acción, instancias responsables e indicadores de ejecución. Acciones: Desarrollar una metodología para el mapeo del ecosistema de la IA en México; Integrar en la Política Nacional de Inclusión Digital/Agenda Digital Nacional de acuerdo al mandato del Art. 6 Constitucional, acciones específicas para el desarrollo, uso y aprovechamiento de las tecnologías emergentes, entre ellas la Inteligencia Artificial, promoviendo el ejercicio pleno de los derechos humanos, y protección del medio ambiente, como parte estructural de la agenda; Definir el conjunto de acciones de la Política Nacional mediante un proceso abierto y colaborativo, involucrando a todos los participantes del ecosistema digital de México. Esto incluye a la academia, el sector privado, la sociedad civil, entidades gubernamentales de todos los niveles, organismos internacionales y el público en general, asegurando una representación integral de todos los sectores involucrados; Establecer acciones concretas, definidas en una o más agendas específicas en materia digital, dentro del marco del Plan Nacional de Desarrollo 2024-2030; así como, en la Agenda de México para cumplir con las Metas de los Objetivos de Desarrollo Sostenible al 2030. Cada acción planteada deberá estar acompañada de una hoja de ruta clara, especificando la entidad encargada de llevarla a cabo, la inversión necesaria y las posibles fuentes de financiamiento, sean públicas (mediante partidas presupuestarias, fondos, etc.) y/o privadas; Garantizar que las acciones - como mínimo - promuevan el desarrollo y el acceso a Infraestructura Pública Digital (DPI por sus siglas en Inglés) como son sistemas para el intercambio de información, los servicios financieros digitales; así como, el acceso a datos abiertos en formatos que sean legibles por máquinas. El desarrollo de la DPI se estructurará siguiendo estándares, especificaciones técnicas y marcos de referencia internacional como GovStack Global de la Unión Internacional de Telecomunicaciones (ITU), garantizando la privacidad, seguridad e inclusión desde su diseño; Poner en marcha un sistema de identidad digital; • Construir una infraestructura nacional de datos con un modelo de gobernanza democrático en el que se definan los tipos de datos, un marco regulatorio que brinde certeza durante todo el ciclo de vida, los actores y responsables involucrados de su generación, acceso, tratamiento, así como, las posibles sanciones en caso de mal uso. Este modelo de gobernanza deberá vincularse con políticas de transparencia y acceso a la información pública, privacidad y protección de datos personales, datos abiertos, entre otros que se crean necesarios; Habilitar un tablero público para el seguimiento del progreso de las acciones de la(s) agenda(s), con datos de indicadores de cumplimiento en formato abierto y visualizaciones que faciliten el análisis de información. Dicho tablero puede incluir indicadores específicos que midan el impacto de la Inteligencia Artificial en México. EDUCACIÓN Y MERCADOS LABORALES Objetivo 3.2.1: Propiciar la integración de habilidades y conocimientos de tecnologías basadas en Inteligencia Artificial en el diseño curricular de educación básica, media superior y superior. Acciones: Establecer un ecosistema que contemple los elementos clave que permita la integración de las tecnologías basadas en la IA dentro de los entornos educativos (infraestructura, desarrollo profesional docente, oferta de recursos educativos digitales; así como, mecanismos de monitoreo y evaluación); Garantizar la infraestructura necesaria (como conectividad y dispositivos tecnológicos) que permita integrar herramientas de las tecnologías basadas en la IA en las instituciones educativas, especialmente en áreas rurales y marginadas; Capacitar a docentes y demás autoridades educativas de todos los niveles en el conocimiento e integración responsable de las tecnologías basadas en la IA dentro de los entornos educativos, preparándolos en el entendimiento y transmisión de estas competencias a la población estudiantil. Este esfuerzo asegurará la formación de nuevas generaciones de profesionales altamente capacitados para adquisición, profundización y creación de las tecnologías basadas en IA, fortaleciendo así el liderazgo del país en este campo tecnológico emergente; Desarrollar e implementar un diseño curricular, en cada uno de los niveles educativos, que considere el entendimiento, uso y desarrollo de las tecnologías basadas en IA desde su aplicación en contextos cotidianos hasta la programación en lenguajes actualizados y relevantes alineados con el progreso tecnológico y digital, y el análisis de datos; así como el fomento del pensamiento computacional, que abarca la resolución de problemas mediante la descomposición, el reconocimiento de patrones, la abstracción y el uso de algoritmos Asegurar que los planes y programas de estudio en todos los niveles educativos incluyan el desarrollo de habilidades blandas o socioemocionales. Lo anterior con el fin de generar perfiles profesionales que no solo complementan el entendimiento, uso y desarrollo de las tecnologías basadas en IA, sino que también se alineen a la demanda de la sociedad y del mercado laboral actual y futuro; Generar políticas públicas que fomenten la ciudadanía digital a través de campañas de concientización y capacitación; Incorporar mecanismos de monitoreo y evaluación para medir el impacto de la IA en la educación, alineando las políticas y estrategias a los estándares internacionales de evaluación de tecnologías educativas, como los establecidos por la UNESCO, la ITU y la OCDE; Facilitar la colaboración internacional para compartir mejores prácticas y lecciones aprendidas en la implementación de la IA en diferentes contextos educativos, a través de plataformas de intercambio de conocimientos y la participación en foros globales. Objetivo 3.2.2: Impulsar programas de formación, actualización y certificación profesional (micro-credenciales), de acuerdo a la demanda laboral generada por las tecnologías basadas en IA, garantizando siempre los derechos laborales. Acciones: Fomentar la educación y capacitación continua a través de recursos educativos y talleres de todos los niveles; Fortalecer los programas de formación, actualización y certificación profesional (micro-credenciales) dirigidos a la Población Económicamente Activa (PEA). Estos programas deberán desarrollar y fomentar las habilidades y competencias que permitan a las personas mantener sus empleos actuales, facilitar la transición o adquisición de nuevas capacidades de acuerdo a la demanda del mercado laboral. Las ofertas de formación deberán incluir un enfoque de uso ético y responsable, y de protección de los derechos humanos; • Implementar programa integrales de formación y capacitación en tecnologías basadas en IA dirigido a funcionarios públicos; Fomentar una cultura organizacional que promueva el desarrollo e integración de la IA como una herramienta fundamental para la Transformación Digital de la Administración Pública, considerando aspectos clave como la gestión del cambio. Esto permitirá al personal que integra las dependencias públicas comprender los beneficios y riesgos asociados con esta tecnología, identificar los campos de aplicación que generen valor y adquirir los conocimientos técnicos necesarios para su adecuada implementación; Implementar un modelo de educación dual que permita a los estudiantes incorporarse al mercado laboral mientras continúan sus estudios a través de métodos híbridos y flexibles, que combinan la enseñanza presencial con la modalidad en línea; Implementar políticas de complementariedad, reconversión y capacitación cruzada en el mercado laboral que genere las habilidades necesarias para adaptarse a los cambios generados por tecnologías emergentes. Objetivo 3.2.3: Incrementar la inversión en investigación y desarrollo de tecnologías emergentes para impulsar el desarrollo de México. Acciones: Promover el fortalecimiento del ecosistema de la Inteligencia Artificial en México y mitigar la fuga de talento mediante la implementación de políticas que fomenten la creación de oportunidades laborales para ciudadanos mexicanos en áreas de investigación en IA y roles especializados, en colaboración entre instituciones educativas, iniciativa privada y organismos internacionales; Crear un fondo de inversión pública y privada para investigación y desarrollo científico y tecnológico de sistemas de IA y tecnologías emergentes; Promover la creación de centros de excelencia y clústeres tecnológicos especializados en las tecnologías basadas en IA para fomentar la innovación y el desarrollo tecnológico de sectores prioritarios para el país. CIBERSEGURIDAD Y GESTIÓN DE RIESGOS Objetivo 3.3.1: Promover la ciberseguridad en el país mediante la implementación de principios para el desarrollo tecnológico, la gestión de riesgos y la investigación, así como, protocolos efectivos de intercambio de información sobre ciberataques entre sectores. Nota: Estas acciones deberán verse reflejadas en la Ley de Ciberseguridad que se describe en la sección de recomendaciones de regulación. Acciones: Establecer principios de desarrollo, adquisición e implementación de software y tecnologías emergentes que integren: a) elementos de interacción, control y supervisión humana; b) protocolos de gestión de riesgos, monitoreo de incidentes, y autenticación de información; y c) políticas de privacidad, protección de datos, transparencia, rendición de cuentas y explicabilidad; Incrementar la inversión en investigación y desarrollo de ciberseguridad y la aplicabilidad de algoritmos de aprendizaje automático para complementar modelos de análisis de eventos pasados (prescriptivos y de diagnóstico) y futuros (predictivos y descriptivos) en la gestión de riesgos cibernéticos; Impulsar la innovación en la gestión de la ciberseguridad y riesgos cibernéticos a través del uso de espacios controlados de pruebas - \"sandboxes\" - involucrando equipos expertos multidisciplinarios y multisectoriales. Éstos equipos definirán, y evaluarán diferentes criterios de medición de impacto del uso de sistemas de IA que se aplicarán durante los procesos de contratación, desarrollo y uso en el sector público y privado; Actualizar continuamente los protocolos para compartir información sobre ciberataques entre organizaciones del sector público, la academia, empresas/PyMES, instituciones educativas y sociedad civil organizada para: a) compartir lecciones aprendidas y estrategias de mejora para prevención y corrección de los sistemas de respuesta a incidentes cibernéticos; y b) Fortalecer los protocolos de actuación policial ante ciberataques, ataques ofensivos o técnicas de desanonimización; Articular campañas de concientización continua sobre los beneficios y riesgos de las tecnologías basadas en IA. Éstas deben facilitar y promover la adopción de estándares, gestión de riesgos, y certificaciones de ciberseguridad, principalmente en las pequeñas y medianas empresas (PyMES); Crear un grupo multiactor que se encargue de analizar y anticipar problemas sobre el desarrollo y uso de las tecnologías emergentes, así como, su impacto ético, legal, médico, social, cultural, económico, político, de seguridad pública y ciudadana. GÉNERO, INCLUSIÓN Y RESPONSABILIDAD SOCIAL Objetivo 3.4.1: Promover el ejercicio pleno de los derechos humanos en el desarrollo, adquisición, y uso de sistemas de IA en el sector público como privado a través de guías, protocolos, capacitación y asistencia técnica. Acciones: Desarrollar guías de desarrollo y uso de las tecnologías basadas IA en programas sociales y educativos, acceso a crédito, oportunidades de empleo, y servicios de salud orientadas a prevenir la discriminación en el perfilamiento de la población usuaria; Establecer protocolos de información a las personas usuarias sobre el uso de las tecnologías basadas en IA en los sistemas con los que interactúan describiendo claramente riesgos y limitaciones del sistema, el proceso de quejas y tiempos de resolución de las mismas; Identificar y mitigar la discriminación algorítmica mediante la capacitación sobre sesgos, perspectiva de género, derechos humanos, a todas las personas involucradas en las distintas etapas del ciclo de la IA desde la generación de datos hasta el uso de sistemas; Proveer de infraestructura de internet de alta velocidad y capacidad de procesamiento de grandes volúmenes de datos en Universidades y Centros de Investigación orientados al desarrollo de casos de uso de IA aplicados al contexto y las necesidades de las comunidades que sirven. Facilitar el acceso a esta infraestructura a las PYMES e instituciones Públicas locales para el desarrollo de casos de uso, capacitación, desarrollo de habilidades en IA e inclusión digital de toda la población; Medir y mitigar los impactos ambientales del ciclo de vida de la IA, particularmente en lo que se refiere al consumo energético, de agua y emisiones de gases de efecto invernadero de los centros de datos públicos y privados; Impulsar el emprendimiento de base tecnológica y atracción de capital potenciando las oportunidades del \"Powershoring\"; Adecuar espacios públicos como bibliotecas, aulas digitales, centros de atención al público y centros de inclusión digital con programas para el desarrollo, uso y aplicación de la IA en diferentes actividades y profesiones. Los espacios deberán proveer hardware y software accesible para personas no familiarizadas con las nuevas tecnologías, o con alguna discapacidad sensorial visual, auditiva, física, intelectual o psicosocial; Fomentar la formación humanista y ética en IA, con un enfoque en derechos humanos, inclusión, diversidad y perspectiva de género, facilitando el acceso a becas para la formación y estudio de especialización en áreas STEM a mujeres, comunidades indígenas y población de entornos rurales y semiurbanos; Salvaguardar la diversidad multicultural y lingüística del país, emprendiendo acciones para generar datos de entrenamiento (grandes modelos de lenguaje locales y regionales) que representen la diversidad de la población, integrando aspectos culturales en el desarrollo de la IA garantizando sistemas sean más equitativos, relevantes y éticamente sólidos. INFRAESTRUCTURA Y DATOS Objetivo 3.5.1: Promover la inversión en el desarrollo de Infraestructura Pública Digital (DPI), incluyendo redes de telecomunicaciones, software, modelos de IA, y estructuras de datos abiertos diseñadas bajo principios éticos. Acciones: Definir una política nacional de gobernanza de datos; Impulsar la inversión en el despliegue de redes de telecomunicaciones - incluidas las comunitarias -, el incremento de la capacidad de procesamiento de los centros de datos, la gestión de un consumo energético sostenible, capacidades de soporte técnico y administrativo, así como, el fortalecimiento a redes de computación entre centros académicos de investigación y desarrollo; Impulsar el desarrollo de software en código certificado, abierto, reutilizable y basado en estándares internacionales, así como, modelos abiertos de IA como parte del stack tecnológico de la Administración Pública. Dicha DPI deberá estar disponible para el uso compartido de entidades públicas y privadas; Fortalecer el desarrollo de estructuras y esquemas de datos que faciliten el intercambio legal y seguro de información, implementando técnicas de anonimización de datos personales y aplicando protocolos de procesamiento ético y responsable, especialmente en datos comerciales que contengan información de identificación personal. Además, promover la generación sistemática de estadísticas, indicadores y bases de datos representativas; Promover políticas de datos y gobierno abierto, así como, interfases de aplicación - APIs - que aseguren que los usuarios tendrán acceso a datos necesarios, actualizados y de calidad para el desarrollo y uso de las tecnologías basadas en IA. En este sentido, se deberá asegurar una gestión efectiva de los datos y calidad en su ciclo de vida; Definir principios claros sobre cómo el gobierno y las empresas recopilan, utilizan y comparten datos, promoviendo la transparencia, explicabilidad y auditoría en la interacción con soluciones basadas en inteligencia artificial. Deberán también especificar los mecanismos de protección, y supervisión para asegurar la privacidad y seguridad de los datos; Acelerar la digitalización de todos los organismos del Estado para una mejor aplicación y uso de la IA en el diseño de servicios digitales proactivos y altamente personalizados en la experiencia de interacción con el usuario. Así como, para la mejora en todas las labores del sector público, la toma de decisiones y el diseño de política pública basado en evidencia; Capacitar a los funcionarios públicos de todos los niveles de gobierno en el uso ético, responsable y basado en derechos humanos sobre la aplicación de tecnologías basadas en la IA en sus labores, impulsando el desarrollo de casos de uso para mejora de servicios a la población, así como, en la gestión interna de la función pública. La capacitación deberá estar en el marco de una agenda de Innovación Pública que permita espacios de experimentación abierta como pueden ser laboratorios de diseño de servicios y/o sandboxes. Éstos, habilitados en colaboración con el ecosistema GovTech y co-financiamiento público y privado; Alinear los incentivos para promover la inversión en infraestructura básica de telecomunicaciones e internet, computación, supercomputación y centros de datos, abriendo oportunidades para la implementación de esquemas de colaboración público-privada, basados en principios de neutralidad tecnológica y competencia. INNOVACIÓN, INVESTIGACIÓN E INDUSTRIA Objetivo 3.6.1: Articular la atracción de capital para la investigación y desarrollo de tecnologías emergentes incluida la IA. Acciones: Aumentar progresivamente la inversión en Investigación y Desarrollo (I & D) para alcanzar el promedio de inversión como porcentaje del Producto Interno Bruto (PIB) de la OCDE de 2.3%, actualmente México destina sólo el 0.3%. Este aumento deberá priorizar la investigación y desarrollo de casos de uso de IA en todos los sectores económicos y sociales del país, utilizando la Infraestructura Pública Digital (DPI) física y de software. Comenzando con sectores que ya tienen una base tecnológica y capacidad de absorción de IA para alcanzar resultados y casos de éxito a corto plazo que justifiquen inversiones futuras en otros sectores; Focalizar fondos de inversión en desarrollo de casos de uso de IA en industrias cuyos equipos directivos son diversos en términos de experiencia profesional y paritarios en el número de mujeres en espacios de liderazgo. Los casos de uso podrán utilizar infraestructura pública digital y espacios controlados de prueba sandboxes, así como, acceso a redes de investigación y desarrollo Nacionales e Internacionales; Impulsar la soberanía tecnológica, el emprendimiento de base tecnológica y atracción de capital potenciando las oportunidades del \"Nearshoring\" a empresas desarrollando productos y servicios en las áreas de IA aplicada a biociencia, modelos abiertos de IA, videojuegos, tecnología verde y apoyando a la industria de alta tecnología como el desarrollo de microprocesadores de nueva generación, bajo un enfoque sostenible; Apoyar la investigación colaborativa impulsando proyectos conjuntos entre universidades, industria y emprendimientos de base tecnológica para avanzar en el desarrollo de la IA; Aumentar el papel de la cooperación internacional así como la coordinación de políticas y estrategias a nivel nacional para fortalecer la soberanía tecnológica en áreas estratégicas - como es el diseño de microprocesadores-; Requerir a los desarrolladores de sistemas basados en la IA el uso de espacios controlados de pruebas denominados \"Sandboxes\" que faciliten el cumplimiento con protocolos de seguridad, protección y respeto a los derechos humanos, medición de impacto y estándares de transparencia algorítmica. Estos espacios proveerán alta capacidad de cómputo y acceso a redes de especialistas en México y el extranjero que ayuden a calibrar los casos de uso; Impulsar la productividad de las PYMES a través de la digitalización de sus operaciones y el desarrollo de nuevos modelos de negocio con el uso de IA. Promoviendo el desarrollo de capacidades técnicas y jurídicas en ámbitos como la propiedad intelectual, privacidad y datos personales recursos de etiquetado que faciliten validar la autenticidad de la información, todo en concordancia con estándares nacionales e internacionales de derechos humanos. RECOMENDACIONES DE REGULACIÓN En el contexto del avance acelerado de las tecnologías basadas en inteligencia artificial en todos los ámbitos de la sociedad, México se encuentra en un momento clave para establecer un marco regulatorio sólido que fomente la innovación y proteja los derechos y valores fundamentales de las personas, especialmente de los grupos poblacionales menos representados y en situación de vulnerabilidad. Las recomendaciones de regulación tomaron como punto de partida un análisis de las políticas existentes, las propuestas legislativas en curso y las consideraciones éticas y jurídicas que están dando forma al futuro de esta tecnología en el país. Incluyendo desde la protección de la privacidad hasta la equidad en el acceso y uso de las tecnologías basadas en IA, pasando por la responsabilidad algorítmica y la transparencia en su implementación, e identificando la gobernanza y el valor de los datos. Integrar en la protección de los derechos humanos, la protección de los derechos relacionados con el sistema nervioso central y periférico, así como con la actividad mental de las personas y la información que de estos se derive - neuroderechos- mediante la actualización en la Ley General de Protección de Datos Personales en Posesión de los Sujetos Obligados y la Ley Federal de Protección de Datos Personales en Posesión de los Particulares, para la protección contra las neurotecnologías; Promover el fortalecimiento de organismos certificadores de software y hardware para el desarrollo, uso y aplicación de las tecnologías basadas en IA; conforme a los estándares acordados por los mecanismos de coordinación regulatoria que se implementen para el fin de este documento. Dichos organismos deberían operar bajo mecanismos de coordinación institucional, asegurando la colaboración entre diferentes sectores y niveles de gobierno para garantizar una visión integrada y coherente a nivel nacional; Fomentar esquemas de regulación progresivos, flexibles y adaptables así como de autorregulación, bajo un marco de principios, obligaciones y consecuencias legales vinculantes; Establecer normativas claras y específicas para la gestión de datos en la nube y en los centros de datos; Optar por una regulación de la IA basada en la neutralidad tecnológica, la competencia económica, la gestión de riesgos, la privacidad, la seguridad y la transparencia de acuerdo a estándares internacionales y mejores prácticas; Clasificar a las tecnologías basadas en IA por su grado de afectación en los derechos humanos, prohibiendo el reconocimiento y predicción de emociones, pensamientos y/o conductas, y/o la incidencia sobre estos, así como la identificación biométrica con fines de perfilamiento o vigilancia; Facilitar medios y mecanismos de denuncia de abusos y aplicación de las sanciones correspondientes; Compaginar las regulaciones y definiciones existentes con marcos de referencia internacional como la \"Recomendación sobre la ética de la inteligencia artificial de la UNESCO¨, los principios de IA de la OECD, la Resolución A/78/L49 de la Organización de las Naciones Unidas (ONU), entre otros, de acuerdo a la necesidad de desarrollo, uso y aprovechamiento de la IA en el contexto mexicano. Así como, determinar cuáles deben ser adaptadas, actualizadas y/o creadas; Fortalecer la garantía del ejercicio pleno de los derechos humanos, como principios regulatorios en todo el ámbito digital, incluidas las tecnologías basadas en la IA. La definición de estándares, código de ética y procesos anti sesgos, deberán publicarse como Decretos Secretariales, Guías y Lineamientos de acuerdo al ámbito de competencia de Organismos Autónomos, Gobiernos Estatales y Municipales; a través de procesos de participación con academia, sociedad civil organizada y comunidades impactadas por el uso de IA. Es fundamental que estos principios y regulaciones se fundamenten en la Constitución Política de los Estados Unidos Mexicanos; Expedir una Ley de Ciberseguridad que considere: la protección de infraestructuras críticas y datos sensibles, la promoción de la educación y la concientización en materia de ciberseguridad, así como la colaboración entre sectores público y privado para compartir información, mejores prácticas, y la implementación de mecanismos eficaces de respuesta ante incidentes. El proceso de preparación de la Ley deberá considerar el cumplimiento de los estándares del Convenio de Budapest u otros convenios sobre delitos cibernéticos diferenciando claramente la seguridad nacional, que se ocupa de proteger infraestructura y servicios críticos, de la seguridad ciudadana, que se enfoca en protocolos de actuación y respuesta a incidentes cibernéticos bajo mecanismos de cooperación efectivos, transparentes y con rendición de cuentas para garantizar una contribución efectiva a la ciberseguridad; Armonizar principios regulatorios a los tratados comerciales y convenios internacionales de los que México sea parte; Promover una gestión ética y responsable en el desarrollo, uso, aplicación e implementación de las tecnologías basadas en IA (marco de responsabilidades legales): responsables, responsabilidades y consecuencias; Implementar \"sandboxes regulatorios\" o espacios de prueba controlados, en donde se reúnan los reguladores para guiar a las empresas en el lanzamiento seguro de sus innovaciones al mercado, con el fin de identificar riesgos potenciales que lleven o no a una posible intervención específica (De La Peña et al., 2024); Fortalecer las capacidades de la Comisión Federal de Competencia Económica (COFECE) como órgano regulador que fomente la competencia y el acceso equitativo a los datos para que nuevas tecnologías como las basadas en Inteligencia Artificial estén al alcance de todas y todos, sin importar su tamaño (emprendedores o gigantes tecnológicos), y para que estas sean un motor de desarrollo, innovación e inclusión económica en México; Fortalecer las capacidades del Instituto Federal de Telecomunicaciones (IFT) como órgano de competencia en materia de telecomunicaciones para mejorar las condiciones de despliegue de infraestructura, y asequibilidad de los servicios de telecomunicaciones en México. Esto, a través de procesos de conectividad significativa, autonomía y apropiación digital, de acuerdo con análisis de contexto basados en las necesidades, intereses y riesgos asociados de las localidades en materia de conectividad; Fortalecer las capacidades y marco normativos del Instituto Nacional de Transparencia, Acceso a la Información y Protección de Datos Personales (INAI), como órgano de competencia en materia de protección de datos personales para incluir la supervisión y el cumplimiento de las normativas relacionadas con el uso de las tecnologías basadas en IA y la protección de datos personales. Esto implicaría la implementación de mecanismos de monitoreo y evaluación para garantizar que las instituciones públicas y privadas cumplan con las regulaciones establecidas y tomen medidas correctivas cuando sea necesario; Actualizar la Ley Federal de Protección de Datos Personales en Posesión de los Particulares, la Ley General de Protección de Datos Personales en Posesión de Sujetos Obligados; Crear una Ley de Datos Abiertos Públicos; Fortalecer las capacidades del Instituto Mexicano de la Propiedad Industrial (IMPI) y el Instituto Nacional del Derecho de Autor (INDAUTOR) en materia de protección de derechos de autor, patentes y marcas registradas en el contexto del desarrollo, uso, aplicación y comercialización de tecnologías basadas en IA; Fusionar y fortalecer las capacidades del Instituto Mexicano de la Propiedad Industrial (IMPI) y el Instituto Nacional del Derecho de Autor (INDAUTOR) en materia de protección de derechos de autor, patentes y marcas registradas en el contexto del desarrollo, uso, aplicación y comercialización de tecnologías basadas en IA; Definir el marco de protección de la propiedad intelectual y de los derechos de autor ante el uso de datos y obras en los sistemas de IA. Así como la protección de obras, desarrollos e invenciones producidos con tecnologías basadas en IA; Actualizar la Ley Federal de Derecho del Autor y la Ley Federal de Protección a la Propiedad Industrial. Esto permitirá adaptar las regulaciones a las nuevas realidades tecnológicas y garantizar la adecuada protección de los derechos de propiedad intelectual en un entorno digital; Desarrollar guías prácticas, modelos de contratos y herramientas de evaluación de riesgos para ayudar a mitigar posibles problemas éticos y legales, así como desarrollar auditorías, investigaciones de posibles infracciones y sanciones para aquellos que no cumplan con las regulaciones establecidas; Fortalecer las capacidades del Instituto Nacional Electoral (INE), a través de la creación de un marco reglamentario que defina los límites y condiciones bajo los cuales las herramientas basadas en la IA pueden ser utilizadas en campañas políticas, propaganda electoral y difusión de información relacionada con elecciones; Desarrollar herramientas y estrategias que permitan identificar y contrarrestar la desinformación generada por IA. Así como, desarrollar sistemas de detección de noticias falsas o engañosas, desinformación, distorsión de la realidad y otros contenidos sintéticos que puedan ser utilizados para manipular la opinión pública; Fortalecer las capacidades del Poder Judicial para el uso y aplicación ético y responsable de las tecnologías basadas en la IA a través de la capacitación, el desarrollo de directrices y estándares éticos, auditoría y evaluación de algoritmos, protección de la privacidad y los derechos humanos, y promoción de la participación ciudadana y la rendición de cuentas en los procesos de justicia; El Poder Judicial deberá colaborar con expertos en IA, ética y derechos humanos para desarrollar directrices y estándares éticos y legales para el uso y aplicación de las tecnologías basadas en la IA en el sistema judicial. Estas directrices deberán abordar cuestiones como la transparencia, la equidad, la imparcialidad y la protección de datos, garantizando que las decisiones judiciales basadas en algoritmos sean justas y respeten los derechos fundamentales; Fortalecer las competencias de la Comisión Nacional de los Derechos Humanos (CNDH), el Centro Nacional de Prevención de Desastres (CENAPRED), el Instituto Nacional de las Mujeres (INMUJERES) y el Instituto Nacional de Propiedad Industrial (INPI) en áreas relacionadas con la discriminación, la inclusión, la representación, el consentimiento en material audiovisual, la salvaguarda de la imagen y la reputación, así como los derechos de las comunidades indígenas, grupos vulnerables y otras cuestiones pertinentesFomentar en el poder legislativo, la constante evolución, efectividad y coherencia de la legislación en materia de tecnologías emergentes; Integrar los principios de protección a los derechos humanos en el desarrollo, uso y aplicación de las tecnologías basadas en la IA en todos los convenios y tratados internacionales, como el T-MEC, incorporando cláusulas específicas que aborden estos temas y referenciando instrumentos internacionales pertinentes; Establecer mecanismos de supervisión y cumplimiento, fomentar la cooperación y el intercambio de mejores prácticas, y promover la inclusión de cláusulas de salvaguarda y resolución de controversias. RECOMENDACIONES DE GOBERNANZA La gobernanza efectiva y democrática de la IA se vuelve indispensable para asegurar su uso ético, responsable, transparente y beneficioso para la sociedad. Las Recomendaciones de Gobernanza buscan mecanismos institucionales, políticas y estrategias que el país está implementando para supervisar y regular el desarrollo, uso y aplicación de esta tecnología. Desde la creación de comités multiactor, multisectoriales, interdisciplinarios y transdisciplinarios, hasta la colaboración con el sector privado y la sociedad civil. Una gobernanza robusta, abierta y colaborativa es clave para fomentar la innovación responsable y proteger los derechos y valores fundamentales de las personas. Integrar las atribuciones de la Coordinación de Estrategia Digital Nacional de la Presidencia de la República, y las del Centro de Investigación e Innovación en Tecnologías de Información (INFOTEC) para crear la Agencia Digital Nacional (ADN) como organismo público descentralizado que reportaría al Ejecutivo Federal. La fusión considera la integración de plantillas de personal, activos y presupuesto para formar la ADN. Así como, la reconversión de roles y perfiles profesionales, sin que esto considere un incremento en el monto de presupuesto que actualmente ejercen cada una de las entidades descritas; Crear una Oficina de Inteligencia Artificial dentro de la ADN. Las tareas de la Oficina, incluyen el desarrollo de herramientas para evaluar las capacidades de los modelos de IA de propósito general, monitorear la implementación de reglas, identificar riesgos emergentes, investigar posibles infracciones y apoyar la aplicación de regulaciones sobre usos y prácticas prohibidas de IA, y el registro de sistemas de riesgo; Promover a través de la ADN que todas las entidades públicas asignen un talento digital como punto focal responsable de supervisar todos los sistemas basados en la inteligencia artificial que utilicen y que garanticen que el uso de estas herramientas en el servicio público siga siendo seguro para el ciudadano y la nación; Integrar un Comité de Ética que fomente la innovación, compra, desarrollo, uso y aplicación responsable de las tecnologías basadas en la IA en el sector público y privado. El Comité debe tener un enfoque multiactor, multisectorial, interdisciplinario y transdisciplinario; En temas relacionados a la seguridad nacional, se deberá seguir la normatividad aplicable; Alinear las directrices en materia de gestión de presupuesto TIC y de procesos de adquisiciones de bienes y servicios TIC de la Administración Pública Federal, los Organismos Autónomos, los Poderes Legislativos, Gobiernos Estatales y Municipales, así como los de los Programas de Apoyo a la Modernización Local como el INAFED, para generar mejores condiciones de precio, y promover el desarrollo, uso y actualización constante de infraestructura pública digital abierta y de uso compartido con entidades públicas y privadas; Actualizar y fortalecer las atribuciones de la Comisión Intersecretarial de Tecnologías de la Información y Comunicación, y de la Seguridad de la Información (CITICSI) y sus grupos de trabajo, incorporando uno especializado en Inteligencia Artificial y tecnologías emergentes; para reflejar las prioridades de desarrollo digital en el país; Promover la implementación de mecanismos de coordinación con Gobiernos Estatales como la Conferencia Nacional de Gobernadores (CONAGO); Estatales y Municipales como el Comité de Informática de la Administración Pública Estatal y Municipal A.C. (CIAPEM); así como con Órganos Constitucionales Autónomos como el INAI, la Comisión Nacional de Competencia Económica (COFECE), el IFT, la Comisión Nacional Derechos Humanos, la Comisión Federal para la Protección contra Riesgos Sanitarios (COFEPRIS), el INE, el IMPI, la Comisión Nacional de Bioética (CONBIOÉTICA), y los poderes Legislativo y Judicial, por mencionar algunos; Habilitar al Consejo Consultivo de la CITICSI como un espacio de gobernanza multiactor - sector privado, academia, sociedad civil, población, entre otros- responsable de empujar actualizaciones constantes a la Agenda Digital Nacional y Agendas Específicas salvaguardando los principios de inclusión, no discriminación, privacidad, acceso equitativo, y fomento a la innovación digital en todos los grupos, poblaciones y sectores productivos del País; Incorporar a representantes de la industria TIC y sectores industriales de alto consumo de servicios y productos basados en la IA, la academia y la sociedad civil organizada al proceso de definición de estándares, protocolos, y salvaguardas para el desarrollo, uso y aplicación ética, legal y responsable de modelos de IA y tecnologías emergentes, dentro del marco de derechos humanos; Institucionalizar mecanismos de colaboración entre reguladores, stakeholders y entidades públicas para implementar espacios de prueba, conocidos como \"sandboxes\"; Habilitar el Centro de Datos tier 4 de INFOTEC como un ¨Sandbox¨ especializado en el desarrollo de casos de uso estratégicos para el desarrollo del país y cuyo uso de datos requiere que éstos sean tratados bajo los estándares más altos de seguridad, anonimización y privacidad. Dichos casos de uso contarán con consejos consultivos y acceso a redes de expertos nacionales e internacionales; Garantizar la aplicación del principio constitucional de paridad de género en la dirección de entidades gubernamentales y su extensión a diversos niveles jerárquicos, funciones y áreas especializadas de tecnologías basadas en la IA, así como su incorporación en organizaciones privadas y sociales mediante cambios legales que contemplen acciones afirmativas, cuotas y medidas de transparencia. Esto debe incluir la promoción de la diversidad de perfiles en los órganos directivos y en todas las áreas de especialización, abarcando género, edad y experiencia en aspectos técnicos, tecnológicos, humanísticos y éticos, entre otros; Reconocer y contribuir a la agenda definida por la Alianza Nacional de Inteligencia Artificial (ANIA) como un espacio consultivo y de acción pública del Poder Legislativo, dirigido desde el Senado y articulación bicameral, multiactor, abierto y participativo, orientado a mantener el marco legislativo de México a la vanguardia para garantizar los derechos de las personas y el mejor aprovechamiento de las tecnologías digitales; Promover la participación de México en el mayor número de procesos de Gobernanza Digital y estandarización técnica, como definición de estándares, y marcos de referencia internacional y demás agendas de Organismos Internacionales donde la ADN articulará la postura país en colaboración con la Secretaría de Relaciones Exteriores y Organismos Especializados en México según sea el caso. RECOMENDACIONES DE INDICADORES Definir indicadores sobre el impacto de la Inteligencia Artificial en la sociedad es desafiante debido a su complejidad y múltiples dimensiones. Es esencial identificar y medir con precisión los efectos positivos y negativos de la IA en áreas como economía, empleo, privacidad y equidad. Las recomendaciones de indicadores buscan fortalecer las capacidades institucionales para generar datos confiables y medir el impacto de la IA de manera precisa. Se basan en la información del Anexo 1.9. Establecer un subgrupo de trabajo para la construcción de Indicadores del uso y desarrollo de las tecnologías basadas en la IA, con la participación de la CITICSI y el INEGI; Construir una matriz nacional de indicadores de IA que deberá ser consistente con los marcos de indicadores globales con el objeto de medir el avance de México respecto del resto de los países en el mundo. Esta deberá poder definir cómo mínimo, el indicador, método de cálculo, fuente de obtención de la información - encuesta, sistema - así como, establecer estándares sólidos de recopilación y gestión de datos, garantizando la transparencia y la responsabilidad en su uso; Habilitar una matriz de indicadores en formato abierto, que contemple una curaduría continua de datos subyacentes, que se encuentren basados en el mapeo de APIs y sistemas de información fuente acreditados para el cálculo del indicador. (Por ejemplo, el número de carreras dirigidas al estudio de la IA pueden ser datos extraídos del catálogo de carreras de entidades educativas acreditadas ante la SEP). CONCLUSIONES Las recomendaciones de este documento reflejan un compromiso sólido y multifacético para orientar el desarrollo y la implementación de la inteligencia artificial en México hacia un futuro sostenible, inclusivo, ético y responsable, estableciendo un marco integral que abarca políticas públicas, regulaciones específicas y estrategias de gobernanza, subrayando la importancia de un enfoque colaborativo, multiactor, multidisciplinario, multisectorial, interdisciplinario y transdisciplinario que involucre a todos los sectores de la sociedad. Con el propósito de contar con una visión integral del país en materia digital y poder implementar las recomendaciones vertidas en este documento, es imperante contar con la continua participación de todos los actores del ecosistema digital del país, además de contar con una estrecha coordinación institucional de los distintos órganos de gobierno y la creación de estructuras que permitan materializar estas recomendaciones. Además, la adopción y el aprovechamiento del desarrollo científico y tecnológico de las tecnologías basadas en IA presentan una oportunidad única para impulsar el crecimiento económico, enfrentar desafíos sociales y medioambientales y mejorar la calidad de vida de la población. Sin embargo, es fundamental que este avance tecnológico se gestione de manera respetuosa y comprometida con la protección de los derechos humanos y el medio ambiente, y se promueva la equidad, mitigando y evitando a su vez la exacerbación de las desigualdades existentes. Las recomendaciones detalladas en este documento no sólo buscan posicionar a México al frente en el uso ético, legal y responsable de las tecnologías basadas en la IA, sino también asegurar que la transición hacia una economía y sociedad digitalmente avanzadas beneficie a todos los sectores de la población, protegiendo especialmente a los más vulnerables. Para lograr esto, es esencial la inversión en educación, formación, infraestructura digital, investigación y desarrollo, así como la creación de un marco regulatorio que fomente la innovación mientras protege contra los riesgos potenciales asociados con la tecnología. Mirando hacia el futuro, la implementación efectiva de estas recomendaciones requerirá un esfuerzo sostenido, monitoreo constante y la voluntad de adaptarse a los cambios rápidos en el campo de la tecnología. La abierta comunicación y colaboración a nivel nacional e internacional, así como el intercambio de conocimientos y mejores prácticas, serán cruciales para navegar los desafíos emergentes y aprovechar las nuevas oportunidades que las tecnologías basadas en IA ofrecen. Con este documento, México se posiciona en la vanguardia del debate global sobre la IA, reiterando su compromiso con un desarrollo tecnológico que sea inclusivo, justo y beneficioso para toda su población.",
      "word_count": 10317,
      "character_count": 70169,
      "vector": [
        0.15565285086631775,
        -0.16328740119934082,
        0.10471870005130768,
        0.0022427139338105917,
        -0.08818931132555008,
        -0.034954506903886795,
        -0.000611956522334367,
        0.025418048724532127,
        -0.0650581642985344,
        -0.0010844889329746366,
        -0.027361994609236717,
        0.10104446858167648,
        0.08190888911485672,
        -0.041623424738645554,
        0.1137077808380127,
        -0.01386046502739191,
        -0.04642907530069351,
        -0.032419316470623016,
        -0.022371305152773857,
        -0.08465006947517395,
        -0.05315178632736206,
        -0.10363639146089554,
        0.07689401507377625,
        0.14016421139240265,
        -0.014831341803073883,
        0.04232848808169365,
        -0.10682915896177292,
        -0.002442050026729703,
        -0.008821651339530945,
        -0.010540978983044624,
        0.02414787746965885,
        -0.09236955642700195,
        0.04097999632358551,
        -0.03965560346841812,
        0.059734687209129333,
        0.023303302004933357,
        0.0790880024433136,
        -0.03266681730747223,
        -0.015256471931934357,
        0.013411340303719044,
        -0.012931413017213345,
        0.01628786139190197,
        0.0640411376953125,
        -0.06452637165784836,
        0.06035544350743294,
        0.09491407126188278,
        0.07530517876148224,
        -0.0012796934461221099,
        -0.0617503896355629,
        -0.016178734600543976,
        0.05872297286987305,
        0.046790190041065216,
        -0.04958207905292511,
        0.07413901388645172,
        0.003021216718479991,
        -0.016604319214820862,
        -0.041717007756233215,
        -0.03690178319811821,
        -0.05974997580051422,
        -0.03412773460149765,
        0.003937414847314358,
        0.0424966961145401,
        0.015383940190076828,
        -0.08855418860912323,
        -0.08071115612983704,
        0.05972680449485779,
        -0.039558615535497665,
        -0.001940727117471397,
        -0.032563336193561554,
        -0.05399714410305023,
        0.008052960969507694,
        0.014434540644288063,
        -0.036840155720710754,
        0.013590240851044655,
        0.056366294622421265,
        0.02913002483546734,
        -0.05092973634600639,
        0.02254357561469078,
        0.008948300965130329,
        0.02835793048143387,
        0.09962805360555649,
        0.030784400179982185,
        0.042805321514606476,
        0.04091314971446991,
        0.01931823417544365,
        -0.013411860913038254,
        -0.03929978236556053,
        0.048394400626420975,
        0.041561201214790344,
        -0.06697767227888107,
        -0.025090234354138374,
        -0.019944114610552788,
        -0.046012941747903824,
        -0.0942143052816391,
        0.023615064099431038,
        0.02491905353963375,
        -0.023953916504979134,
        0.03152225539088249,
        -0.020160429179668427,
        -0.04972507804632187,
        0.005926554556936026,
        0.04593219235539436,
        -0.11363143473863602,
        0.04094119742512703,
        0.028486860916018486,
        0.0005611475789919496,
        -0.00614440580829978,
        -0.0028129862621426582,
        -0.06081687659025192,
        -0.0406096912920475,
        0.010821238160133362,
        -0.02244899421930313,
        0.0216582752764225,
        -0.03649764508008957,
        0.008568527176976204,
        -0.001026539015583694,
        -0.05660836771130562,
        0.03576642647385597,
        -0.005430715158581734,
        0.009621541015803814,
        0.041256215423345566,
        0.020087137818336487,
        -0.03613337501883507,
        0.017219215631484985,
        -0.017295554280281067,
        -0.04033153876662254,
        -0.021442387253046036,
        0.02039060741662979,
        0.0006331814802251756,
        -0.09099442511796951,
        -0.021277278661727905,
        0.04881555959582329,
        0.0007790184463374317,
        0.027457349002361298,
        -0.01651940308511257,
        0.032963141798973083,
        -0.0009051969391293824,
        -0.10327474772930145,
        -0.0490521676838398,
        0.04644670709967613,
        -0.06606384366750717,
        0.038918010890483856,
        -0.00276734447106719,
        -0.002396108815446496,
        -0.008219495415687561,
        -0.02793865092098713,
        0.020658938214182854,
        0.005010465160012245,
        -0.021783476695418358,
        0.03685953468084335,
        -0.0068061272613704205,
        -0.017253359779715538,
        -0.051633529365062714,
        -0.03783421963453293,
        0.041879478842020035,
        0.037406690418720245,
        -0.02221289835870266,
        -0.019317349418997765,
        -0.005804957821965218,
        -0.025760427117347717,
        -0.010089063085615635,
        0.05788446590304375,
        -0.05034100264310837,
        -0.010554619133472443,
        -0.04461238533258438,
        -0.006155124865472317,
        0.005004484206438065,
        0.06528817862272263,
        0.003888251492753625,
        0.005922229494899511,
        -0.018290050327777863,
        0.027262616902589798,
        -0.000819740875158459,
        0.02270832285284996,
        -0.002248145639896393,
        -0.013333966955542564,
        0.04122824966907501,
        0.08752179890871048,
        0.015881843864917755,
        0.08726893365383148,
        0.059951409697532654,
        -0.06526029109954834,
        -0.07726553827524185,
        0.02817109227180481,
        -0.023642966523766518,
        -0.004197460133582354,
        0.028847085312008858,
        0.030199332162737846,
        -0.00422077439725399,
        -0.015952391549944878,
        0.012533691711723804,
        0.036890506744384766,
        0.03029155172407627,
        0.0211391169577837,
        0.029991433024406433,
        -0.010009374469518661,
        -0.02526813931763172,
        -0.018960893154144287,
        0.022379662841558456,
        -0.04356878250837326,
        -0.017432328313589096,
        0.0021395888179540634,
        -0.005758280400186777,
        0.0197399090975523,
        -0.03714964538812637,
        0.0192397553473711,
        0.008213457651436329,
        -0.005593812093138695,
        0.008038198575377464,
        0.07121092826128006,
        -0.013377068564295769,
        0.005642124451696873,
        0.030144039541482925,
        -0.0425858348608017,
        -0.06981796026229858,
        0.0006505086785182357,
        0.02493271790444851,
        0.04939429834485054,
        0.04011864960193634,
        -0.02962016686797142,
        -0.013892332091927528,
        -0.03162122890353203,
        0.0402529276907444,
        0.001165062771178782,
        0.010036741383373737,
        0.005955848842859268,
        -0.03976652771234512,
        0.008394437842071056,
        0.03389495983719826,
        0.009181472472846508,
        0.029279587790369987,
        0.03279385343194008,
        -0.03826611489057541,
        0.008220942690968513,
        0.010223438031971455,
        0.01655513606965542,
        -0.02162959612905979,
        0.01937270723283291,
        0.059739936143159866,
        0.0052843596786260605,
        -0.035890813916921616,
        -0.02017139084637165,
        -0.02813597209751606,
        0.02116703987121582,
        -0.05607813596725464,
        -0.01789538934826851,
        -0.018473589792847633,
        -0.014511831104755402,
        -0.05649362877011299,
        0.03596196323633194,
        0.004418236669152975,
        0.030012203380465508,
        -0.0527120940387249,
        -0.0401422455906868,
        0.012103436514735222,
        -0.011458447203040123,
        0.009965618140995502,
        -0.01302562840282917,
        -0.06319455057382584,
        0.008854297921061516,
        -0.027637358754873276,
        0.029351897537708282,
        -0.02724570594727993,
        0.004961448721587658,
        0.023798128589987755,
        -0.009796774946153164,
        0.005022107623517513,
        0.008658960461616516,
        0.015952622517943382,
        -0.026156282052397728,
        -0.023417487740516663,
        -0.03667411208152771,
        -0.045512039214372635,
        0.05212468281388283,
        -0.0011956702219322324,
        0.031780604273080826,
        -0.023315874859690666,
        0.015448857098817825,
        0.02208024635910988,
        0.00780317559838295,
        -0.04723198711872101,
        0.0024033086374402046,
        -0.0037198078352957964,
        0.018027056008577347,
        -0.015705164521932602,
        0.015949681401252747,
        0.02058611996471882,
        -0.003518703393638134,
        0.035373784601688385,
        0.03266967833042145,
        -0.016007814556360245,
        -0.009011760354042053,
        0.024039171636104584,
        -0.0038998255040496588,
        0.05425556004047394,
        0.013991858810186386,
        -0.05352596193552017,
        -0.0034567948896437883,
        0.02935190126299858,
        0.015108970925211906,
        -0.003389434888958931,
        0.02270679362118244,
        0.0155109828338027,
        0.041892267763614655,
        -0.025505544617772102,
        0.01236014161258936,
        -0.026069847866892815,
        -0.018720852211117744,
        -0.013273525051772594,
        -0.017097115516662598,
        0.002630815142765641,
        -0.013219757005572319,
        0.01531145628541708,
        -0.0032103252597153187,
        0.00992154236882925,
        -0.024028856307268143,
        -0.018446803092956543,
        0.019765939563512802,
        0.0028059969190508127,
        0.0016960450448095798,
        -0.01783960498869419,
        -0.00775786442682147,
        0.012351571582257748,
        0.01179805863648653,
        -0.03584461286664009,
        -0.01170077733695507,
        -0.005295995622873306,
        -0.015552067197859287,
        0.011661632917821407,
        -0.010385933332145214,
        0.030187716707587242,
        -0.019753338769078255,
        0.01775970496237278,
        0.047753941267728806,
        0.006309703458100557,
        -0.042405035346746445,
        0.01930074393749237,
        -0.001653089071623981,
        0.029143396764993668,
        -0.015113403089344501,
        0.03254035860300064,
        0.008911002427339554,
        0.044866085052490234,
        -0.013865563087165356,
        0.022266339510679245,
        0.022732364013791084,
        0.007551706861704588,
        -0.006757897324860096,
        0.007367341313511133,
        0.07114216685295105,
        -0.01052863523364067,
        -0.00285680522210896,
        -0.037544962018728256,
        -0.006930008064955473,
        0.02769038826227188,
        0.025143075734376907,
        0.020401597023010254,
        0.02966015599668026,
        -0.00984890852123499,
        -0.029531780630350113,
        -0.03956007957458496,
        0.02222069911658764,
        0.034756120294332504,
        0.07882504910230637,
        -0.024297989904880524,
        -0.015507730655372143,
        0.05039717257022858,
        0.022550517693161964,
        0.001273679663427174,
        -0.0010816273279488087,
        -0.02262798510491848,
        0.0060587190091609955,
        -0.007811619900166988,
        -0.02366454154253006,
        -0.034220896661281586,
        -0.000353770301444456,
        0.03094089962542057,
        0.03324182331562042,
        0.06945538520812988,
        -0.02351805940270424,
        0.0012627453543245792,
        -0.051211994141340256,
        -0.014987640082836151,
        -0.008117110468447208,
        -0.020169023424386978,
        -0.022144043818116188,
        0.05162937194108963,
        -0.04621072858572006,
        0.018169282004237175,
        -0.038426220417022705,
        0.017004316672682762,
        -0.01437851320952177,
        0.05305498465895653,
        -0.00597990769892931,
        -0.05882665142416954,
        0.011966452933847904,
        0.03056151047348976,
        -0.04532207176089287,
        0.0025451367255300283,
        0.023183559998869896,
        0.022450853139162064,
        -0.013697020709514618,
        0.01577487774193287,
        -0.048609599471092224,
        0.03298339620232582,
        0.017112119123339653,
        -0.022052675485610962,
        -0.03344786912202835,
        -0.053135573863983154,
        -0.01617642305791378,
        -0.02355518378317356,
        0.035935159772634506,
        -0.036597684025764465,
        -0.0014354996383190155,
        0.007249756716191769,
        -0.055023062974214554,
        0.050761111080646515,
        0.030599327757954597,
        -0.037714894860982895,
        -0.009943646378815174,
        0.040425267070531845,
        0.017552047967910767,
        0.010106593370437622,
        -0.028874531388282776,
        0.015558320097625256,
        -0.018964657559990883,
        -0.010302109643816948,
        -0.02457018755376339,
        0.00458117388188839,
        0.03923431783914566,
        -0.03877681493759155,
        -0.014491978101432323,
        0.03408301994204521,
        0.0389275923371315,
        -0.005688903853297234,
        0.0018953352700918913,
        0.025020595639944077,
        0.009494965896010399,
        -0.01897639036178589,
        -0.012686435133218765,
        0.018505876883864403,
        0.00994875282049179,
        0.016089238226413727,
        -0.03131726756691933,
        -0.023638468235731125,
        -0.0025637890212237835,
        0.0634542778134346,
        -0.04770490527153015,
        -0.0014108387986198068,
        -0.01889178529381752,
        -0.003925651777535677,
        0.026041066274046898,
        -0.042402662336826324,
        -0.014482890255749226,
        0.05541886389255524,
        -0.02556351013481617,
        0.039418354630470276,
        -0.023574355989694595,
        0.06869902461767197,
        0.0011731598060578108,
        0.0011905852006748319,
        -0.034952372312545776,
        -0.00502431346103549,
        -0.018883967772126198,
        0.05939026549458504,
        0.0046897330321371555,
        0.101896733045578,
        -0.017007559537887573,
        0.04546879604458809,
        -0.03171113505959511,
        0.004279934801161289,
        0.018286680802702904,
        0.02603320963680744,
        -0.015070485882461071,
        0.01798914186656475,
        0.03562890365719795,
        0.023927578702569008,
        -0.012926378287374973,
        0.012349202297627926,
        -0.00029423306114040315,
        0.03570942208170891,
        -0.014158323407173157,
        0.016550308093428612,
        0.05537334457039833,
        0.008794560097157955,
        -0.021595295518636703,
        -0.04733411967754364,
        -0.006964296568185091,
        0.016896506771445274,
        0.025420406833291054,
        0.028693854808807373,
        -0.00460732402279973,
        0.02212567627429962,
        0.07693220674991608,
        -0.013166612945497036,
        -0.00796910747885704,
        0.00022983016970101744,
        -0.04824322462081909,
        -0.004358311183750629,
        -0.05590878799557686,
        -0.048243723809719086,
        -0.03450755774974823,
        0.03730450198054314,
        -0.014737092889845371,
        -0.02892601303756237,
        -0.019477972760796547,
        -0.0018554988782852888,
        -0.0312538743019104,
        -0.020116839557886124,
        -0.00848459918051958,
        -0.004056632053107023,
        0.0169075857847929,
        -0.008381904102861881,
        -0.006843870040029287,
        0.021178390830755234,
        -0.00876439455896616,
        0.03255995362997055,
        0.0031832014210522175,
        -0.003306491067633033,
        -0.005573089700192213,
        -0.011186596006155014,
        -0.005493357311934233,
        0.06264296174049377,
        -0.032224565744400024,
        0.013198701664805412,
        0.04196564853191376,
        -0.026314249262213707,
        0.008130400441586971,
        0.011056489311158657,
        -0.014632039703428745,
        0.029078122228384018,
        0.028740908950567245,
        -0.002278226427733898,
        -0.011417705565690994,
        0.02555721066892147,
        0.04057793319225311,
        -0.018462136387825012,
        -0.014846433885395527,
        0.049977824091911316,
        -0.014036804437637329,
        -0.029298778623342514,
        -0.03896591067314148,
        0.012251622043550014,
        -0.02545274794101715,
        -0.0035827714018523693,
        0.00506946537643671,
        -0.018320156261324883,
        -0.012532052583992481,
        0.03957689553499222,
        0.024010512977838516,
        -0.01902174763381481,
        0.01178230531513691,
        -0.011532380245625973,
        0.010648146271705627,
        -0.0036346069537103176,
        -0.05509920418262482,
        -0.007298457436263561,
        -0.0009813477518036962,
        -0.0036922369617968798,
        -0.03193986043334007,
        -0.006522790994495153,
        0.006581488531082869,
        0.008427231572568417,
        -0.02588881179690361,
        -0.047563232481479645,
        0.00619437824934721,
        -0.0038594731595367193,
        0.0145237036049366,
        -0.015802429988980293,
        0.011469963937997818,
        0.008807133883237839,
        0.028973177075386047,
        -0.02175787277519703,
        0.02763098105788231,
        0.029947303235530853,
        -0.04570525512099266,
        0.030916785821318626,
        0.046625204384326935,
        0.014355084858834743,
        0.00605569314211607,
        -0.019843444228172302,
        -0.04226960614323616,
        0.0010177826043218374,
        0.03009696863591671,
        0.02094944566488266,
        0.0031346753239631653,
        -0.030388113111257553,
        -0.03524218127131462,
        0.0011345711536705494,
        0.0004436818999238312,
        0.01325221173465252,
        0.012621607631444931,
        -0.006353769917041063,
        0.017450552433729172,
        0.001707518589682877,
        -0.018116211518645287,
        -0.019023194909095764,
        -0.023748211562633514,
        -0.01942591741681099,
        0.017261603847146034,
        -0.05390701815485954,
        -0.0006598032778128982,
        -0.005646999925374985,
        0.028619414195418358,
        0.04577140510082245,
        0.02263251692056656,
        0.018570715561509132,
        0.008153151720762253,
        -0.02657746709883213,
        -0.008624211885035038,
        0.0014247972285375,
        0.029914850369095802,
        -0.023359283804893494,
        -0.012227246537804604,
        0.029497699812054634,
        0.032079827040433884,
        0.024252187460660934,
        -0.022118184715509415,
        -0.011775107122957706,
        0.016467569395899773,
        0.048630040138959885,
        -0.01516309566795826,
        0.029545815661549568,
        -0.026672478765249252,
        0.01636921428143978,
        -0.004807198885828257,
        0.017406266182661057,
        0.05051718279719353,
        -0.008759893476963043,
        0.030972788110375404,
        0.010037568397819996,
        0.028551803901791573,
        0.03257141634821892,
        -0.010103660635650158,
        0.026245901361107826,
        0.00026727680233307183,
        0.01951560191810131,
        -0.00820271484553814,
        -0.015567651018500328,
        0.05710139498114586,
        0.01679408550262451,
        -0.010582705028355122,
        -0.023528002202510834,
        0.02599211037158966,
        -0.022334786131978035,
        -0.05955437198281288,
        0.018527332693338394,
        -0.023962529376149178,
        0.011516467668116093,
        -0.022732052952051163,
        -0.005942750256508589,
        0.013686483725905418,
        -0.024723919108510017,
        -0.009182814508676529,
        -0.01433600578457117,
        -0.02831326797604561,
        -0.0035873379092663527,
        0.01388123445212841,
        -0.036798473447561264,
        -0.05206462740898132,
        -0.005181967746466398,
        -0.020756198093295097,
        0.05412493273615837,
        -0.01184375211596489,
        0.016595061868429184,
        0.007716941647231579,
        -0.001075300737284124,
        0.022815052419900894,
        -0.03783387690782547,
        0.014687860384583473,
        -0.010777096264064312,
        -0.03358461335301399,
        0.008407617919147015,
        -0.004378246143460274,
        0.009068259038031101,
        0.010751573368906975,
        0.02190215513110161,
        0.004140986129641533,
        -0.00774233927950263,
        -0.010585962794721127,
        -0.013131462037563324,
        -0.018810240551829338,
        -0.020291531458497047,
        0.01367135625332594,
        0.008858832530677319,
        0.026379287242889404,
        -0.0353219211101532,
        0.002089027315378189,
        -0.004800067748874426,
        -0.001991808647289872,
        0.01228940486907959,
        -0.010397792793810368,
        0.04030415788292885,
        -0.020135460421442986,
        0.021532246842980385,
        -0.028676016256213188,
        -0.017448319122195244,
        0.0026439984794706106,
        0.015917228534817696,
        -0.010995438322424889,
        -0.045259129256010056,
        -0.008909388445317745,
        0.02167181856930256,
        -0.003851010464131832,
        -0.04086820036172867,
        0.015355193056166172,
        0.017541956156492233,
        -0.00796143151819706,
        0.0331023633480072,
        -0.02253195457160473,
        -0.02240554615855217,
        0.029413025826215744,
        0.01903720013797283,
        -0.020185839384794235,
        0.024401118978857994,
        -0.001084266696125269,
        0.03235621377825737,
        -0.02190837636590004,
        0.04100169241428375,
        -0.010462179780006409,
        0.02852744795382023,
        -0.008618086576461792,
        0.005050706677138805,
        -0.05051359161734581,
        0.012592349201440811,
        -0.011060725897550583,
        0.0337202250957489,
        0.004235421307384968,
        -0.018653342500329018,
        -0.010934939607977867,
        -0.041027624160051346,
        -0.023274827748537064,
        -0.014315715990960598,
        0.010285740718245506,
        -0.023524370044469833,
        0.012782927602529526,
        0.03129667788743973,
        0.027687903493642807,
        -0.025753695517778397,
        -0.041406165808439255,
        -0.04289449006319046,
        0.036676548421382904,
        -0.03801008686423302,
        0.01692189835011959,
        -0.01260929275304079,
        -0.030743366107344627,
        -0.011715233325958252,
        0.0017342634964734316,
        0.007465648464858532,
        -0.004062656778842211,
        -0.006295176688581705,
        0.036276910454034805,
        -0.020013894885778427,
        -0.019470790401101112,
        0.018047437071800232,
        -0.0025215288624167442,
        -0.03192152455449104,
        -0.006399601697921753,
        0.028902001678943634,
        -0.022067377343773842,
        -0.02955777384340763,
        0.04489488527178764,
        0.011385911144316196,
        -0.010007559321820736,
        -0.013390854001045227,
        0.024692729115486145,
        -0.002500093076378107,
        -0.009922115132212639,
        0.00785923283547163,
        -0.021881086751818657,
        -0.01743229851126671,
        -0.036342307925224304,
        0.03998479247093201,
        0.015961412340402603,
        0.014703361317515373,
        -0.00016946301911957562,
        -0.002147521125152707,
        0.03504161909222603,
        -0.01836984232068062,
        -0.023919889703392982,
        -0.020523415878415108,
        0.02566930651664734,
        0.01536890584975481,
        0.004919938277453184,
        0.01795882172882557,
        0.07350613921880722,
        -0.025047270581126213,
        -0.035443954169750214,
        0.006590715143829584,
        0.010317417792975903,
        -0.044678568840026855,
        -0.01150516327470541,
        0.005232865922152996,
        -0.0016596869099885225,
        -0.019552942365407944,
        -0.023340916261076927,
        -0.029257087036967278,
        0.01937898062169552,
        0.01828138343989849,
        -0.0037316593807190657,
        0.0100615369156003,
        -0.027211949229240417,
        0.0286392979323864,
        0.0001864686782937497,
        0.007346822414547205,
        0.01828351803123951,
        0.0019075804157182574,
        -0.0068334490060806274,
        0.016888897866010666,
        0.003267052350565791,
        0.020780513063073158,
        0.0330539271235466,
        0.014665829949080944,
        -0.014957310631871223,
        -0.01638312079012394,
        -0.019814061000943184,
        0.005316494032740593,
        -0.0019623292610049248,
        0.0052957478910684586,
        0.06782379746437073,
        0.009813533164560795,
        0.0060989572666585445,
        0.009633591398596764,
        -0.015447070822119713,
        -0.04346675053238869,
        0.024180959910154343,
        -0.036564458161592484,
        -0.04190797731280327,
        -0.00840761512517929,
        0.02280985563993454,
        -0.020655740052461624,
        0.012596397660672665,
        -0.025265710428357124,
        0.04279765486717224,
        -0.00042591794044710696,
        -0.026014765724539757,
        -0.02713371440768242,
        0.0011279098689556122,
        -0.024439582601189613,
        0.0017833149759098887,
        -0.027102530002593994,
        -0.005916138645261526,
        0.00906291138380766,
        -0.006097210571169853,
        -0.011724097654223442,
        0.0125657357275486,
        -0.04486481472849846,
        0.014758366160094738,
        0.031922973692417145,
        -0.019037675112485886,
        -0.00025600750814191997,
        -0.016543373465538025,
        0.023429781198501587,
        -0.014475926756858826,
        -0.044802527874708176,
        -0.010950139723718166,
        -0.003359920810908079,
        -0.00234971079044044,
        0.01337270624935627,
        -0.005176173057407141,
        0.002884512534365058,
        0.023353585973381996,
        -0.042228274047374725,
        -0.025130826979875565,
        -0.010477658361196518,
        0.01907895877957344,
        -0.051870666444301605,
        0.008599438704550266,
        0.0185520239174366,
        0.0186841432005167,
        -0.0022334824316203594,
        0.02267901413142681,
        0.04126541689038277,
        0.008830166421830654,
        -0.027114029973745346,
        -0.01187125500291586,
        0.024687113240361214,
        0.016098415479063988,
        -0.004250689409673214,
        -0.002296178136020899,
        0.013363213278353214,
        0.018725784495472908,
        -0.00437466474249959,
        -0.03329245001077652,
        -0.0024443576112389565,
        0.014728277921676636,
        0.01981392502784729,
        -0.0012330394238233566,
        0.019090408459305763,
        -0.009965682402253151,
        -0.019654855132102966,
        0.006629875861108303,
        0.007808066438883543,
        -0.020791159942746162,
        -0.03468908369541168,
        -0.005247245542705059,
        -0.021010978147387505,
        0.014344005845487118,
        0.009430458769202232,
        -0.004456313792616129,
        -0.05312473326921463,
        -0.00779586099088192,
        -0.019182851538062096,
        0.011204943060874939,
        -0.02805992402136326,
        -0.003171783871948719,
        0.049835361540317535,
        0.001765994937159121,
        0.024093547835946083,
        -0.01502738893032074,
        0.033354032784700394,
        0.018276812508702278,
        0.0028047964442521334,
        -0.004968992434442043,
        0.011380484327673912,
        -0.0033623625058680773,
        0.0321357399225235,
        0.005603615660220385,
        -0.05089985206723213,
        0.011798523366451263,
        -0.01799456775188446,
        -0.01727762073278427,
        -0.01731504686176777,
        -0.03591272607445717,
        0.015714647248387337,
        0.00914708897471428,
        -0.011831087060272694,
        0.002845434006303549,
        0.007650112733244896,
        -0.016575926914811134,
        -0.032533369958400726,
        0.00026641302974894643,
        0.03195600584149361,
        -0.023590819910168648,
        -0.031428370624780655,
        0.008785644546151161,
        0.015317265875637531,
        -0.007884759455919266,
        -0.014488883316516876,
        0.017071200534701347,
        -0.004317002836614847,
        0.007279346231371164,
        -0.007670185994356871,
        0.015097130089998245,
        -0.0010448625544086099,
        -0.004464150406420231,
        0.02076590061187744,
        -0.019353287294507027,
        0.01058107241988182,
        -0.001976119354367256,
        -0.019040917977690697,
        0.031234048306941986,
        0.018974032253026962,
        -0.01726408302783966,
        0.0022490955889225006,
        -0.01740727201104164,
        0.005247861612588167,
        0.045682501047849655,
        -0.02052447944879532,
        0.018955379724502563,
        -0.03992459550499916,
        -0.009189712814986706,
        0.019635053351521492,
        0.00960414856672287,
        -0.025061795487999916,
        0.033478230237960815,
        0.02367415279150009,
        0.029569482430815697,
        -0.013883032836019993,
        0.012045696377754211,
        -0.010595077648758888,
        0.03534131869673729,
        0.006489383522421122,
        -0.010846566408872604,
        0.02601868286728859,
        -0.0025031862314790487,
        0.018845880404114723,
        -0.006877760402858257,
        0.003719355445355177,
        0.05662095174193382,
        -0.011565500870347023,
        -0.0008478404488414526,
        0.023081405088305473,
        -0.023450147360563278,
        -0.010967034846544266,
        -0.019647790119051933,
        0.014123929664492607,
        0.01895829290151596,
        0.0023690136149525642,
        -0.02526557631790638,
        0.020027903839945793,
        0.021801091730594635,
        -0.00685051828622818,
        0.006572703830897808,
        -0.010190910659730434,
        -0.014963294379413128,
        0.006028044503182173,
        0.0289868526160717,
        0.010744834318757057,
        -0.015424048528075218,
        -0.026473907753825188,
        -0.0015803752467036247,
        -0.005070872604846954,
        -0.024418946355581284,
        0.009755375795066357,
        0.008448140695691109,
        0.03155627101659775,
        0.013924608007073402,
        -0.009492505341768265,
        0.0064924792386591434,
        0.04865102842450142,
        0.012850206345319748,
        -0.01977728307247162,
        0.0031692569609731436,
        -0.027703488245606422,
        -0.0072283511981368065,
        0.04537387937307358,
        0.030761493369936943,
        -0.03661409020423889,
        -0.008204992860555649,
        0.005369758233428001,
        0.02161029353737831,
        -0.034323763102293015,
        -0.0047723217867314816
      ],
      "title": "Propuesta de Agenda Nacional de la Inteligencia Artificial para México 2024-2030"
    },
    {
      "id": "gai-esp_corpus-item002",
      "count": 8,
      "created": "2025-07-06T05:47:23.587508",
      "text": "Conversando con una computadora: ¿Cómo entienden las inteligencias artificiales lo que les pedimos? La evolución humana ha supuesto cambios no solo en lo que podemos hacer, sino en cómo podemos hacer. Más precisamente, la necesidad de eficientizar el trabajo ha dictado una aceleración exponencial en la tecnología; no es ninguna sorpresa ver la enorme cantidad de inventos y descubrimientos que han surgido a partir del siglo XIX, especialmente cuando los comparamos con los siglos anteriores (Gregersen, 2020). El sueño humano de la máquina que se mueve por sí sola es sumamente antiguo, con Herón de Alejandría no sólo ideando autómatas ya en la primera mitad del siglo I, sino habiendo documentado la existencia de otros ingenios similares que le precedieron (Ceccarelli, 2007): la prevalencia del término autómata siglos antes de las primeras computadoras mecánicas comprueba el latente anhelo de la humanidad por una máquina sirviente (Hockstein et al., 2007). La forma en que las inteligencias artificiales actuales están cambiando la forma en que los humanos interactúan con la información, con el conocimiento acumulado de la especie, pero, como se explorará a lo largo de este artículo, enseñarle a una máquina a \"hablar\", a\"entender\", podría ser un proceso mucho más introspectivo de lo que parece pues al menos por el momento, nuestras creaciones no pueden superarnos en algo que nosotros mismos no entendemos del todo como lo es el lenguaje: desde la psicología cognitiva recurriendo al modelo computacional para el proceso de la información, hasta los modelos lingüísticos de inteligencia artificial, el camino por lograr que una máquina hable y piense está inesperadamente ligado al esfuerzo por entender en cómo el humano mismo habla y piensa. Hoy más que nunca el término \"inteligencia artificial\" está llevando a la humanidad a cuestionarse cuánto realmente sabemos sobre nosotros mismos: ¿qué significa \"significado\"? ¿cuál es el significado de \"crear\"? A final de cuentas, por más impresionantes que parezcan las inteligencias artificiales, por ahora no son sino un paralelo de lo que sabemos sobre nosotros mismos: mientras no puede negarse la velocidad a la que una computadora puede realizar cálculos o comparar la memoria humana con la enorme cantidad de información a la que los modelos lingüísticos como GPT-3 tienen acceso, los procesos que realizan estas inteligencias artificiales para entender el lenguaje humano son en realidad imitaciones bastante burdas aun de la forma en la que opera el cerebro humano. Pero tampoco podemos negar el potencial que tienen las inteligencias artificiales de ayudarnos a comprender más sobre la forma en que nuestra propia mente funciona. Breve historia de la comunicación humano-máquina La evolución del cerebro humano le permitió realizar acciones cada vez más y más complejas, sin embargo, no puede negarse que fue la evolución del lenguaje lo que verdaderamente permitió a nuestros ancestros pasar del uso de herramientas para realizar trabajos y actividades que les permitían mantenerse con vida a la verdadera labor humana de comunicar, registrar y planear (Bickerton, 2009; Boeckx & Benítez-Burraco, 2014). A partir de ese momento, la sapiencia humana se dedicaría a buscar formas de hacer más con menos y en menos tiempo. Sin embargo, para 1770, año en que el escocés James Watt inventaba la máquina de vapor (Pennock, 2007), ese menos implicaba también menos humanos. Pero tan eficientes como podían ser las máquinas, aun no podía removerse del todo el factor humano: era necesario realizar ajustes al proceso, aun se necesitaba reparar o modificar las máquinas para lo cual era necesario a alguien que entendiera cómo funcionaba la máquina y pudiera adaptarla a las necesidades de la situación. Dicho de otra forma: la comunicación con las máquinas se había vuelto el nuevo problema a superar. En 1725, Basile Bouchon inventaría lo que se considera la primera máquina semiautomatizada al utilizar tarjetas perforadas para controlar una máquina tejedora. El principio de las tarjetas perforadas seguiría en uso por más de 100 años gracias a Herman Hollerith, fundador de IBM, quien las ligara a aplicaciones de computación y almacenamiento de información (Kaur et al., 2014). Justamente, la necesidad de procesar y almacenar información (más precisamente de computarla) dirigiría los esfuerzos por lograr y mejorar la comunicación humano-máquina. El siguiente gran paso en los esfuerzos por homologar el lenguaje de las máquinas con el lenguaje humano llegó durante la década de los cuarenta (del siglo XX), cuando la Segunda Guerra Mundial exigió una evolución en la forma en la que podía ordenársele a las nuevas máquinas de guerra: atrás habían quedado los tiempos en los que las piezas de artillería podían ser apuntadas por un pequeño equipo de hombres, pues las nuevas armas navales podían disparar mucho más allá del horizonte observable y golpear con precisión a un buque en movimiento. Lo único que se necesitaba era una forma de decirle a las armas qué hacer y cuándo hacerlo. Para esto se construyeron computadoras electromecánicas, máquinas con cientos de engranes y poleas que le permitían a los usuarios humanos comunicarle al sistema de armas la información del mundo real que la máquina entonces computaría y traduciría en las angulaciones necesarias de las baterías (Bureau of Ordnance, 1949). No pasaría mucho tiempo, sin embargo, para que los avances tecnológicos produjeran las primeras computadoras modernas y, a partir de ese momento, las computadoras han impulsado a la humanidad de formas cada vez más complejas y en campos cada vez más variados (Janssen et al., 2019): desde las tareas de comunicación, pasando por la automatización de las líneas de producción, hasta diagnóstico médico con ayuda de inteligencia artificial (Bi et al., 2019). No hay duda de lo que las computadoras han ayudado a la humanidad a lograr pero, aun hay un aspecto en la corta historia de la computación moderna que ha visto poco avance: la comunicación humano-máquina. Los lenguajes de programación Los lenguajes de programación surgieron para establecer la comunicación humano-máquina con las entonces nuevas computadoras digitales, pues éstas ya no tenían perillas o palancas mediante las cuales introducirles información y, si bien el lenguaje binario comparte genealogía con las tarjetas perforadas[^1], las computadoras digitales interpretaban y procesaban información mediante el lenguaje binario, es decir, en unos y ceros. El claro ejemplo de esta problemática fue la computadora BINAC, creada en 1949 por la compañía Echert-Mauchly, cuyos programadores eran aun matemáticos y físicos puros a los cuales se recurría por su dominio sobre expresiones lógicas. Al enfrentarse al problema del almacenamiento de la información y la necesidad de comunicarse con un dispositivo completamente digital, estos primeros programadores decidieron utilizar octal[^2] para \"abreviar\" los comandos en binario que la computadora podía entender (Murray Hopper, 1981). La necesidad de establecer estándares vanguardistas, acelerada por la nueva organización del mundo tras la Segunda Guerra Mundial, daría lugar a los primeros programas computacionales; fue entonces que, mientras trabajaban en la BINAC, Grace Murray Hopper y su equipo comenzarían a establecer una serie de códigos que sobrepasaban el sistema algebraico que la BINAC utilizaba: ya no se introducían operaciones algebraicas, sino una serie de comandos que la computadora podía emparejar con las operaciones lógicas que ésta \"conocía\" (Murray Hopper, 1981). En la década de 1950 surgen las primeras menciones de \"programación automática\", término que en ese entonces se utilizaba para referirse al uso de mnemónicos, una forma en la que computadora y humano podían comunicarse mediante un lenguaje intermedio: no se usaban literalmente ceros y unos, ni tampoco era necesario compilar las operaciones básicas cada vez que se creaba un programa, sino que podían recurrirse a palabras como \"SUM\" que la computadora entonces interpretaba como la operación matemática de adición. Los mnemónicos eran un lenguaje intermedio, pues no se estaba utilizando un lenguaje propiamente humano, aún tenía que prepararse la memoria de la computadora con aquellos procesos y operaciones lógicas que cada mnemónico habría de invocar además de que se tenía que entrenar a los operadores para sobre el inventario de mnemónicos que la computadora podía entender (Sammet & Holberton, 1981). Estos lenguajes de programación primitivos funcionaban bien para tareas como la computación de datos y cálculos matemáticos, pero conforme la tecnología avanzaba y las computadoras se volvían más y más potentes, surgía la necesidad de estandarizar los lenguajes de programación: se perdía mucho tiempo y dinero cada que una nueva computadora se ponía en operación, pues la mejora en la tecnología implicaba necesariamente el cambio en su arquitectura y el establecimiento de un nuevo lenguaje ensamblador[^3]. Entonces, aquellos programadores tempranos se propusieron crear una especie de lingua franca para la comunicación humano-máquina, un lenguaje que pudiera ser utilizado en la mayor cantidad de computadoras posibles sin importar su fabricante y que además fuera fácil de enseñar y aprender para los humanos que usarían dichas máquinas (Sammet & Holberton, 1981); comenzaba la historia de los lenguajes de programación modernos. Desde la programación orientada a objetos hasta las aplicaciones del internet de las cosas[^4], los lenguajes de programación han ido cambiando junto con las computadoras, por mencionar algunos ejemplos[^5]: FORTRAN en 1954, ALGOL en 1958, COBOL en 1959, BASIC en 1964, Pascal en 1970, C en 1972, Java en 1995, Python en 1991 y C++ en 1998. Pero el avance de los lenguajes de programación se ha encontrado con una disyuntiva: un lenguaje de programación con el que es fácil escribir un programa, suele ser difícil de leer. Por ejemplo, crear un programa que pueda realizar cálculos con números complejos puede ser muy complicado si se utiliza un lenguaje que no esté específicamente destinado para realizar cálculos de ese tipo; tal es el caso de C++, que requeriría que el usuario \"extendiera\" el lenguaje para, lo que a su vez podría dificultar que otra persona pudiese entender el código a primera vista (Leendert, 1991). En otras palabras, lejos de lo que aquellos primeros programadores imaginaban, los lenguajes de programación actuales no están mucho más cerca de permitir a los humanos comunicarse con las computadoras utilizando un lenguaje natural. Además, la verdadera dificultad de hacer que una computadora entienda lo que un humano dice está en el hecho de que aún no entendemos completamente la forma en que el lenguaje humano funciona, pues el mismo Alan Turing decía en 1951: \"las computadoras no son sino una imitación del cerebro humano\" (Copeland, 2004). Curiosamente, para proponer un esquema sobre la forma en que el cerebro humano procesa, almacena y compara la información que recibe del mundo, la psicología cognitiva se apoyaría en los conceptos que los primeros programadores dedujeron sobre el proceso de la información aun cuando la psicología cognitiva había surgido antes de la primera computadora digital (Leahey, 2003). No es extraño entonces que los programas computacionales sean imitaciones de la forma en que el cerebro humano procesa la información para solucionar un problema, pues los humanos solemos establecer (muchas veces de manera inconsciente) una serie de pasos para realizar prácticamente cualquier tarea por cotidiana o extraordinaria que parezca: construimos algoritmos que dan solución a nuestros problemas. En ese sentido, un algoritmo es un conjunto de pasos o procedimientos que nos permiten alcanzar un resultado o resolver un problema (Cairó Battistutti, 2005), y esa es justamente la forma en que está construido o escrito un programa de computadora. Inteligencia artificial y redes neurales La búsqueda de la inteligencia artificial propiamente dicha no es tan moderna como se puede creer: en el siglo XVII, Thomas Hobbes proponía que \"los pensamientos no son expresables en lenguaje escrito o hablado, sino en una dimensión interna\" y que, por lo tanto, las operaciones lógicas que implica el raciocinio no están limitadas a las matemáticas, sino que son aplicadas a todo aquello que el individuo conoce (Haugeland, 1989). Alan Turing se basaría en ese concepto para responder la pregunta \"¿puede una computadora pensar?\", pregunta que lo llevaría a establecer el Test de Turing entre 1951 y 1952[^6] para poder discernir si una computadora es capaz de pensar por sí misma. Pero Turing no pretendió en ningún momento definir el pensamiento, mucho menos la mente, simplemente establecer criterios que pudieran diferenciar el verdadero raciocinio de la \"simple\" computación de información (Copeland, 2004). Es aquí donde surge el primer punto a esclarecer: la inteligencia artificial actual no está ni cerca de la verdadera inteligencia, pues el pensamiento lógico-verbal, la solución de problemas como se plantea en la definición del algoritmo, no representa el pensamiento humano completamente[^7]. Pero no por esto debe restársele valor a los esfuerzos conseguidos hasta ahora: en su estado actual, el concepto de inteligencia artificial se refiere a un programa computacional que recurre a redes neurales para aprender y procesar información. Las redes neurales están basadas en la forma en que las neuronas del cerebro humano se comunican entre sí para dar lugar a múltiples procesos cognitivos (Copeland, 2004). Cada \"neurona\" artificial está compuesta por una capa de input, una serie de capas ocultas, y una capa de output, esto quiere decir que cada capa recibe información que procesa según un sub-algoritmo que le dice qué hacer con esa información para después pasarla a la siguiente capa, eventualmente, la \"neurona\" completa el ciclo a lo largo de sus capas y pasa la información que ha procesado a la siguiente neurona. El cómo y cuándo la información pasa de neurona a neurona depende, desde luego, de la programación de la red neural: cada conexión entre neuronas tiene un weight o parámetro, un valor numérico que se establece durante el entrenamiento de la red neural que controla qué tanto el output o producción de una neurona afectará el resultado final (IBM, 2021). Las redes neurales son el elemento clave de conceptos como machine learning, deep learning y desde luego inteligencia artificial. Pero a diferencia de un cerebro humano, el cual continuamente está procesando la información que percibe del exterior, comparándola con la información que tiene en los distintos niveles de memoria y realizando una enorme variedad de juicios y consideraciones para aprender (Leontiev et al., 2004), las redes neurales dependen de los programadores para decirles qué hacer con la información que reciben: los antes mencionados weights, si bien pueden ser aleatorios durante las primeras iteraciones de la red neural, eventualmente requieren que los programadores los ajusten para obtener resultados consistentes de la red neural (T. Brown et al., 2020; IBM, 2021; Kingma et al., 2021). Una vez que el modelo comienza a generar outputs satisfactorios, los programadores pueden modificar ciertas partes de la red neural para que éste realice distintas acciones, esto es lo que hace la diferencia entre un algoritmo de red neural y el verdadero deep learning. Este término suele utilizarse, junto con machine learning, de manera intercambiable con inteligencia artificial, pero la acepción general es que una red neural con tres o más capas puede considerarse un algoritmo de deep learning, pues la palabra \"deep\" se refiere justamente a que el algoritmo tiene un nivel oculto en su red neural, la parte intermedia entre la parte de la red que únicamente prepara la información, la capa de input, y la parte que prepara la información para devolverla al usuario, la capa de output (IBM, 2021). A su vez, el término machine learning suele utilizarse para describir algoritmos de red neural que requieren una intervención más directa por parte de los humanos: mientras que un algoritmo deep learning tiene la capacidad de aprender, el machine learning no \"aprende\" a menos que sus desarrolladores explícitamente vuelvan a iniciar el proceso de entrenamiento, es decir, el deep learning es un paso más cerca hacia la \"verdadera\" inteligencia artificial (IBM, 2020). Inteligencia artificial y lenguaje humano Una vez que se tiene la idea general del funcionamiento de las redes neurales es más sencillo apreciar cuán lejos estamos de crear una verdadera inteligencia artificial[^8]: los asistentes virtuales (Siri o Alexa) e incluso los chatbots que tanto revuelo han causado últimamente (ChatGPT o Bing Chat), están aún muy lejos de una verdadera inteligencia (IBM, 2020). Hemos hablado de Thomas Hobbes y Alan Turing proponiendo lo que una máquina inteligente tendría que ser capaz de hacer, y a partir de esas propuestas, actualmente se consideran tres tipos de inteligencia artificial (Goertzel, 2014; IBM, 2020): Artificial Narrow Intelligence, ANI: sistemas que realizan comportamientos \"inteligentes\" en contextos muy específicos, es decir, pueden llegar a aparentar que se está tratando con un humano real en tanto no se sobrepase su configuración. El estado actual de las inteligencias artificiales se encuentra aún en este nivel. Artificial General Intelligence, AGI: en este nivel se encontrarían sistemas capaces de realizar una gran variedad de tareas para lograr objetivos en distintos contextos y ambientes, en otras palabras, una AGI podría anticiparse y reaccionar a situaciones y problemas que sus creadores no habrían considerado al momento de su programación inicial. Una AGI tendría ya un cierto nivel de conciencia, pues podría recurrir a sus experiencias para razonar un plan de acción que dé solución a una situación a la que esta inteligencia se encontrara. A manera de ejemplo, ya que no hay ningún sistema actualmente que esté siquiera cerca de este nivel, pueden nombrarse algunas inteligencias artificiales de la ficción: los robots en \"Yo robot\" de Asimov, GladOS de la franquicia de videojuegos \"Portal\" y HAL9000 de la película \"2001: odisea del espacio\". Artificial Super Intelligence, ASI: si bien las AGI son teóricamente posibles, las ASI tendrían que superar la sapiencia humana. Desde luego los únicos ejemplos provienen de obras de ficción: La IA de la franquicia de películas \"The Matrix\" y Skynet de la franquicia de películas \"Terminator\". Tanto las AGI como las ASI se consideran \"inteligencias artificiales fuertes\" (IBM, 2020) y, si bien algunos autores consideran que actualmente estamos en el puente entre las ANI y las AGI, la principal limitante es bastante burda: No entendemos cómo funciona la mente humana, no podemos ni siquiera señalar a una parte del cerebro humano y declarar \"aquí está la conciencia\", por lo tanto, es irreal pretender que pudiésemos imitarla (Goertzel, 2014). Los avances actuales en IA no se han logrado por accidente, como se ha venido planteando a lo largo de este artículo, todo ha sido un largo camino y sería obtuso pretender que el siguiente paso en el desarrollo de la IA sucedería por accidente. Pero entonces, si las IA no aprenden como los humanos y aun necesitan que sus programadores guíen ese aprendizaje, ¿cómo entienden las IA como ChatGPT, Dall-E o Stable Diffusion lo que les pedimos? Y realmente, los modelos de IA disponibles para el público al momento de escribir este artículo logran interpretar el tan elusivo \"lenguaje humano\" bastante bien. ChatGPT[^9], por ejemplo, es una \"IA conversacional que utiliza NPL[^10] para generar respuestas parecidas a las que daría un humano (real)\" (T. B. Brown et al., 2020). Esto quiere decir que ChatGPT utiliza una serie de redes neurales para entender y generar expresiones escritas: no es que ChatGPT entienda lo que le escribimos, al menos no en el sentido en el que un humano entiende. Cuando un humano observa una palabra escrita en su lengua materna, se dispara un complejo mecanismo cognitivo en su cerebro (pensamiento) que de forma simultánea recupera la pronunciación de dicha palabra (símbolo) y, particularmente, todo aquello que la persona relaciona con esa palabra (referente), producto de su aprendizaje, experiencia e ideología. Este proceso cognitivo tan complejo ha sido replicado, desde luego en una escala mucho menor, en la red neural que ordena a la IA en cuestión: primero se tiene que diseñar un algoritmo con la serie de pasos que la IA tendría que seguir al encontrarse con una producción escrita, ese algoritmo entonces involucra su respectiva red neural en la cual se han de asignar los parámetros o weights. Evidentemente esto es más complicado de lo que parece, pues aun siendo una recreación bastante simple del proceso cognitivo que toma lugar en el cerebro humano, el entrenamiento del GPT-3, el modelo en el cual se basa ChatGPT[^11], tomó varios días ininterrumpidos de GPUs[^12] procesando información de entrenamiento. Ahora bien, ¿qué significa \"entrenamiento\" en el contexto de las inteligencias artificiales? El entrenamiento es, literalmente, el proceso mediante el que los programadores de un modelo de IA le enseñan a las redes neurales a procesar la información, pero sobre todo a establecer una diferencia entre los resultados (outputs) deseables de aquellos considerados errores (Radford et al., 2021). Lo que realmente hace único al modelo GPT-3 es la enorme cantidad de parámetros que posee en su red neural: cerca de 175 mil millones de parámetros (T. B. Brown et al., 2020). Como se ha mencionado anteriormente, al comienzo del entrenamiento la red neural comienza con parámetros aleatorios, derivados de los algoritmos particulares de cada modelo y, según las necesidades u objetivos de los desarrolladores, nuevos parámetros se van añadiendo o se van modificando los existentes. Modelos de IA como ChatGPT, DALL-E o Stable Diffusion[^13] están causando mucho revuelo al momento de escribir este artículo porque no sólo entienden lo que sus usuarios les piden, sino que pueden predecir y aprender sin necesidad de que sus programadores intervengan. Los modelos lingüísticos como ChatGPT, por ejemplo, fueron entrenados oponiendo conocimiento \"real\" con muestras de lenguaje que los programadores utilizaron para \"enseñarle\" a analizar construcciones escritas: una vez que la red neural logró entender esas construcciones muestra, se fueron añadiendo más capas o modificando las existentes[^14] (T. B. Brown et al., 2020; Vaswani et al., 2017), de tal forma que los chatbots que están actualmente a la vanguardia pueden hacer mucho más que los bots tradicionales: las redes sociales y los proveedores de correo electrónico llevan varios años utilizando bots[^15] para detectar spam, traducir mensajes e incluso detectar mensajes radicales u ofensivos, mientras que chatbots como ChatGPT o Bing Chat pueden identificar el contexto, las ideas claves e incluso detectar jerga o palabras características de un corpus particular (Kublik & Saboo, 2022). Lo que hace la diferencia entre los bots de detección de spam y los chatbots antes mencionados son los transformers, un tipo de red neural propuesto por investigadores de la universidad de Toronto (Kublik & Saboo, 2022) que, habiendo aprendido a identificar las funciones gramaticales de las palabras en distintas muestras de lenguaje durante su entrenamiento, se le ha programado para aplicar lo aprendido en nuevas muestras, que en otras palabras significa que estas redes neurales pueden aplicar lo que sus desarrolladores les han enseñado, mediante horas y horas de ensayo y error, para analizar producciones escritas completamente nuevas; es así como los modelos lingüísticos no solo \"entienden\" lo que se les pide sino que también pueden producir respuestas a partir de esa expresión inicial con base en los datos duros a los que tiene acceso además de lo que aprendió durante la fase de entrenamiento (T. B. Brown et al., 2020; Douglas Heaven, 2020). Para aclarar un poco más este proceso obsérvese la Figura 7, donde la flecha azul representa la forma en que el transformer le permite a la IA comparar lo que sabe sobre la palabra \"El\" y compararla con el resto de las palabras en una secuencia. En la figura antes mencionada se ha obviado que cada palabra de la oración pasa por el mismo proceso que las primeras dos: los transformers, las redes neurales que como se dijo anteriormente son características de los modelos lingüísticos, procesan las palabras de una producción escrita de manera simultánea, lo que les evita la necesidad de utilizar memoria física para guardar el texto completo durante todos los pasos el proceso y además, evita la interferencia de este durante los procesos intermedios. Esto es lo que caracteriza a los modelos lingüísticos que forman el núcleo de chatbots como ChatGPT o Bing Chat, pues al poder analizar los componentes de un texto dado de manera simultánea pueden entonces aplicar una fórmula matemática para calcular las palabras con mayor probabilidad[^16] de aparecer en el texto, a partir de lo cual, pueden incluso predecir la continuación de este (Vaswani et al., 2017). Esto le permite a ChatGPT, por ejemplo, producir una respuesta aceptable pese a no tener conocimiento sobre lo que el usuario le ha preguntado o solicitado; esto, combinado con la masiva red neural que compone el GPT-3, hace que ChatGPT siempre tenga una respuesta \"válida\". Para explorar la capacidad de atención y predicción de ChatGPT se realizaron algunos experimentos simples (ver figura 8): para provocar una respuesta incoherente o extraña, se le presentó a ChatGPT una frase en español, lengua que ChatGPT puede \"entender\" mediante machine translation, es decir, la IA traduce la frase que le introducimos (\"a mí me gusta el tangananá\") mediante el proceso de análisis antes descrito, y logra predecir el significado de la frase e incluso generar una respuesta escrita en español; sin embargo, como puede apreciarse en la figura, la IA no tiene forma de saber qué significa \"tangananá\". Continuando con el experimento se introdujo la frase \"Pese a la negativa de prensa covfefe\" (ver figura 9), una traducción al español de un tweet publicado por Donald Trump que de inmediato se volvió viral por su carencia de sentido. En este caso, si bien \"covfefe\" no tiene significado alguno se esperaba que, por la viralidad del evento, ChatGPT tuviera un registro en su memoria sobre el mismo, de tal forma que la IA pudiera entender el contexto de la frase introducida. Como puede apreciarse en la respuesta generada por el chatbot, éste no entiende la frase, pero logra identificar la palabra \"covfefe\" y ligarla a información dura en su memoria para dar una respuesta coherente. Estas dos pruebas, si bien simples, sirven para mostrar lo que los desarrolladores han denominado un \"motor de atención\": una red neural con parámetros y capas que le permiten a la IA no solo identificar el contexto de una producción y compararlo con la información \"dura\" que tienen en su memoria, sino a identificar las palabras clave de una construcción, lo que le permite predecir palabras afines mediante un análisis sintáctico único, pues a diferencia de los humanos, la IA no entiende realmente lo que es un verbo o un adjetivo, sino que los compara con valores (scores) que le ha asignado a los componentes de las oraciones usadas durante el periodo de prueba, que en otras palabras significa que la IA identifica la función gramatical de una palabra dependiendo su posición en el texto y comparándola con lo que aprendió durante la fase de entrenamiento (Kublik & Saboo, 2022; Singh, 2023; Vaswani et al., 2017). El modelo sucesor de GPT-3, GPT-4, se puso al alcance del público el 14 de marzo de 2023. En el reporte oficial no hay una mención clara de lo que hace distintos a GPT-3 de GPT-4, pero se alude a que se han agregado más parámetros (weights), añadiendo varias capas a la red neural. Además, de acuerdo con OpenAI[^17] (OpenAI, 2023b), GPT-4 ha sido entrenado directamente con textos referentes a exámenes y cursos estandarizados de una gran variedad de ramas, algunas de las cuales incluyen: SAT Math, Medical Knowledge Self-Assessment Program, AP Art History, AP Biology, AP Chemistry, AP Language and Composition, AP Macro and Microeconomics, Advanced Sommelier, AP Psychology y AP Statistics. GPT-4 ha logrado obtener puntajes por encima del promedio humano en casi todas las pruebas y exámenes relativos a estos campos. A diferencia de GPT-3, GPT-4 posee una cantidad masiva de información que ha estudiado extensivamente durante horas y horas de entrenamiento (OpenAI, 2023b). Pero más impresionante aun es la capacidad de GPT-4 de \"entender\" imágenes, describirlas, predecir contenido relativo a dichas e incluso producir contenido específico a una rama del conocimiento (véase figura 10). El potencial de este nuevo modelo lingüístico todavía está por verse[^18] y no cabe duda de que la competencia con Google y Microsoft impulsará la inteligencia artificial a niveles sorprendentes. Inteligencias artificiales de generación de imágenes a partir de texto El proceso semántico que realizan las inteligencias artificiales como GPT-3 está revolucionando la forma en que los humanos acceden y hacen uso de la información, pero hay también inteligencias artificiales que no sólo pueden interpretar texto, sino que además pueden generar imágenes a partir de ese texto. El principio es el mismo que con los modelos lingüísticos como GPT-3: el texto introducido por el usuario pasa por una red neural con distintos parámetros y genera un output de vuelta al usuario, sin embargo, en este caso el output ha de ser una imagen, por lo que hay una serie de pasos extras bastante sustanciales. Hazañas como la de GPT-4 siendo capaz de extraer información de una fotografía de un dibujo en una servilleta y generar un output sumamente específico a partir de lo que logra predecir de dicha información son sólo una muestra de lo que inteligencias artificiales de generación de imágenes a partir de texto pueden hacer. Actualmente hay dos modelos generativos que han cautivado al mundo: DALL-E y Stable Diffusion, ambos con claras diferencias en su diseño. Comenzaremos por describir la forma en que DALL-E funciona por tratarse de un modelo lingüístico parecido a GPT-3 que ya ha sido explorado anteriormente en este artículo. El primer problema al momento de conectar lenguaje con imágenes es, como sugiere la figura 6, el siguiente paso en la arquitectura de los transformers, la arquitectura de red neural que caracteriza a los modelos lingüísticos. En otras palabras, GPT-3 es muy bueno para identificar, generar y predecir lenguaje escrito, pero no puede ni generar imágenes ni obtener información de imágenes. Ni siquiera GPT-4 que puede \"leer\" imágenes logra completar esta tarea tan bien como lo haría un modelo expresamente diseñado para esta tarea (Goodfellow et al., 2014; Jay Wang, 2021). Así como los modelos lingüísticos deben ser entrenados para interpretar texto, DALL-E tuvo que ser entrenado para interpretar una imagen, a este proceso se le llama codificación. El problema es que, a diferencia de los humanos, una inteligencia artificial no asocia lo visual con lo lingüístico, sino que el lenguaje escrito y las imágenes suponen dos dimensiones completamente distintas: se necesita crear una nueva red neural que le permita a la IA \"traducir\" una imagen en una expresión lingüística a partir de la cual se pueda generar otra imagen, todo esto simplemente para la etapa de entrenamiento. La codificación de imágenes ya lleva varios años siendo utilizada por bots moderadores en redes sociales: se entrenó a las redes neurales poco profundas a detectar patrones de píxeles[^19] característicos de contenido sensible que la plataforma en cuestión decide rechazar por defecto. El problema, de manera similar a los bots de detección de spam y traducción, es que estas redes neurales no aprenden, no se adaptan y mucho menos entienden las implicaciones lingüísticas de aquello que analizan. Una de las principales propuestas que marcaría la evolución de las inteligencias artificiales de generación de texto serían los Visual Auto Encoders (VAE), redes neurales que convierten una imagen dada en información que la IA pueda analizar mediante transformers (Goodfellow et al., 2014; Van Den Oord et al., 2017). Los VAE generan lo que los desarrolladores denominan un \"espacio latente\", un punto intermedio entre la codificación y la decodificación; en este espacio latente el VAE recurre a un codebook, una especie de vocabulario que los desarrolladores programan en el VAE, de tal forma que éste tiene que asignar partes de la imagen inicial a categorías en ese codebook (véase figura 11). Es un proceso muy largo que consume una enorme cantidad de recursos y necesita una gran cantidad de GPUs trabajando en conjunto, pero se descubrieron dos ventajas principales (Van Den Oord et al., 2017): 1. Los VAE no necesitan decodificar la imagen input píxel por píxel sino en de 32 por 32 píxeles (tiles o azulejos) y, dependiendo de la capacidad de proceso disponible, se pueden usar múltiplos de esas dimensiones (64x64, 128x128, 256x256, etc.). 2. Se le pueden agregar capas extra al VAE que le permitan mejorar la calidad de la imagen antes de devolverla en el output final (véase figura 12). Es importante mencionar que DALL-E no utiliza un VAE de forma explícita, OpenAI no explica a detalle cómo funciona este modelo, pero se cree que recurre a un proceso similar durante su entrenamiento, pues OpenAI afirma que este recurre al GPT-3, lo que les permitió entrenar el modelo más rápido y establecer el proceso de decodificación como un proceso discreto (Razavi et al., 2019; Van Den Oord et al., 2017). En otras palabras, lo único que DALL-E tiene que hacer es asignarles categorías a los tiles resultantes de la decodificación de la imagen input[^20]. DALL-E no está disponible para el público, al menos no del todo, pues se trata más de una prueba de concepto que de un modelo con una verdadera aplicación como, digamos, GPT-3 o como se verá más adelante, Stable Diffusion. OpenAI ha reconocido que los resultados de DALL-E presentados en sus artículos y reportes de estado están específicamente seleccionados de entre cientos (potencialmente miles) de imágenes generadas carentes de sentido (Jay Wang, 2021), pues, aunque este modelo es capaz de generar imágenes con buena calidad, además de lograr interpretar indicaciones escritas que podrían considerarse imposibles o carentes de sentido (véase figura 13). Pero hay otro problema: si bien es relativamente sencillo obtener información con la cual entrenar y establecer la base de conocimiento en modelos lingüísticos como GPT-3, los modelos generativos de imágenes como DALL-E necesitan, desde luego, muchas imágenes con las cuales aprender. Más importante aún, cada imagen necesita ir acompañada de una descripción más o menos detallada para que la IA pueda aplicar su entrenamiento y obtener resultados consistentes. A los conjuntos de imágenes acompañadas de texto se les denomina datasets, y a lo largo de los años compañías como Microsoft, Amazon y Google han construido sus propios datasets[^21], los cuales han sido instrumentales en el entrenamiento de modelos como DALL-E. Como se dijo anteriormente, este entrenamiento ha sido mucho más lento y problemático que el de los modelos lingüísticos que no generan imágenes, pues aún cuando se logran ajustar los parámetros de un modelo de manera satisfactoria, no hay ninguna garantía de que el modelo mantenga su consistencia al exponerlo a un dataset nuevo ya que, a diferencia de los humanos, las inteligencias artificiales carecen de un motor cognitivo que enlace experiencias, conocimientos e ideologías con los estímulos del exterior (Luria, 1989), por lo que la IA puede llegar a realizar descripciones extrañas (véase figura 14). Greimas (1987) explicaba (en humanos, desde luego) con su propuesta de los ejes semánticos: el mecanismo semiótico no se da por adición y substracción, sino por una concatenación de lo que el sujeto asume o conoce. Curiosamente, la forma en que las inteligencias artificiales de generación de imágenes como DALL-E parecen realizar un proceso similar al propuesto por Hjelmslev que es más matemático (Bigot, 2010), aunque no hay menciones directas a Hjelmslev en la literatura referente a DALL-E, Stable Diffusion, VAEs o clasificadores, se asume que la aproximación hjelmsleviana se adapta mejor a las fórmulas probabilísticas que componen el motor lógico de las redes neurales de estas inteligencias artificiales. A finales de 2022, Stability AI publicó el modelo 1.5 de Stable Diffusion en la página github.com[^22]. Aunque Stable Diffusion es comúnmente conocido como un generador de imágenes a partir de texto, este modelo no utiliza un modelo lingüístico como lo hace DALL-E, en su lugar recurre a una combinación de distintos modelos como VAEs y CLIP[^23] para ejecutar la síntesis de imágenes y, sobre todo, Stable Diffusion recurre a un proceso que añade ruido a la imagen durante varios pasos (véase figura 15). Por esta razón este modelo no entiende realmente lo que sus usuarios le piden mediante la caja de indicaciones o prompts (véase figura 16) como lo haría DALL-E, pues incluso cuando Stable Diffusion recurre a VAEs[^24], el proceso de difusión inversa mediante el que este modelo genera imágenes no involucra procesos lingüísticos (Ho et al., 2020; Kingma et al., 2021; Nichol & Dhariwal, 2021; Song et al., 2020). Para compensar esto, Stability AI ha hecho públicos tanto los parámetros generales de la red neural como el checkpoint de su entrenamiento[^25]. Un checkpoint puede entonces tomarse como base para re-entrenar el modelo con un cierto tipo de imágenes (Rombach et al., 2021), creando a su vez un nuevo checkpoint sumamente eficaz para generar un cierto tipo de imagen, pero sólo ese tipo de imagen (véase figura 17). Stability AI considera que esto es el punto fuerte de su modelo, pues ha sido entrenado con un dataset con un fuerte enfoque en muestras de arte, desde pinturas e ilustraciones hasta modelos tridimensionales, lo que le brinda una gran versatilidad al modelo para generar \"imágenes hermosas\" (Stability AI, 2022). Esto ha causado una gran controversia por haberse comprobado que Stability AI entrenó su modelo con los trabajos de artistas digitales sin su consentimiento (Vincent, 2023), pero sobre todo ha traído una importante pregunta a la mesa: ¿puede una inteligencia artificial \"crear\" arte? Hoy más que nunca el término \"inteligencia artificial\" está llevando a la humanidad a cuestionarse cuánto sabemos realmente sobre nosotros, sobre lo que nos hace humanos: ¿qué significa \"significado\"? ¿cuál es el significado de \"crear\"? y, quizás más importante aún, ¿puede una computadora \"crear\"? Es fácil perderse en la sorprendente capacidad de modelos como DALL-E o Stable Diffusion para no sólo entender lenguaje natural sino además generar imágenes que responden a una descripción textual dada; pero la forma en que estos modelos están revolucionando nuestra realidad va más allá de si las inteligencias artificiales reemplazarán a los humanos en actividades como programación o incluso ilustración: ¿podrían las inteligencias artificiales ayudarnos a entender nuestra propia mente? Así como muchos artistas, con justa razón, se han motivado a emprender acciones legales contra modelos que han sido entrenados explícitamente para replicar su estilo, a muchos otros les ha despertado un cuestionamiento por explorar cómo pueden las inteligencias artificiales elevar su esfuerzo artístico pues, de forma similar a como GPT-4 está ahorrando horas de trabajo tedioso y mecánico a los programadores que a su vez les permite enfocarse en aspectos verdaderamente creativos o hasta experimentales de su labor, las inteligencias artificiales podrían liberar la mente del artista para elevar su intención artística que, sin duda alguna, seguirá siendo una labor exclusivamente humana por bastante tiempo. Figure figure_1: Computadora de control de fuego de la USS New Jersey. Obsérvense las manivelas para introducir información sobre el buque y sobre su objetivo. Tomada de \"Fire Control\" en YouTube (Battleship New Jersey, 2020) Figure figure_2: La UNIVAC I sólo podía almacenar el equivalente mil palabras y pesaba un poco más de 7 toneladas (Murray Hopper, 1981). Imagen tomada de \"A third survey of domestic electronic digital computing systems\" (Weik, 1961) Figure figure_3: Si bien la ENIAC de 1945 aquí mostrada es considerada la primera computadora programable, ésta carecía de un verdadero lenguaje: su programación se basaba en recombinaciones de cables y bulbos para hacer que la computadora realizara tal o cual operación (Sammet & Holberton, 1981). Imagen tomada de los archivos de la ARL Technical Library. Figure figure_4: Ejemplo de dos \"neuronas\" en una red neural procesando información. Adaptada de \"What are neural networks?\" (IBM, 2021) Figure figure_5: Ejemplo del flujo de la información a través de una red neural. Obsérvese cómo el flujo de datos en color azul continúa su camino por la red mientras que el flujo verde se interrumpe por no cumplir con los parámetros o \"weights\" establecidos en su programación. Adaptada de \"What are neural networks?\" (IBM, 2021) Figure figure_6: El triángulo de Ogden es uno de los diagramas más básicos para describir el proceso semántico. Adaptada de \"Semantics\" (Palmer & Frank Robert, 1981). Figure figure_7: En este diagrama se explica, de forma bastante simplificada, la forma en que un modelo lingüístico como GPT-3 analiza producciones escritas. El proceso es muy similar al análisis sintáctico. (T. B. Brown et al., 2020) Figure figure_8: En esta \"conversación\" con ChatGPT se ha introducido un fragmento de la canción \"Tangananica, Tangananá\" del programa chileno \"31 minutos\" Figure figure_9: El tweet original leía \"Despite the constant negative press covfefe\", se asume que fue un error de dedo, pero de inmediato se volvió objeto de burlas y parodias. Figure figure_10: Se le presenta una imagen a GPT-4 y se le pregunta \"¿Qué hace chistosa a esta imagen?\". La IA entonces analiza la composición de dicha imagen y es capaz de formular una explicación relativamente satisfactoria. Tomada de \"GPT-4 Developer Livestream\" (OpenAI, 2023a) Figure figure_11: Este diagrama pretende ejemplificar, de una forma muy simple, lo que los VAEs hacen: durante la fase de entrenamiento se ajustan los parámetros de la red neural de tal forma que el VAE pueda reconstruir la imagen original. Adaptada de \"Neural discrete representation learning\", (Van Den Oord et al., 2017) Figure figure_12: Una de las debilidades de los VAE es que, como si de una fotocopia se tratara, la imagen output suele ser borrosa o tener ruido. Izquierda: Imágenes input. Derecha: Imágenes output. Tomada de \"Neural discrete representation learning\" (Van Den Oord et al., 2017) Figure figure_13: DALL-E es capaz de generar imágenes a partir de indicaciones (prompts) complejos. Sin embargo, debe recordarse que OpenAI ha seleccionado estos resultados de entre miles de imágenes generadas con el mismo prompt. Tomada de \"DALL·E: Creating images from text\" (Jay Wang, 2021). Figure figure_14: Radford et al. (2021) llevaron a cabo pruebas con su clasificador CLIP, un tipo de red neural que busca poder generar descripciones textuales para imágenes dadas sin necesidad de supervisión humana, con distintos datasets. El nombre del dataset usado se lee en negritas. Las barras verdes señalizan una descripción aceptable y las naranjas una incorrecta o sin sentido. Tomada de \"Learning Transferable Visual Models From Natural Language Supervision\" (Radford et al., 2021). Figure figure_15: Los modelos de difusión latente (LPM) como Stable Diffusion agregan \"ruido\" a la imagen input poco a poco hasta tener sólo ruido, a partir del cual reconstruyen la imagen mediante un algoritmo probabilístico. Figure figure_16: Una de las interfaces gráficas disponibles para Stable Diffusion. Obsérvense las dos cajas de texto en la parte superior. Figure figure_17: Al introducir la frase \"an apple\" en la caja de instrucciones, Stable Diffusion genera resultados distintos dependiendo el checkpoint utilizado. De izquierda a derecha: El checkpoint base. ProtoGen 5.8 enfocado en fotografía. Anything V3, enfocado en ilustraciones estilo manga/anime. Un ejemplo curioso del proceso semántico incompleto que la IA lleva a cabo.",
      "word_count": 7020,
      "character_count": 44609,
      "vector": [
        0.22259306907653809,
        -0.11078469455242157,
        0.1110902652144432,
        0.01917346566915512,
        0.07843630760908127,
        -0.0011872912291437387,
        -0.07721426337957382,
        0.014218677766621113,
        0.0030585345812141895,
        -0.048406876623630524,
        -0.10740929841995239,
        0.049789413809776306,
        0.011894733645021915,
        0.028374742716550827,
        0.03824816271662712,
        0.10976739972829819,
        -0.029498199000954628,
        -0.048193685710430145,
        -0.099971242249012,
        -0.03333389014005661,
        -0.06137360632419586,
        0.03403962031006813,
        0.0885850340127945,
        0.14724579453468323,
        -0.062426116317510605,
        0.06670283526182175,
        -0.06354555487632751,
        -0.06603796035051346,
        -0.031139472499489784,
        -0.026700880378484726,
        0.13307851552963257,
        -0.04837608337402344,
        0.019894607365131378,
        -0.01944640278816223,
        -0.0010532417800277472,
        -0.009928327985107899,
        0.05893059819936752,
        -0.044245894998311996,
        -0.020024899393320084,
        -0.0789259672164917,
        -0.018795883283019066,
        -0.019082248210906982,
        -0.005974557716399431,
        -0.024561280384659767,
        0.10668797045946121,
        0.08529918640851974,
        0.04210129380226135,
        0.004693740978837013,
        -0.0006352538475766778,
        0.008069456554949284,
        0.0392632782459259,
        0.09862062335014343,
        -0.038381706923246384,
        0.04178398475050926,
        0.007041220087558031,
        -0.0394287109375,
        0.008059403859078884,
        0.030229436233639717,
        -0.014907664619386196,
        0.027170570567250252,
        -0.05578980594873428,
        0.09185221046209335,
        0.045089222490787506,
        -0.0468141995370388,
        -0.02797815389931202,
        0.023818492889404297,
        -0.02354029379785061,
        -0.024588370695710182,
        0.011628232896327972,
        0.0028953272849321365,
        0.00524925347417593,
        0.04216264188289642,
        -0.014767821878194809,
        0.04770888388156891,
        -0.04401665925979614,
        0.0853361189365387,
        -0.035415682941675186,
        -0.029342714697122574,
        0.01575457863509655,
        -0.01432916708290577,
        0.10325118154287338,
        0.034340716898441315,
        0.06390734016895294,
        0.029038093984127045,
        0.008969590999186039,
        -0.016241135075688362,
        -0.040039170533418655,
        0.027588872238993645,
        0.006521211471408606,
        -0.07548991590738297,
        -0.017789602279663086,
        -0.06911341100931168,
        -0.006919377949088812,
        -0.10455454140901566,
        0.028124291449785233,
        -0.03181736171245575,
        -0.009417453780770302,
        0.030314022675156593,
        -0.05706100910902023,
        -0.02049897238612175,
        0.059859540313482285,
        0.059369754046201706,
        -0.10909413546323776,
        0.018016859889030457,
        0.0013500516070052981,
        -0.027098778635263443,
        -0.00281420536339283,
        0.04810149967670441,
        -0.042927347123622894,
        0.052332013845443726,
        -0.024661919102072716,
        0.008528487756848335,
        0.02867926098406315,
        0.0002094537776429206,
        -0.026827286928892136,
        0.051082711666822433,
        -0.02322833053767681,
        0.05464999005198479,
        0.05784982070326805,
        -0.0005749535630457103,
        -0.023299675434827805,
        0.028306541964411736,
        -0.03217447176575661,
        0.014354337938129902,
        -0.03207120671868324,
        -0.0329943411052227,
        -0.006896873936057091,
        0.0005751010030508041,
        -0.022850308567285538,
        -0.05339105799794197,
        -0.05614357069134712,
        0.012074342928826809,
        -0.04952900484204292,
        0.02998482808470726,
        -0.030349791049957275,
        -0.0541505292057991,
        0.017869288101792336,
        0.0020026955753564835,
        0.042088501155376434,
        0.028123119845986366,
        0.03179189935326576,
        0.061920374631881714,
        0.013613475486636162,
        0.006916891783475876,
        -0.01524768304079771,
        -0.050598397850990295,
        -0.01175880990922451,
        0.03093278408050537,
        0.03988886624574661,
        -0.014233337715268135,
        0.02964327484369278,
        -0.007373760920017958,
        -0.01705268770456314,
        0.06234068423509598,
        -0.012249440886080265,
        -0.02337203361093998,
        -0.011618967168033123,
        0.011843767017126083,
        -0.017747586593031883,
        0.03630581125617027,
        -0.015323474071919918,
        0.054748740047216415,
        -0.01571028120815754,
        0.03950296342372894,
        -0.04094419628381729,
        0.009094977751374245,
        -0.008970864117145538,
        0.028848063200712204,
        -0.0059880479238927364,
        -0.025723854079842567,
        -0.03381534293293953,
        0.014931624755263329,
        0.026293853297829628,
        -0.002438303316012025,
        0.004789712373167276,
        -0.05134701728820801,
        0.03287423402070999,
        0.056224025785923004,
        0.01969141885638237,
        0.0659908801317215,
        0.04056503623723984,
        -0.03838474303483963,
        -0.03564042970538139,
        0.016959240660071373,
        -0.045993611216545105,
        0.009233735501766205,
        -0.00676548108458519,
        0.01518825814127922,
        0.008083834312856197,
        -0.07194660604000092,
        0.034343019127845764,
        -0.00593703705817461,
        0.05796913057565689,
        0.014063753187656403,
        -0.009238054975867271,
        0.01213273499161005,
        -0.021607037633657455,
        0.0016743867890909314,
        0.022706376388669014,
        -0.054555702954530716,
        -0.01987099088728428,
        -0.02268088422715664,
        0.01619740203022957,
        -0.042168743908405304,
        -0.013535603880882263,
        0.04178783297538757,
        -0.020302314311265945,
        -0.043632011860609055,
        -0.043154239654541016,
        0.058026570826768875,
        -0.014433694072067738,
        0.045094773173332214,
        0.03760579600930214,
        -0.0003702283720485866,
        -0.010519122704863548,
        -0.025499125942587852,
        0.022430604323744774,
        0.05758558213710785,
        0.047842878848314285,
        -0.03432217985391617,
        0.006012130994349718,
        0.020746467635035515,
        -0.013107807375490665,
        -0.04032565653324127,
        -0.042372092604637146,
        0.013165328651666641,
        -0.02469237893819809,
        0.012564404867589474,
        -0.02679949812591076,
        -0.008691797964274883,
        0.03696172311902046,
        0.06634823977947235,
        -0.0016523661324754357,
        0.013347098603844643,
        0.017286080867052078,
        0.0009700597729533911,
        -0.01864076405763626,
        0.032995082437992096,
        0.03047752194106579,
        0.015944933518767357,
        -0.030640870332717896,
        0.0027464611921459436,
        -0.02227703481912613,
        -0.0035277612041682005,
        -0.0633460059762001,
        -0.026819884777069092,
        -0.035013165324926376,
        -0.04418758302927017,
        -0.03725901246070862,
        0.061727408319711685,
        0.055463265627622604,
        0.00840675923973322,
        -0.038489364087581635,
        -0.051075637340545654,
        -0.001509020570665598,
        -0.012878132052719593,
        0.055631909519433975,
        -0.00676519563421607,
        -0.0374106802046299,
        0.014152616262435913,
        -0.007766985800117254,
        0.04093314707279205,
        0.001884270808659494,
        0.02227761410176754,
        -0.02226007916033268,
        0.03194282203912735,
        -0.009856696240603924,
        -0.02250247821211815,
        0.016315842047333717,
        -0.023852601647377014,
        -0.05670465901494026,
        -0.004346849862486124,
        -0.053525447845458984,
        0.007456306833773851,
        0.0022096445318311453,
        0.018941333517432213,
        -0.02142508141696453,
        0.03302978351712227,
        -0.009937829338014126,
        0.03217846527695656,
        -0.04622390866279602,
        -0.04418204724788666,
        0.0008483028504997492,
        -0.0036300178617239,
        0.0001934454485308379,
        -0.03008766658604145,
        0.015538849867880344,
        0.025346040725708008,
        0.026324445381760597,
        0.005346905440092087,
        -0.004976099822670221,
        -0.04215453937649727,
        0.016894059255719185,
        -0.04342372715473175,
        -0.0022226949222385883,
        -0.0009955710265785456,
        -0.08515433967113495,
        -0.0018155894940719008,
        0.03151815012097359,
        0.012134884484112263,
        -0.022420121356844902,
        0.03269756957888603,
        0.011728526093065739,
        0.020451238378882408,
        0.024139970541000366,
        -0.017102453857660294,
        -0.04985251650214195,
        -0.032196883112192154,
        -0.04033626988530159,
        -0.017224589362740517,
        0.014373009093105793,
        -0.013831814751029015,
        -0.01262097992002964,
        0.04405885934829712,
        0.0007326154736801982,
        0.034948788583278656,
        0.004509476013481617,
        0.031364165246486664,
        0.005707509815692902,
        -0.0005617616698145866,
        -0.018154438585042953,
        -0.018941832706332207,
        -0.004290393553674221,
        -0.01570265181362629,
        -0.036342836916446686,
        -0.05980914458632469,
        -0.0053998674266040325,
        0.00398954888805747,
        -0.015058953315019608,
        -0.02272077277302742,
        0.003966807387769222,
        0.006412394344806671,
        0.015409622341394424,
        0.02464006468653679,
        -0.004875516518950462,
        -0.007840744219720364,
        0.010146520100533962,
        -0.02138431929051876,
        0.02958470955491066,
        -0.001400795066729188,
        0.03571495786309242,
        -0.03042735904455185,
        0.005595081020146608,
        -0.009696432389318943,
        0.009567574597895145,
        0.02722546085715294,
        -0.021916711702942848,
        0.007358911447227001,
        0.01820269040763378,
        0.04066513478755951,
        0.0026053658220916986,
        0.020791443064808846,
        -0.01920383609831333,
        0.009008465334773064,
        -0.00973562803119421,
        0.0031015935819596052,
        0.006637329235672951,
        0.020906424149870872,
        0.041150327771902084,
        -0.050538353621959686,
        -0.006147306878119707,
        -0.011178682558238506,
        0.024328961968421936,
        0.04897338151931763,
        -0.013670647516846657,
        0.01726391725242138,
        -0.004682152532041073,
        0.07367003709077835,
        -0.00046572895371355116,
        -0.0003421661676838994,
        -0.017916491255164146,
        0.009420471265912056,
        -0.01641683466732502,
        -0.018024558201432228,
        0.03103494830429554,
        0.017094803974032402,
        0.07051583379507065,
        0.026848210021853447,
        0.07414299249649048,
        0.024062732234597206,
        0.014319268055260181,
        -0.028661170974373817,
        0.04966721311211586,
        0.005941461306065321,
        0.006963152904063463,
        -0.0025840045418590307,
        0.09146405756473541,
        -0.026104668155312538,
        -0.006502625998109579,
        0.030898910015821457,
        -0.029829248785972595,
        0.008476877585053444,
        0.03139982745051384,
        -0.02337072789669037,
        -0.0700652077794075,
        -0.005191172938793898,
        0.022149283438920975,
        -0.0039023563731461763,
        0.014200352132320404,
        0.0035496531054377556,
        0.022829990833997726,
        0.0083617577329278,
        -0.0027416974771767855,
        -0.06186826899647713,
        0.027721857652068138,
        0.004528183490037918,
        0.031106073409318924,
        -0.01421036571264267,
        -0.02688722312450409,
        -0.01700335554778576,
        -0.01996885985136032,
        -0.01631932519376278,
        -0.06056676059961319,
        0.008768575266003609,
        0.034083303064107895,
        -0.038231637328863144,
        0.03210088983178139,
        0.005063787568360567,
        -0.02074987255036831,
        -0.012945462949573994,
        0.012162283062934875,
        0.03760886192321777,
        -0.00599293876439333,
        -0.0002875265199691057,
        0.028900234028697014,
        -0.029382096603512764,
        -0.03303346037864685,
        -0.02090379036962986,
        0.010913447476923466,
        0.02261114865541458,
        -0.03846670314669609,
        -0.006969050504267216,
        -0.015000770799815655,
        0.0236643198877573,
        -0.022036852315068245,
        -0.008554543368518353,
        -0.02361246757209301,
        0.02315266616642475,
        -0.007839642465114594,
        -0.0009159728069789708,
        0.052044399082660675,
        0.014306709170341492,
        0.006462728604674339,
        0.0002505215525161475,
        0.011422066017985344,
        0.010711345821619034,
        0.0431823655962944,
        -0.03128330782055855,
        0.021388446912169456,
        0.00011293186253169551,
        -0.025642404332756996,
        0.03005749173462391,
        -0.03855200111865997,
        -0.0395037904381752,
        -0.012040279805660248,
        -0.006881947163492441,
        0.02398216910660267,
        -0.018168387934565544,
        0.009030666202306747,
        0.014462917111814022,
        0.04099934175610542,
        0.0030036582611501217,
        0.008801545016467571,
        -0.003931662533432245,
        0.08490892499685287,
        0.020321039482951164,
        0.0648745596408844,
        0.023310422897338867,
        0.014208982698619366,
        0.004840991459786892,
        0.011976244859397411,
        -0.005560404621064663,
        -0.02234610728919506,
        -0.020722022280097008,
        0.0014709547394886613,
        -0.006589035037904978,
        0.0011314753210172057,
        -0.03680963069200516,
        -0.022393330931663513,
        -0.038910068571567535,
        -0.022270826622843742,
        -0.023465611040592194,
        0.027004502713680267,
        0.0157752875238657,
        0.042634181678295135,
        -0.047457121312618256,
        -0.01574072614312172,
        -0.0586155466735363,
        0.02480272389948368,
        0.01993572525680065,
        -0.0020329998806118965,
        -0.04042782261967659,
        0.023220708593726158,
        0.05856803432106972,
        -0.0164773091673851,
        -0.011014818213880062,
        -0.0015275211771950126,
        -0.03406232222914696,
        -0.00848340429365635,
        -0.06136119365692139,
        -0.019579272717237473,
        0.004446066450327635,
        -0.01244600210338831,
        -0.024240929633378983,
        -0.023435236886143684,
        -0.0326092429459095,
        -0.030105436220765114,
        -0.0036119951400905848,
        0.008831986226141453,
        -0.031040774658322334,
        -0.030302956700325012,
        0.009430339559912682,
        0.023960037156939507,
        0.003548607463017106,
        -0.031359270215034485,
        -0.013589896261692047,
        0.03464795649051666,
        -0.014052637852728367,
        0.007530571427196264,
        0.012251083739101887,
        0.026556367054581642,
        -0.007819241844117641,
        0.01493979524821043,
        -0.031705986708402634,
        -0.0008434359333477914,
        0.008968839421868324,
        -0.01796608231961727,
        -0.029051069170236588,
        0.022709151729941368,
        -0.02480074018239975,
        0.05373406410217285,
        0.013448628596961498,
        0.038907065987586975,
        -0.03827029839158058,
        0.024008627980947495,
        -0.00330332200974226,
        -0.013831027783453465,
        -0.03398147225379944,
        -0.0031350196804851294,
        -0.01325587835162878,
        0.006122148595750332,
        -0.030890626832842827,
        -0.0032861162908375263,
        -0.005180367734283209,
        -0.06054101139307022,
        0.012737502343952656,
        0.01218357402831316,
        0.02108176052570343,
        0.018393980339169502,
        0.024635914713144302,
        -0.031608909368515015,
        0.018083132803440094,
        0.0011190134100615978,
        -0.010111209936439991,
        0.012235847301781178,
        -0.03401986509561539,
        0.02299332804977894,
        -0.02875913493335247,
        -0.01599458046257496,
        -0.0215256717056036,
        -0.009383974596858025,
        -0.00811680220067501,
        -0.010355712845921516,
        -0.047967735677957535,
        -0.04324720799922943,
        -0.003687711898237467,
        -0.004078255034983158,
        0.008222999051213264,
        -0.02412993088364601,
        0.02388872019946575,
        -0.0022968403063714504,
        0.020186251029372215,
        -0.01578257605433464,
        0.04345118626952171,
        0.011453508399426937,
        -0.028813565149903297,
        -0.0051255663856863976,
        0.063944973051548,
        0.008660219609737396,
        0.012944675050675869,
        -0.018216386437416077,
        -0.04377260059118271,
        -0.014446244575083256,
        0.02196664921939373,
        0.013255388475954533,
        0.006329007912427187,
        -0.010355249047279358,
        -0.0005570315406657755,
        0.001487483736127615,
        0.009769844822585583,
        -0.020124664530158043,
        0.021078944206237793,
        0.0016225717263296247,
        0.02397116646170616,
        0.03919234499335289,
        0.0032964551355689764,
        -0.032059937715530396,
        -0.04196266457438469,
        -0.0340903177857399,
        -0.04005720466375351,
        -0.050151560455560684,
        -0.003856350900605321,
        0.0006320584798231721,
        0.01861739531159401,
        0.038608089089393616,
        0.03358696773648262,
        -0.004987552762031555,
        0.02904905565083027,
        -0.016252564266324043,
        -0.01599009335041046,
        0.01001635380089283,
        0.005343819502741098,
        0.012383541092276573,
        -0.014891513623297215,
        0.04085976630449295,
        0.008284216746687889,
        0.0021361103281378746,
        -0.021825654432177544,
        -0.012810781598091125,
        -0.0027318343054503202,
        0.026342269033193588,
        0.023634225130081177,
        0.029184509068727493,
        -0.024940425530076027,
        0.011953732930123806,
        0.007997793145477772,
        0.023334981873631477,
        0.045407652854919434,
        -0.0011690137907862663,
        0.02812613733112812,
        0.00048337833140976727,
        0.01948012411594391,
        0.012018423527479172,
        0.019393498077988625,
        -0.022032244130969048,
        -0.004436461720615625,
        0.05373682826757431,
        0.021068044006824493,
        0.0015317632351070642,
        0.041569389402866364,
        0.00724650826305151,
        -0.019586428999900818,
        0.025112131610512733,
        0.034954171627759933,
        -0.034841056913137436,
        -0.04601642116904259,
        0.022730635479092598,
        0.0057554407976567745,
        0.012332595884799957,
        -0.0019071863498538733,
        -0.06088286638259888,
        0.01432378776371479,
        -0.041738931089639664,
        0.014743407256901264,
        -0.02817748486995697,
        -0.0027828754391521215,
        -0.016181571409106255,
        -0.01743847317993641,
        -0.0288745928555727,
        -0.03220843896269798,
        -0.012388147413730621,
        0.007923517376184464,
        0.05509631708264351,
        -0.016933254897594452,
        0.009429256431758404,
        0.015246779657900333,
        -0.005804457236081362,
        0.03620389476418495,
        -0.00889462511986494,
        0.014688575640320778,
        -0.0006336135556921363,
        0.004599909298121929,
        0.006693958304822445,
        -0.04375862330198288,
        0.009247458539903164,
        -0.003794681979343295,
        0.020734896883368492,
        0.020926088094711304,
        0.0078898835927248,
        -0.010858096182346344,
        -0.014524033293128014,
        0.000944773550145328,
        0.021164605394005775,
        -0.0201015193015337,
        0.002302746055647731,
        -0.02772146463394165,
        -0.039566222578287125,
        0.009820428676903248,
        -0.0047552743926644325,
        0.057348452508449554,
        -0.028161663562059402,
        -0.00366259110160172,
        0.016887174919247627,
        0.0013540886575356126,
        0.01873425953090191,
        -0.027391739189624786,
        -0.0025211742613464594,
        0.0012274046894162893,
        0.007752620615065098,
        0.0026708957739174366,
        -0.015139400959014893,
        -0.01325716357678175,
        0.02253628335893154,
        -0.00912143848836422,
        -0.023988226428627968,
        0.02051413059234619,
        0.0024810151662677526,
        0.0003653971361927688,
        0.008648252114653587,
        0.008047682233154774,
        -0.007925271056592464,
        0.001855005626566708,
        -0.0067882053554058075,
        -0.015931224450469017,
        0.009756825864315033,
        -0.018289657309651375,
        0.0020451920572668314,
        -0.033037085086107254,
        0.03825214132666588,
        0.04050125554203987,
        0.006242510862648487,
        -0.02533320151269436,
        0.02021820843219757,
        -0.005151820369064808,
        0.0252520851790905,
        0.008153817616403103,
        0.012554147280752659,
        -0.002215843414887786,
        -0.030008912086486816,
        0.005070342216640711,
        -0.007264807354658842,
        0.0050483825616538525,
        -0.0075418464839458466,
        -0.004342413507401943,
        -0.018189191818237305,
        -0.005150924902409315,
        0.0057296184822916985,
        -0.0019302279688417912,
        -0.029626166447997093,
        -0.03182995319366455,
        0.005478253122419119,
        -0.004627192858606577,
        -0.03584320470690727,
        0.042504724115133286,
        0.02145095355808735,
        -0.007084019482135773,
        -0.014777316711843014,
        0.03021867386996746,
        0.025736786425113678,
        -0.02890895865857601,
        0.010258618742227554,
        0.06068130210042,
        -0.003889545565471053,
        -0.02392369881272316,
        0.01439963560551405,
        -0.025763334706425667,
        -0.016253383830189705,
        0.04681401327252388,
        0.011727044358849525,
        -0.0660654753446579,
        -0.03617860749363899,
        0.06429783999919891,
        0.008852703496813774,
        0.039943668991327286,
        -0.0379786416888237,
        0.029357725754380226,
        0.0015558090526610613,
        -0.022778432816267014,
        -0.017882877960801125,
        0.016652438789606094,
        0.006491171661764383,
        -0.021024631336331367,
        0.008656417950987816,
        -0.011900689452886581,
        0.03075234219431877,
        0.004832783248275518,
        -0.019644949585199356,
        -0.024672653526067734,
        -0.03036472201347351,
        -0.020268231630325317,
        -0.03530842810869217,
        0.017191942781209946,
        -0.02294480800628662,
        0.02716507948935032,
        -0.0019110903376713395,
        0.016537271440029144,
        -0.014827010221779346,
        0.007264510728418827,
        -0.0057284473441541195,
        0.0010421440238133073,
        -0.010521776042878628,
        -0.007425983902066946,
        -0.020724231377243996,
        0.014247837476432323,
        -0.05137116089463234,
        0.02873341552913189,
        -0.04208516702055931,
        0.0628567561507225,
        0.025066334754228592,
        0.010410051792860031,
        0.010863268747925758,
        0.019595632329583168,
        0.005848126485943794,
        0.006994479801505804,
        -2.9798682589898817e-05,
        -0.0017841453664004803,
        -0.006825424265116453,
        -0.03349154442548752,
        0.042755503207445145,
        0.0010193708585575223,
        0.015865864232182503,
        0.010047681629657745,
        0.02345597930252552,
        -0.02510809898376465,
        -0.0331408828496933,
        -0.010133893229067326,
        -0.02562526986002922,
        0.009997589513659477,
        0.011242297478020191,
        0.017199700698256493,
        -0.006879543419927359,
        -0.006536189001053572,
        -0.001765094930306077,
        -0.007910003885626793,
        -0.06980179250240326,
        0.01803020015358925,
        0.010288668796420097,
        -0.015218610875308514,
        -0.02835497446358204,
        0.024393314495682716,
        0.010417606681585312,
        0.021304691210389137,
        -0.03059915266931057,
        0.01879720389842987,
        -0.002038049278780818,
        -0.014218277297914028,
        -0.03736971318721771,
        0.032394889742136,
        -0.034178201109170914,
        0.0035594250075519085,
        -0.02080613747239113,
        -0.014640049077570438,
        0.016873260959982872,
        0.008139433339238167,
        -0.016143158078193665,
        0.042224954813718796,
        -0.03537309169769287,
        -0.0077914344146847725,
        0.013131855987012386,
        -0.0014303586212918162,
        -0.02268015593290329,
        -0.009932239539921284,
        0.043458595871925354,
        -0.0007127002463676035,
        -0.021609006449580193,
        0.016711344942450523,
        0.02630944363772869,
        -0.01760498434305191,
        -0.007965168915688992,
        0.011184518225491047,
        -0.019593767821788788,
        0.008845372125506401,
        -0.06137610226869583,
        -0.044489555060863495,
        -0.017959166318178177,
        0.004811991471797228,
        -0.053536269813776016,
        0.033399637788534164,
        0.0022082317154854536,
        -0.007200020365417004,
        -0.00808430090546608,
        0.0037748394533991814,
        0.018279284238815308,
        -0.0034048829693347216,
        -0.022959308698773384,
        -0.03459084779024124,
        -0.0029750149697065353,
        0.02290542609989643,
        -0.006224764045327902,
        0.008692356757819653,
        0.0038867874536663294,
        0.04923265054821968,
        -0.0020823581144213676,
        0.008875872008502483,
        0.017736658453941345,
        0.006003628950566053,
        0.038614384829998016,
        -0.03095722198486328,
        0.005561181344091892,
        0.015729689970612526,
        -0.009912744164466858,
        -0.021290715783834457,
        -0.011713109910488129,
        -0.0037134713493287563,
        -0.02050638385117054,
        0.0012668785639107227,
        -0.01992524415254593,
        -0.009156418032944202,
        0.007796570658683777,
        -0.023311279714107513,
        -0.03713272511959076,
        0.027519330382347107,
        -0.025650983676314354,
        0.0020495327189564705,
        -0.007878308184444904,
        0.03154449909925461,
        0.03757010027766228,
        -0.01449623703956604,
        0.004497605375945568,
        -0.025195641443133354,
        0.01696510799229145,
        0.033980052918195724,
        0.037007495760917664,
        0.034187279641628265,
        -0.021525181829929352,
        0.011055605486035347,
        0.007874265313148499,
        -0.0005763312801718712,
        -0.01938055455684662,
        0.009451368823647499,
        -0.0071310680359601974,
        0.011492285877466202,
        -0.043975476175546646,
        -0.04728086665272713,
        -0.030033761635422707,
        -0.020104555413126945,
        0.008259782567620277,
        -0.018998345360159874,
        0.0069724684581160545,
        -0.007094362750649452,
        0.00020995779777877033,
        -4.691771027864888e-05,
        0.062386784702539444,
        -0.025723660364747047,
        -0.020713023841381073,
        -0.009767785668373108,
        0.004940893035382032,
        0.020567700266838074,
        -0.021602051332592964,
        0.014239916577935219,
        -0.021528441458940506,
        0.030176866799592972,
        -0.011274292133748531,
        0.030788157135248184,
        0.02505219541490078,
        -0.012459083460271358,
        0.007058441173285246,
        -0.022834908217191696,
        -0.007314200513064861,
        0.007869233377277851,
        -0.015024928376078606,
        -0.00023560618865303695,
        0.010915981605648994,
        0.007367617450654507,
        -0.013803813606500626,
        -0.002067738911136985,
        0.04205277934670448,
        0.020344043150544167,
        0.000382701720809564,
        -0.011927549727261066,
        -0.023440180346369743,
        -0.03857824206352234,
        0.0011975005036219954,
        0.012637417763471603,
        -0.021100249141454697,
        0.014773992821574211,
        0.0046229069121181965,
        0.02882777340710163,
        0.0026602461002767086,
        0.026624979451298714,
        -0.022300656884908676,
        -0.008256299421191216,
        0.02382582053542137,
        0.0026526832953095436,
        0.006040310021489859,
        -0.02996327169239521,
        0.018370145931839943,
        0.014971327967941761,
        0.009380379691720009,
        0.03842824324965477,
        -0.012113695964217186,
        -0.015970349311828613,
        0.026172809302806854,
        -0.04780028387904167,
        0.026554614305496216,
        0.012252513319253922,
        -0.013329880312085152,
        -0.010480981320142746,
        0.002876270329579711,
        0.0031260924879461527,
        0.009706549346446991,
        0.005120601039379835,
        -0.03242288529872894,
        -0.018898846581578255,
        0.006592073477804661,
        -0.016240691766142845,
        0.011844420805573463,
        -0.010861614719033241,
        0.04489358142018318,
        -0.00818799901753664,
        -0.03922560438513756,
        -0.023941412568092346,
        -0.002269076881930232,
        0.011766882613301277,
        0.011815877631306648,
        -0.0028583223465830088,
        0.00849098153412342,
        0.027974529191851616,
        -0.011527004651725292,
        0.02600642293691635,
        0.033973921090364456,
        0.01035466231405735,
        -0.0056746527552604675,
        0.022494059056043625,
        -0.03326877951622009,
        -0.014308156445622444,
        -0.0022007315419614315,
        -0.00048120241262950003,
        -0.0223200935870409,
        -0.03011237643659115,
        0.00840798020362854,
        0.03259826451539993,
        -0.005225776229053736,
        -0.005239501129835844
      ],
      "title": "Conversando con una computadora: ¿Cómo entienden las inteligencias artificiales lo que les pedimos?"
    },
    {
      "id": "gai-esp_corpus-item003",
      "count": 9,
      "created": "2025-07-06T05:53:21.806419",
      "text": "Inteligencia artificial generativa: irrupción y desafíos Las aplicaciones de la inteligencia artificial generativa (IAG) disponibles en versiones gratuitas online permiten a usuarios en general, en cuestión de segundos, el acceso a la generación de diversos contenidos en un lenguaje natural. A través de prompts que permiten interactuar con chatbots, como el caso de ChatGPT y otras similares, es posible recibir respuestas a las preguntas o planteamientos introducidos, e incluso mantener una especie de conversación con la máquina inteligente. Su irrupción, su uso creciente y su impacto en la sociedad occidental, a la par de su desarrollo acelerado; conlleva a cuestionarse la serie de desafíos que estas tecnologías representan y la manera de integrarlas a los procesos de gestión del conocimiento, con base en una ética de la tecnología que permita potenciar sus beneficios y minimizar su impacto negativo en la calidad de vida y los valores de los seres humanos. Introducción En el marco de la revolución tecnológica, la irrupción de la inteligencia artificial generativa (IAG) supone un hito en la manera en la que la tecnología ha evolucionado y la función que cumple dentro de las sociedades contemporáneas, presentando avances sin precedentes en la actualidad. Atestiguamos una era en donde las máquinas inteligentes no sólo procesan datos, también son capaces de aprender información, mantener interacciones con lenguaje natural y generar contenidos diversos. El uso de sus aplicaciones con fines educativos, entretenimiento, profesionales, empresariales, creativos, etc. crece con rapidez; por lo tanto, este hecho permite cuestionarse acerca de sus implicaciones, influencia, desafíos, áreas de oportunidad y ética; con el fin de lograr una adopción y un uso eficaz y conveniente en los usuarios. Pese a la popularidad actual y la aparente novedad de esta rama de la inteligencia artificial (IA), ésta significa un desarrollo cuyos antecedentes se remontan a la época temprana del siglo pasado, e incluso superan el siglo de historia, mucho antes de que Alan Turing apareciera en la escena. En 1910, el ingeniero español Leonardo Torres y Quevedo, proyectó la primera computadora digital electromecánica. Empleó el vocablo autómata —una máquina que imita y puede remplazar las funciones humanas—, un artefacto capaz de proceder en todo momento como \"un ser inteligente que sigue ciertas reglas\", destacando que \"procede como un ser inteligente en el momento en que hay que escoger un camino en cada caso particular\" (Torres y Quevedo, 2003). Cuatro décadas después, el matemático y científico de la computación británico Alan Turing cuestionó si las máquinas podían pensar. Para ello partió de la necesidad de definir los conceptos \"máquina\" y \"pensar\" y el uso habitual de éstos; no obstante, la dificultad intrínseca lo llevó a un mejor escenario: pensar en el \"juego de la imitación\", conocido también como el \"test de Turing\", dos asuntos relacionados y propuestos para poder determinar y evaluar la capacidad de una máquina para mostrar un comportamiento inteligente similar al de un ser humano. La prueba involucra a tres participantes: un humano (A), una máquina capaz de generar respuestas similares a las humanas (B) y un interrogador humano (C); de tal suerte que, mediante una prueba con una conversación textual en lenguaje natural, a través de preguntas entre la máquina (B) y el humano (A), el interrogador (C) no pueda distinguir consistentemente si se está comunicando con la otra persona (A) o con la máquina inteligente (B), en tal caso se consideraría que la máquina pasó el Test de Turing al demostrar un nivel de inteligencia equivalente a la humana. Pese a que esta prueba ha sido objeto de críticas y generado debates entre la comunidad científica al considerar que no se trata de un instrumento definitivo para probar y determinar la inteligencia de un autómata ni su posible comprensión profunda; sí puede demostrar su capacidad de simular la cognición humana relacionada a un sistema lógico en cuestión y continúa siendo un referente de influencia en la discusión pues, el \"juego de la imitación\" propuesto por Turing, se basa en un proceso de enseñanza y aprendizaje y, por lo tanto, no excluye el potencial de las máquinas para ejecutar tareas intelectuales propias de un humano (Turing, 1950). Los antecedentes sobre el desarrollo de la IA continuaron en Estados Unidos en 1956 con otros precursores como John McCarthy —fundador y el primero en dirigir los laboratorios de inteligencia artificial del Instituto de Tecnología de Massachussets (MIT) en 1957, además de atribuírsele la creación del término Inteligencia Artificial—; Marvin Minsky, quien después dirigiría el mismo laboratorio; Allen Newell y Herbert Simon (Mata y Grosch 2007); asimismo como Nathaniel Rochester, Claude Shannon, Trenchard More, Arthur Samuel, Ray Solomomoff y Oliver Selfridge los cuales asistieron a una histórica conferencia en el Dartmouth College de 1956, la cual colocó en el mapa a la IA como un campo de investigación y donde dieron forma a la idea del desarrollo tecnológico de máquinas electrónicas capaces de aprender, pensar, resolver problemas, ejecutar funciones vinculadas a las del cerebro de una persona y comunicarse en un lenguaje natural. De acuerdo a Barrera (2012), el investigador Joseph Weizenbaum del MIT desarrolló ELIZA en 1965, un programa interactivo con algotitmos complejos capaz de mantener diálogos simulados sobre diferentes temas y respuestas de terapia conversacional, el cual fue considerado como precursor en la generación de lenguaje natural. Un año después se realizó en Escocia el primer taller de máquinas inteligentes. En 1968 se presentó MACSYMA el primer programa en usar razonamiento simbólico en la integración de problemas matemáticos desarrollado por Joel Moses del MIT y al año siguiente el Instituto de Investigación de Stanford ya presentaba Shakey The Robot, un desarrollo que combinaba la locomoción animal, la percepción y la solución de problemas. Pese a los avances demostrados y el optimismo por los logros obtenidos en este campo, 1969 también fue un año de decepción, pérdida de confianza y austeridad en los recursos para investigar tras la publicación Perceptrons, un trabajo de Marvin Minsky y Seymour Papert que demostró limitaciones en las redes neuronales. No obstante, este asunto no frenó los intentos y, a principios de 1970, Jaime Carbonell desarrolló SCHOLAR, un programa interactivo basado en redes semánticas para lograr representar conocimiento mediante una instrucción asistida por computadora. En 1979 se presentó el primer vehículo autónomo controlado por una máquina, producto desarrollado por Hans Moravec del Instituto de Investigación de Stanford, mismo lugar donde al año siguiente se llevó a cabo la primera Conferencia Nacional de la American Association for Artificial Intelligence. En la década de los 90 se lograron grandes avances para la IA respecto al \"aprendizaje de máquinas, capacitación inteligente, razonamiento basado en casos, planificación de multi agentes, calendarización, razonamiento incierto, minería de datos, entendimiento y traducción de lenguaje natural, visión artificial, realidad virtual, juegos, etc.\", como los avances en la construcción de carros robots autónomos; el proyecto MIT COG de Brooks, Stein y Breazeal quienes en 1993 se propusieron crear a un niño robot humanoide; la conquista de la máquina de ajedrez de la IBM, conocida como Deep Blue, que le ganó una partida a Garry Kasparov, el campeón mundial de la época de ese juego; la comercialización de artefactos domésticos tipo mascota desarrollados con técnicas de IA como Furby o AIBO; los programas de extracción de información en internet basados en IA; o las demostraciones de habitaciones inteligentes y agentes emocionales mediante una red adaptativa que conectaba dispositivos móviles y computadoras estacionadas. Siguiendo la tendencia, el nuevo milenio irrumpió con más desarrollos como ASIMO, un robot humanoide artificialmente inteligente presentado por Honda en el 2005; y para el año siguiente se celebró la AI@50, llamada también Conferencia en Inteligencia Artificial de Dartmouth: los próximos 50 años, para conmemorar el medio siglo de su predecesora clave en el desarrollo del campo de la IA (Barrera 2012). El siglo XXI también fue clave para un hito tecnológico: el desarrollo de grandes redes neuronales artificiales en la IA de decenas o cientos de capas, conocidas como neuronas profundas, que originaron la arquitectura *Deep Learning* gracias en parte el acceso a cantidades innimaginables de datos y el abaratamiento del hardware, que han permitido los avances en lenguaje natural, el reconocimiento de imágenes o el paso en el 2014 a las Generative Adversarial Nets (GAN) introducidas por Ian Goodfellow y un equipo de colaboradores. El *Deep Learning* ha sido clave para el aprendizaje automático de las máquinas durante su entrenamiento y su capacidad de sintetizar y analizar datos, y ha permitido ir más allá al desarrollar sistemas capaces de aprender mediante la experiencia y de modificar de manera dinámica su comportamiento por medio de la retroalimentación arrojada por los resultados obtenidos, asunto estudiado por el *reinforcement learning* (aprendizaje por refuerzo). Esto último permitió a DeepMind introducir en el 2016 un sistema de IA llamado AlphaGO, entrenado por una persona para jugar GO, un juego de estrategia japonés mucho más complejo que el ajedrez, y que logró vencer al campeón mundial humano de entonces. En 2017, el mismo equipo presentó AlphaZero una máquina entrenada para competir contra sí misma en el GO y que no ha sido derrotada por persona alguna, lo que supone un verdadero suceso respecto a la capacidad de aprender de las IA, mejorar su comportamiento y superar en ciertas tareas cognitivas a los seres humanos (Caiafa y Lew, 2020). La acelerada evolución de la IA ha desencadenado el desarrollo de diversas y significativas tecnologías, a su vez campos de investigación, como el caso de la inteligencia artificial generativa (IAG), enfocada a generar contenidos de manera automática como ChatGPT, Perplexity, Bard, Copy.ai, Jasper, Writesonic o Claude, por citar algunas aplicaciones que permiten guiar y tener acceso a textos configurados por la IA en cuestión de segundos, a través del uso de chatbots. En el caso concreto de ChatGPT (Generative Pre-training Transformer), un sistema de IAG basado en un modelo de lenguaje generativo, mismo que fue creado con 175 millones de parámetros y entrenado con alrededor de 8 millones de documentos, archivos, artículos, etc. (Hughes, 2023). Esta aplicación fue desarrollada por la empresa Open AI y tiene la capacidad de utilizar técnicas de Procesamiento de Lenguaje Natural y generar respuestas escritas con coherencia y relevancia, en lenguaje natural del tipo humano, y en tiempo real; mediante conversaciones en un chat (Lopezosa, 2023). En un contexto de evolución acelerada y, al parecer imparable, las tecnologías de IAG introducen una transformación significativa en la manera en la que interactuamos con la información, la forma en la que tenemos acceso al conocimiento y cómo nos relacionamos en los entornos digitales contemporáneos en el marco de una revolución digital, llamada también revolución 4.0 o cuarta revolución industrial. Este término fue introducido por el economista alemán Klaus Schwab, quien considera que esta era, sin precedente ni par conocido por la humanidad, alterará todo lo conocido hasta el momento en términos relacionales, organizacionales y del entorno, a través de una confluencia entre esferas físicas, digitales y biológicas; mismas que producirán transformaciones en todos los niveles. La cuarta revolución industrial se caracteriza por el uso de tecnologías emergentes tales como \"la inteligencia artificial, la robótica, el internet de las cosas, los vehículos autónomos, la impresión 3D, la nanotecnología, la biotecnología, la ciencia de materiales, el almacenamiento de energía y la computación cuántica\" (Schwab, 2016). Dentro de esta época de notables avances en términos de inteligencia artificial generativa, no es posible cerrar la mirada al impacto profundo que estas tecnologías tienen en las interacciones humanas en diversos campos, lo que implica en sí un desafío para las sociedades contemporáneas, pues los escenarios en los que se aplica abarcan una variedad de contextos; desde asistencia en la redacción de productos sencillos, como una receta de cocina o una lluvia de ideas; hasta los más complejos, como la creación de un libro o un proyecto de investigación de interés académico con contenidos pertinentes según sea el caso. Cabe destacar que el desarrollo y la implementación de tecnologías de la IAG conllevan también desafíos y cuestiones éticas, sobre todo en relación a la generación automática de contenidos, factor que plantea preguntas sobre la autoría, la originalidad y la veracidad de los mismos. Al respecto, Mantegna (2020) anota que \"la noción de originalidad tiene un componente subjetivo que se requiere del creador, a la par que un componente objetivo que se deriva de su observación y comparación con otras obras ya creadas\". Mientras que Muñoz (2022) ha aportado al tema desde el punto de vista legal y, ante la interrogante de si es posible proteger con el derecho de autor una obra generada totalmente por una aplicación de IA, alude que \"se ha intentado responder haciendo un estudio sobre la importancia de la autoría humana en el contexto de los derechos de autor, concluyendo que están exentas de ese amparo legal\". Otro punto a considerar tiene que ver con la responsabilidad de las y los usuarios en la difusión de información precisa y confiable obtenida de aplicaciones de IAG, ante la preocupación de la posible propagación de desinformación o sesgos informativos por el mal uso de estas tecnologías o por la carente validación y corroboración de los contenidos obtenidos. Sobre este asunto, Baeza (2023) anota que una tecnología como ChatGPT no entiende lo que escribe en realidad, \"sino que predice cuál es la siguiente palabra más probable en el texto que genera, no está realmente mintiendo, pues no sabe si un hecho es falso o no, pues no tiene una base de datos de conocimiento detrás\"; y anota que es tal la popularidad de esta herramienta que en tan sólo dos meses logró captar a 100 millones de usuarios. Este autor también reconoce que, siendo un modelo de lenguaje basado en IA, esta aplicación (ChatGPT) puede presentar diferentes problemas: sesgo en las respuestas, limitaciones de conocimiento, incoherencia, falta de comprensión del contexto y generación de contenido inapropiado. Sobre esta misma herramienta, Carrasco, et al., (2023) señalan que \"desde su lanzamiento ha cosechado un gran éxito, siendo capaz de generar respuestas automáticas a peticiones complejas como la elaboración de resúmenes, poemas, textos de programación informática y complejos problemas matemáticos\", razón por la cual se refuerza su creciente popularidad. En la presente era digital, la IAG constituye una serie de sistemas complejos de lenguaje que supone avances tecnológicos y desafíos éticos en razón de su uso, alcance e impacto; sin poder evadir el asunto de la calidad de sus contenidos ni obviar el hecho de que en la actualidad son millones de personas las que interactúan con sus aplicaciones con fines variopintos; y su incorporación a la vida profesional, académica y del día a día no para de crecer, razón que motiva a investigar su impacto en los sistemas relacionales humanos, los productos propios del intelecto que generan, y su efecto en las sociedades y culturas por los propósitos y fines específicos de las personas que las utilizan. Es importante tener en cuenta las capacidades y limitaciones de las tecnologías de la IAG, y sus implicaciones en la producción, distribución y consumo de conocimiento en la sociedad actual. Tras revisar la literatura citada, el presente documento busca considerar los desafíos que las aplicaciones de la IAG introducen a los contextos humanos desde su irrupción porque, desde entonces, han conseguido transformar las experiencias y las expectativas en la generación de contenidos y la manera en la que son gestionados y aplicados por las personas. Cabe hacer mención que este artículo forma parte de un proyecto de tesis en curso (en vías de finalizar) para obtener el grado de doctorado en educación de la autora. El objetivo es explorar el impacto potencial de la IAG en la forma en la que se crea, consume, gestiona y comparte conocimiento. Esta pieza presenta resultados parciales, mismos que se complementarán con otros instrumentos a publicarse cuando concluya la investigación. Metodología El propósito del presente artículo es abordar la irrupción de la inteligencia artificial generativa y los desafíos que plantea esta rama de la IA en la sociedad digital actual. Para alcanzar tal objetivo se revisó la literatura disponible desde diversas ópticas y se desarrolló una metodología para aproximarse a la experiencia y opinión de usuarios de estas tecnologías respecto a la generación de textos. El objeto de estudio está enmarcado la inteligencia artificial generativa y la percepción de su uso desde su irrupción, los retos que impone y la ética de la tecnología que exige; siendo los usuarios de las aplicaciones el sujeto de estudio del presente trabajo (Hernández, 2010). El trabajo se centra en la investigación cualitativa y se seleccionó la técnica de cuestionario, definida por Bresque et al., (2011) como \"una forma de encuesta caracterizada por la ausencia del encuestador, por considerar que para recoger información sobre el problema objeto de estudio es suficiente una interacción impersonal con el encuestado\". Por tal razón se acudió a esta técnica de recogida de datos que, según los propios autores, \"puede prestar un importante servicio en la investigación cualitativa\". Lo anterior motivó el diseño de un instrumento de 40 ítems cerrados en escala Likert para aproximarse a los usuarios. Cinco expertos de un grupo interdisciplinario lo evaluaron y validaron la confiabilidad y validez del mismo. La versión final se integró de 30 ítems cerrados en escala Likert. Cabe hacer mención que, de acuerdo a Arribas (2004), \"el propósito de la escala va a determinar en gran medida el contenido de sus ítems y algunos aspectos relacionados con su estructura y la logística de la recogida de los datos\". El instrumento se aplicó a una muestra por conveniencia en un muestreo no probabilístico, que según Otzen y Manterola (2017) \"permite seleccionar aquellos casos accesibles que acepten ser incluidos. Esto, fundamentado en la conveniente accesibilidad y proximidad de los sujetos para el investigador\". Los casos accesibles (usuarios de aplicaciones de inteligencia artificial generativa de textos) voluntariamente consintieron formar parte de la investigación al responder el cuestionario, mediante una invitación abierta del 17 al 19 de junio del 2023, a través de la red social Twitter (ahora X). En su primera parte, el instrumento solicitó datos sociodemográficos generales para conocer el perfil de los participantes: correo electrónico, edad, género, país de nacimiento, país de residencia, escolaridad y área de desempeño. Después de completar este apartado, se centraron 10 ítems en los usos de la inteligencia artificial generativa y la manera en que los usuarios se relacionan con estas tecnologías y cómo las utilizan: sensaciones y sentimientos al usarlas, utilidad y percepciones. Los siguentes 7 ítems se enfocaron en la opinión de la calidad de la información arrojada por las aplicaciones de la inteligencia artificial generativa: confiabilidad, utilidad, corroboración de la información, preocupaciones y sesgos informativos. En relación a las aplicaciones y el conocimiento de la inteligencia artificial generativa se cuestionó en 9 ítems sobre: contribuciones, sesgos y afectaciones al conocimiento, amenazas, democratización del acceso al conocimiento. Los últimos 4 ítems se enfocaron en la opinión de las y los usuarios sobre la ética tecnológica: derechos de autor, propiedad intelectual, regulaciones y preocupaciones de su uso. Es importante considerar que, de que los sujetos de estudio expresaron su consentimiento informado para participar en el instrumento al principio del cuestionario, todos los ítems requerían una respuesta obligatoria para poder avanzar y culminar. Resultados El estudio contó con la participación voluntaria de 108 personas usuarias de aplicaciones de la inteligencia artificial generativa. Los resultados fueron divididos en las siguientes categorías de análisis, teniendo como eje las aplicaciones de la inteligencia artificial generativa: usos, calidad de la información, impacto en el conocimiento y ética tecnológica. Un dato que llamó la atención es que la mayoría de los participantes, casi el 93%, nacieron en México y el resto en Estados Unidos, Honduras, Cuba, Colombia, Chile, Brasil, España y Francia. Una proporción similar indicó residir en territorio mexicano; los que no vivían en el país, lo hacían en Estados Unidos, Chile, Brasil, España y Alemania. La mitad de los participantes manifestó tener entre 31 y 40 años cumplidos, siendo la mayoría hombres quienes respondieron el instrumento (casi 57%). La escolaridad predominante de los participantes es la licenciatura (47%), aunque el grado de maestría también registró una presencia importante (41%). La mayor parte de quienes contestaron el instrumento se desempeñan en el área de ciencias sociales y humanidades, seguidos por rubro de la educación. Por el interés para este estudio, se destacan las siguientes respuestas que se presentan a continuación: Ítem 5. Creo que la inteligencia artificial ha influido directamente en la mejora de la calidad y las condiciones de vida de la sociedad, y que su uso creará nuevas y mejores oportunidades para los seres humanos: 6.50 Totalmente de acuerdo, 30.60 De acuerdo, 50.00 Indeciso, 8.30 En desacuerdo, 4.60 Totalmente en desacuerdo Ítem 9. Considero que el uso de la inteligencia artificial generativa sustituirá tareas realizadas por las personas, desatará una pérdida de empleos y llevará a una crisis del desarrollo y el pensamiento humano: 18.50 Totalmente de acuerdo, 31.50 De acuerdo, 28.70 Indeciso, 18.50 En desacuerdo, 2.80 Totalmente en desacuerdo Ítem 15. Me parece que las respuestas de los chats de las aplicaciones de inteligencia artificial generativa de textos como ChatGPT, Copy.ai, Jasper, Claude, Bard u otras similares ofrecen información limitada, superficial o incorrecta que puede afectar de manera negativa la transmisión del conocimiento: 9.30 Totalmente de acuerdo, 32.40 De acuerdo, 44.40 Indeciso, 13.90 En desacuerdo, 0.00 Totalmente en desacuerdo Ítem 18. Considero que las aplicaciones de inteligencia artificial generativa de textos son herramientas valiosas para el aprendizaje, la investigación y la generación de conocimiento: 12.00 Totalmente de acuerdo, 46.30 De acuerdo, 32.40 Indeciso, 7.40 En desacuerdo, 1.90 Totalmente en desacuerdo Ítem 20. Considero que el uso de aplicaciones de inteligencia artificial generativa de textos como ChatGPT, Copy.ai, Jasper, Claude, Bard u otras similares me hacen pensar menos y/o esforzarme menos: 18.50 Totalmente de acuerdo, 33.30 De acuerdo, 25.00 Indeciso, 22.20 En desacuerdo, 1.00 Totalmente en desacuerdo Ítem 23. Creo que las aplicaciones de inteligencia artificial generativa de textos pueden democratizar el acceso al conocimiento al hacerlo más accesible a públicos más amplios: 15.70 Totalmente de acuerdo, 41.70 De acuerdo, 25.90 Indeciso, 14.80 En desacuerdo, 1.90 Totalmente en desacuerdo Ítem 30. Tengo preocupaciones éticas relacionadas con el uso de aplicaciones de inteligencia artificial generativa de textos como ChatGPT, Copy.ai, Jasper, Claude, Bard u otras similares: 10.20 Todos los días, 11.10 Casi todos los días, 49.10 Ocasionalmente, 25.00 Casi nunca, 4.60 Nunca Discusión y conclusiones La introducción de nuevas tecnologías a la vida cotidiana de los seres humanos implica una transformación, en mayor o menor escala, en sus interacciones y percepción de la vida. La tecnología abraza una amplia gama de disciplinas que precisan de la puesta en práctica de \"conocimientos científicos y la comprensión del universo para resolver problemas y mejorar la vida humana\"; esto comprende un \"conjunto de herramientas, técnicas, procesos y sistemas que se utilizan para crear, diseñar, producir y mejorar productos, servicios y sistemas en diversos campos de actividad\" (Carvajal, 2023). En este sentido, \"las tecnologías disruptivas rompen con las que existían hasta el momento, generando resultados novedosos en sus aplicaciones, como hacer que los objetos hablen entre ellos\" (Pérez, 2019). Es posible inferir que esta literatura refuerza la opinión de los participantes en el instrumento de indecisión o de manifestarse de acuerdo (ambas suman el 80% de las respuestas) reflejadas en el ítem 5 respecto a si una tecnología como la IA influye directamente en la mejora de la calidad y las condiciones de vida de la sociedad, y que su uso creará nuevas y mejores oportunidades para los seres humanos. Las características de la sociedad en la era digital, a diferencia de las generaciones predecesoras, permiten una buena acogida de las nuevas tecnologías. Terceiro (1996) ya lo vaticinaba hace casi treinta años cuando reflexionó que con los nuevos sistemas de comunicación la humanidad se dirigía a un panorama en donde los servicios serían más apreciados que los bienes, \"donde la gente preferirá ganar menos y tener más tiempo disponible para dedicarlo, precisamente, al consumo de esa más robusta oferta de servicios ofrecidos por el mundo hipermedia, ya sean de entretenimiento, educación o sanitario\"; cuyos efectos sociales incidirían en sectores específicos como el lugar de trabajo, el cual dejaría de requerir una ubicación en centros urbanos; y el hogar de las personas, que ya no tendría que estar en el mismo país de quien las contrata, aspectos de observamos como una realidad en nuestros días. De acuerdo a Carvajal (2023) el uso de la tecnología —visible en dispositivos electrónicos y máquinas complejas, aplicaciones y sistemas informáticos avanzados— se centra en facilitar la adaptación de un individuo a su entorno individual y colectivo, por lo que buscará mecanismos de solución que sean veloces y precisos \"para satisfacer las necesidades y deseos de las personas en aspectos físicos, como la salud, la alimentación y la vivienda, así como en aspectos sociales y culturales, como la comunicación, el entretenimiento, la educación y el transporte\". Sin embargo, en la actualidad, es útil la visión de Pérez (2019) quien ha anotado un punto relevante para el cambio acelerado que experimenta la sociedad respecto al uso de la desarrollos generativos de la IA pues, según sus palabras, la tecnología siempre ha impulsado las capacidades humanas, pero de una forma pasiva, lo que ha sido de utilidad para lograr ciertas actividades, la cuestión es que en nuestros días \"se ve un cambio drástico. Por primera vez la tecnología toma un rol activo en el trabajo junto a los seres humanos y, en algunos casos, reemplazándolos\". Esta observación ayuda a comprender mejor la percepción de los participantes del instrumento, cuya opinión manifestada de acuerdo o postura indecisa (ambas suman el 60% de las respuestas) en el ítem 9, respecto a si consideran que el uso de la inteligencia artificial generativa sustituirá tareas realizadas por las personas, desatará una pérdida de empleos y llevará a una crisis del desarrollo y el pensamiento humano. La conclusión de Terceiro (1996) anota que \"el exceso de información disponible conducirá al desbordamiento producido por la información de baja calidad, por lo que se hace necesario seleccionar y filtrar la información, lo que hará surgir un tipo de trabajo que requerirá un conocimiento especializado\", ayuda a dimensionar en parte la opinión indecisa o de acuerdo (ambas suman el 67 % de las respuestas) del ítem 15: Me parece que las respuestas de los chats de las aplicaciones de inteligencia artificial generativa de textos como ChatGPT, Sydney, Copy.ai, Jasper, Claude, Bard u otras similares ofrecen información limitada, superficial o incorrecta que puede afectar de manera negativa la transmisión del conocimiento. Cabe destacar que esto conduce a observar uno de los desafíos introducidos por la inteligencia artificial generativa en una era caracterizada por la hiperinformación, debido a que ante un flujo indiscriminado de información y de datos, es indispensable seleccionar, filtrar, corroborar y validar los productos de texto arrojados por las aplicaciones de la IAG para evitar sesgos, desinformación y una posible desvirtuación del conocimiento. Respecto al ítem 18, sobre si las aplicaciones de inteligencia artificial generativa de textos son herramientas valiosas para el aprendizaje, la investigación y la generación de conocimiento, las mayoría de las respuestas (43%) manifestaron estar de acuerdo. Chomsky et al., (2023) han manifestado que \"ChatGPT de OpenAI, Bard de Google y Sydney de Microsoft son maravillas del aprendizaje automático\". Los teóricos explican que estas aplicaciones de la inteligencia artificial generativa \"toman enormes cantidades de datos, buscan patrones en ellos y se vuelven cada vez más competentes a la hora de generar resultados estadísticamente probables, como un lenguaje y un pensamiento aparentemente humanos\". De acuerdo a su visión, estas aplicaciones de la IA son prueba de aquello que se ha profetizado desde hace varias décadas respecto a que las mentes mecánicas puedan superar a los cerebro de los seres humanos \"no sólo cuantitativamente en términos de velocidad de procesamiento y tamaño de la memoria, sino también cualitativamente en términos de perspicacia intelectual, creatividad artística y cualquier otra facultad distintivamente humana (Chomsky et al., 2023). Una de las preocupaciones que introducen estas tecnologías disruptivas tienen que ver con el impacto que pueden tener los sistemas de IA y la tremenda dependecia o los usos desadaptativos al utilizarlas. En un campo específico como el de la educación, Zapata-Ros (2023) es contundente y advierte que \"se podría derivar una disminución de muchos de los rasgos que nos hacen humanos. En este caso, que contribuirían a una formación humana de los alumnos\". Cabe haer mención de que los rasgos a los que hace referencia están relacionados a \"la autorregulación, la metacognición, la orientación a objetivos, la planificación, las tormentas de ideas creativas y una variedad de habilidades que podrían verse afectadas negativamente por la automatización o la toma de control de las máquinas\". Esta concepción tiene una relación con el ítem 20, sobre la consideración de si el uso de aplicaciones de inteligencia artificial generativa de textos como ChatGPT, Copy.ai, Jasper, Claude, Bard u otras similares hacen pensar menos y/o esforzarse menos, donde cabe observar que en este punto se impuso la respuesta \"de acuerdo\" (46%), seguida del 32% que expresó indecisión. Sobre la creencia de si las aplicaciones de inteligencia artificial generativa de textos pueden democratizar el acceso al conocimiento al hacerlo más accesible a públicos más amplios, cuestión planteada en el ítem 23, el 41% de las respuestas de los participantes concidió estar de acuerdo. Miranda (2020), sugiere por su parte que \"la co creación, selección, divulgación, deconstrucción de tesis y elaboración de claves interpretativas de la realidad en discursos multi y transdisciplinarios a favor de la democratización del conocimiento y la inclusión\". Este pensamiento podría ser de utilidad en relación a lo que introducen las aplicaciones de la inteligencia artificial generativa, debido a que no son entes aislados sino que son operados por individuos que se enmarcan en contextos y coyunturas específicas, en tiempos determinados, y en sociedades heterogéneas; sin embargo, los esfuerzos actuales respecto a las bondades que ofrecen estas tecnologías novedosas podrían considerar una orientación hacia la democracia y el acceso del conocimiento a diferentes públicos, puesto que en palabras del autor: \"Las sociedades transitan hacia las libertades, diversidad, pluralidad, defensa de los derechos humanos y democracias más participativas\". Las máquinas inteligentes desarrolladas podrían contribuir a tal fin; trabajando en favor de los seres humanos como una extensión de sus propias mentes, y no en su contra, tal como lo sugiere Bidshahri (2017), quien anota que desde hace mucho se ha valorado a la tecnología como \"un mecanismo liberador de recursos, que nos garantiza un mejor acceso a recursos como la información, los alimentos y la energía\", complementando que, en lo que no reparamos es en \"el revolucionario impacto que la tecnología puede tener en nuestra capacidad para crear\". Mientras que Tobón y Rojas (2006), consideran que la gestión del conocimiento es un asunto de gran relevancia porque \"progresivamente se avanza hacia una sociedad del conocimiento en la cual el capital esencial es el conocimiento\" el cual es también un \"elemento clave para vivir, relacionarse con otros, y crear e innovar productos y servicios\". Tal como se ha mencionado con anterioridad, está en boga lo concerniente a las preocupaciones éticas de algunos teóricos en la materia respecto al uso de aplicaciones de inteligencia artificial generativa de textos por el público en general (ítem 30 del cuestionario). En el caso de las respuestas más recurrentes de las personas que respondieron el instrumento fueron: ocasionalmente y casi nunca (ambas suman el 79%). Esta tendencia se enmarca en las aportaciones de Chomsky et al., (2023) quienes se han considerado la preocupación o el optimismo con el que se han recibido los avances \"supuestamente revolucionarios\" en el campo de la inteligencia artificial. En el caso del optimismo, los autores observan que \"la inteligencia es el medio con el que resolvemos los problemas\"; mientras que la preocupación surge debido a que \"tememos que la variedad más popular y de moda de la inteligencia artificial —el aprendizaje automático— degrade nuestra ciencia y envilezca nuestra ética al incorporar a nuestra tecnología una concepción fundamentalmente errónea del lenguaje y el conocimiento\". En un artículo, Molina y Quinde (2023) citan la postura y políticas de ética editorial de la prestigiosa e importante publicación científica Cambridge University Press sobre artículos de investigación, libros y otros trabajos académicos. De la normatividad referida se destaca lo siguiente por ser de interés para la temática del presente documento: el uso de la inteligencia artificial \"debe declararse y explicarse claramente en publicaciones como los trabajos de investigación\"; la IA no cumple los requisitos de esa institución sobre la autoría debido a la imposibilidad de \"rendir cuentas\"; lo anterior conduce a que aplicaciones de la IAG no podrán aparecer como autores en las publicaciones; sin embargo, su uso tampoco debe transgredir sus políticas de plagio\". Observar un tema que implica tecnologías de tal nivel, compromete a explorar la perspectiva ética y la posibilidad de implementar un marco normativo que permitar hacer un uso equilibrado de éstas en razón del bien común; según Giraldo (2008) moverse hacia la ética permite lograr una comprensión mucho más amplia de la resistencia, vista esta como un preocupación, a la vez de \"estética de la existencia\" en relación al planteamiento de Michel Foucault. Por otro lado, sobre de qué manera proceder en este aspecto, según Flores y García (2023) \"las regulaciones y ética de la IA deben lograrse sin comprometer los valores humanos, sin socavar la diversidad y sin crear nuevas desigualdades\". En relación a la ética de las máquinas, Gamboa (2020) va más allá en sus consideraciones y refiere que parece que escapa al dominio humano la intención de \"ubicar a las inteligencias humana y artificial en un contexto universal, con orígenes comunes y desarrollos por procesos generales\"; lo anterior debido a que, en sus propias palabras, esto \"implica que en cada ser con IA general habrá necesariamente una condición moral: deberá ser respetado y tener los mismos derechos que los seres humanos\". Cabe destacar que, en los resultados de la investigación, la relación estrecha en las respuestas de los participantes entre estar de acuerdo o indeciso sobre los planteamientos del instrumento llaman especialmente la atención. Es pertinente inferir que es una reacción natural ante un escenario incipiente que aún no supera el año desde que la primera aplicación de IAG estuvo disponible para los usuarios, esto a propósito de lo planteado por Chomsky, Roberts y Watumull sobre las preocupaciones o el optimismo con el que estas tecnologías disruptivas pueden ser recibidas y adoptadas por el público en general, mismas que pueden estar más alimentadas por los prejuicios o la desinformación, que por una experiencia consistente en su uso. Estas dudas son legítimas, varios autores dan cuenta de ello, como Morcela (2022) que afirma que \"la IA puede tener beneficios para la eficiencia y la productividad en el lugar de trabajo, también plantea dudas legítimas sobre el impacto en el empleo, la justicia y la equidad, y la falta de control humano\". Respecto a la ética digital para las nuevas generaciones de la era digital, Balladares (2017) plantea la pertinencia de implementarla de manera urgente, debido a que \"desde una perspectiva ética, se pueden identificar valores de las generaciones digitales, para luego plantear una ética digital como una ética aplicada que busca síntesis y mediación entre el ser humano y la tecnología\". Es importante hacer mención de que \"no vivimos un tiempo de cambios, sino un cambio de tiempos. Esta trasformación del paradigma civilizatorio confronta las premisas del pasado\" (Miranda, 2020). Esta afirmación contundente de nos lleva a reflexionar sobre la necesidad de no evadir el tema de tecnologías disruptivas como la IAG por miedo o desconocimiento, pues no podemos abstraernos de lo que sucede aquí y ahora. En tales circunstancias, un reto a considerar es el tiempo que los seres humanos en la era digital están dispuestos a destinar a tareas relacionadas a la información, investigación, redacción, generación de contenidos y validación de los mismos. Bauman (2015) plantea el concepto de modernidad líquida, con el propósito de describir la condición de la sociedad contemporánea caracterizada por la flexibilidad, la incertidumbre y la falta de estructuras sólidas y duraderas. Se caracteriza por el cambio frecuente de trabajos, lugares de residencia, de parejas e incluso identidades en comparación con épocas anteriores; por el desdén de cargar con las responsabilidades, la necesidad de contar con herramientas que indiquen cómo hacer las cosas, qué desechar y cómo moverse en un tiempo en donde todo fluye de manera acelerada; y por la noción de que las normas y los valores tradicionales ya no tienen la misma influencia, razón que conduce a las personas a enfocarse en la búsqueda de la satisfacción individual y la gratificación inmediata. Esta visión es de utilidad para comprender la buena acogida de aplicaciones de la inteligencia artificial generativa que ofrecen resultados casi en tiempo real. Este sociólogo también aborda el asunto de la desintegración de la trama social y la manera en que las agencias de acción colectiva se desmoronan en escenarios cambiantes, escurridizos y evasivos en una era de modernidad líquida, y advierte que \"la desintegración social es tanto una afección como un resultado de la nueva técnica del poder, que emplea como principales instrumentos el descompromiso y el arte de la huida\" de los seres humanos (Bauman, 2015). Lo expuesto anteriormente plantea retos, pues en ojos de autores como el filósofo Byung-Chul Han, \"lo que enferma a la sociedad no es la alienación, la sustracción, la prohibición ni la represión, sino la hipercomunicación, el exceso de información, la sobreproducción y el hiperconsumismo\" Han, (2018). Este pensador también ha ahondado en la revolución digital con la finalidad de explicar la dinámica de las sociedades actuales y analizar lo relacionado al vertiginoso crecimiento del mundo digital que, según su observación, implica una transición entre el universo de lo tangible hacia una era caracterizada por la información y los datos, factor que despoja al mundo de su condición material. Esta interpretación de la actualidad coincide con la de Copa (2019), quien anotó que en este siglo hemos transitado \"del espacio físico al hiperespacio digital y de las interacciones directas, cara a cara, a las mediadas por pantallas y dispositivos digitales\". Estas condiciones implican un cambio de paradigma en las interacciones humanas y también en las interacciones entre humanos y máquinas inteligentes que desafían los sistemas interrelacionales conocidos hasta ahora. Hace más de dos décadas, Brunner (2001) advertía que la humanidad se encontraba en el umbral de un transformación profunda y, en ese tiempo, su hipótesis se concentraba en que se aproximaba una cuarta revolución de una magnitud extraordinaria. Tres lustros más adelante, Perasso (2016) vaticinó que la humanidad se encontraba al límite de \"una revolución tecnológica que modificará fundamentalmente la forma en que vivimos, trabajamos y nos relacionamos. En su escala, alcance y complejidad, la transformación será distinta a cualquier cosa que el género humano haya experimentado antes\". Sobre la cuarta revolución industrial, Schwab (2020) escribió pocos años depués que, aunque no existía una certeza de cómo se desarrollará, sí hizo hincapié en una de las posibles formas de hacerle frente y planteó que \"la respuesta a sus cambios debe ser integrada y exhaustiva, y deberá involucrar a todos los actores de la política global, desde los sectores público y privado, hasta la academia y la sociedad civil\". En conclusión, sin bien la manera en la que se utiliza la tecnología digital toca y transforma los sistemas sociales sin excepción, el desarrollo de la inteligenicia artificial en los últimos diez años, con un énfasis en la irrupción de herramientas de la inteligencia artificial generativa –como Chat GPT– ha cambiado los paradigmas e introduce nuevos desafíos sobre lo que se había proyectado (Giró y Sancho, 2022). Además, aunque cada vez es más evidente la utilización de las aplicaciones y herramientas de la inteligencia artificial en la vida cotidiana de los seres humanos; falta mucho por trabajar y por organizar antes de implementar esta tecnología de manera consistente en diferentes rubros (Padilla, 2019). En una era donde la información y la tecnología bien podrían servir como emblema, la irrupción de la inteligencia artificial generativa ha tenido un impacto sin precedentes con aplicaciones disponibles al público en general capaces de crear contenidos de texto de forma autónoma; mediante la guía y las solicitudes específicas de las y los usuarios de las mismas. Este fenómeno pone de manifiesto la redefinición de cómo se crean y gestionan los textos que generan estas herramientas, lo cual supone beneficios potenciales para las personas que las adopten como aliadas para incentivar la creatividad, el acceso al conocimiento o como una posibilidad de ahorrar tiempo al utilizarlas; sino considerar también los posibles efectos negativos provocados por su introducción como la falta de revisión de la información obtenida, la generación y reproducción de contenido sin aplicar filtros de calidad, o las laxas y/o inexistentes políticas sociales e institucionales sobre las cuestiones éticas y de responsabilidad que demandan. A medida de que estas tecnologías disruptivas crean contenidos de texto, surge de manera inherente la necesidad de comprender cómo funcionan, cuáles son sus limitaciones y de qué manera es posible potenciar su uso en beneficio no sólo de quienes las utilizan, sino de las sociedades y sus instituciones; y no en perjuicio de los mismos.",
      "word_count": 6855,
      "character_count": 44264,
      "vector": [
        0.18523114919662476,
        -0.17947135865688324,
        0.11505933105945587,
        -0.01587430015206337,
        0.051809705793857574,
        -0.05054694414138794,
        -0.0454644039273262,
        0.018264157697558403,
        -0.02184595912694931,
        0.05922107771039009,
        -0.02695547044277191,
        0.07419249415397644,
        0.04243664816021919,
        -0.005227110348641872,
        0.04299714416265488,
        0.056762345135211945,
        -0.03508299961686134,
        0.034346334636211395,
        -0.10895562916994095,
        -0.03549855574965477,
        -0.04078622907400131,
        -0.0097338343039155,
        0.07550526410341263,
        0.13495348393917084,
        -0.040389373898506165,
        0.007207984570413828,
        -0.09473234415054321,
        -0.07130708545446396,
        -0.010678837075829506,
        -0.039627596735954285,
        0.10749086737632751,
        -0.10767299681901932,
        0.004830686375498772,
        -0.06273079663515091,
        0.021898118779063225,
        0.030316462740302086,
        0.05432121455669403,
        -0.04917406290769577,
        -0.026435531675815582,
        -0.06849069893360138,
        -0.007003528531640768,
        -0.041303601115942,
        0.026739463210105896,
        -0.01919427141547203,
        0.09845592826604843,
        0.04637553170323372,
        0.018070824444293976,
        0.01042290311306715,
        0.004851865116506815,
        0.04296613484621048,
        0.05495551601052284,
        0.0649084746837616,
        -0.018571557477116585,
        0.05751333758234978,
        0.02754294127225876,
        -0.025179656222462654,
        0.04736364632844925,
        0.021833395585417747,
        -0.038153454661369324,
        0.015071172267198563,
        -0.017678916454315186,
        0.04842224344611168,
        0.028295448049902916,
        -0.059575289487838745,
        -0.05521569028496742,
        0.03568350151181221,
        -0.07035534828901291,
        -0.06077481433749199,
        -0.057353660464286804,
        0.0167939942330122,
        0.0050730095244944096,
        0.039504554122686386,
        0.013089193031191826,
        0.06682518869638443,
        -0.027402905747294426,
        0.07823922485113144,
        -0.06213654577732086,
        -0.020306644961237907,
        0.001056895824149251,
        -0.0010723350569605827,
        0.1114203929901123,
        0.015707381069660187,
        0.05227687209844589,
        -0.0007685718592256308,
        0.04683644697070122,
        -3.366065720911138e-05,
        -0.028556929901242256,
        0.024881402030587196,
        0.04599003866314888,
        -0.09474468976259232,
        -0.007217799313366413,
        -0.09394142031669617,
        -0.051060158759355545,
        -0.12742623686790466,
        0.060586147010326385,
        0.0031843911856412888,
        -0.020192936062812805,
        0.02369200438261032,
        -0.007973553612828255,
        -0.016640080139040947,
        0.0009318440570496023,
        0.07298054546117783,
        -0.09098915755748749,
        0.060999203473329544,
        -0.009098799899220467,
        0.0429210439324379,
        0.0001568409352330491,
        0.0255122072994709,
        -0.05517753213644028,
        0.023365501314401627,
        -0.0381755493581295,
        0.006759180687367916,
        0.03073381818830967,
        -0.04180692881345749,
        -0.010388313792645931,
        0.05548055097460747,
        -0.05509762465953827,
        0.07316897809505463,
        0.029735907912254333,
        -0.01934184692800045,
        0.06652157008647919,
        0.01908520795404911,
        -0.03399181365966797,
        0.0014347272226586938,
        -0.013167900033295155,
        -0.015488849021494389,
        -0.01657463237643242,
        0.01472461223602295,
        0.014942058362066746,
        -0.07219719886779785,
        -0.001938911504112184,
        0.021828865632414818,
        -0.022080352529883385,
        0.029874715954065323,
        -0.03378540650010109,
        -0.007639429997652769,
        0.015573046170175076,
        -0.04523194581270218,
        0.004273322876542807,
        0.035287629812955856,
        0.0032366598024964333,
        0.06924308091402054,
        0.006472248118370771,
        -0.014627104625105858,
        -0.018322408199310303,
        -0.06826713681221008,
        -0.015072325244545937,
        0.03882301598787308,
        -0.002957266988232732,
        0.004659224301576614,
        0.02309245616197586,
        0.011575560085475445,
        -0.015471387654542923,
        0.03954026848077774,
        -0.011998079717159271,
        0.012781916186213493,
        0.011249200440943241,
        0.024776794016361237,
        -0.02417410910129547,
        -0.010392612777650356,
        -0.0034325867891311646,
        0.026249300688505173,
        0.00350520433858037,
        0.03230387344956398,
        -0.02728317305445671,
        0.0038851136341691017,
        -0.026548245921730995,
        0.034922294318675995,
        0.007634215988218784,
        0.003415602259337902,
        -0.060448311269283295,
        -0.004699243698269129,
        -0.002880390966311097,
        0.0034603793174028397,
        0.00039239603211171925,
        -0.04244142770767212,
        0.032596781849861145,
        0.07635701447725296,
        0.017978088930249214,
        0.08365242183208466,
        0.06100483983755112,
        -0.03390929102897644,
        -0.05968109890818596,
        0.03743187338113785,
        -0.0332966111600399,
        0.01468830369412899,
        0.012709627859294415,
        0.016668742522597313,
        0.025827329605817795,
        -0.03776109591126442,
        0.010146882385015488,
        -0.015651406720280647,
        0.04754354804754257,
        0.02670629695057869,
        -0.01907319761812687,
        -0.0213687215000391,
        -0.04020540416240692,
        -0.004769468680024147,
        0.05187627673149109,
        -0.03492896631360054,
        -0.03161371871829033,
        -0.019952576607465744,
        -0.03333576023578644,
        0.0001673649821896106,
        0.019609319046139717,
        0.021305330097675323,
        -0.004447679966688156,
        -0.02394717186689377,
        -0.0010547953424975276,
        0.06340240687131882,
        0.016616370528936386,
        0.033573977649211884,
        0.054252203553915024,
        0.006113171111792326,
        -0.02377014234662056,
        -0.020047932863235474,
        0.0006048380746506155,
        0.060816310346126556,
        0.0627271831035614,
        -0.025546645745635033,
        0.024121448397636414,
        0.00743307126685977,
        -0.0186837837100029,
        -0.01131660956889391,
        -0.01788313500583172,
        0.044459018856287,
        -0.032198715955019,
        0.06009000912308693,
        -0.0020205003675073385,
        0.018467944115400314,
        0.032271310687065125,
        0.04239431023597717,
        0.01741046831011772,
        0.005224070977419615,
        -0.00823758915066719,
        -0.010110500268638134,
        -0.007121505215764046,
        -0.02248516120016575,
        0.058276042342185974,
        -3.6224333598511294e-05,
        -0.054127272218465805,
        -0.026186615228652954,
        -0.03801992908120155,
        0.02366173267364502,
        -0.09198286384344101,
        0.006684131920337677,
        -0.0384657122194767,
        -0.042558081448078156,
        -0.03579805791378021,
        0.004954889882355928,
        0.07543247938156128,
        0.0016289071645587683,
        -0.051824938505887985,
        -0.04285334795713425,
        0.04796045273542404,
        -0.01209175493568182,
        0.02202681265771389,
        -0.029041359201073647,
        -0.04625469446182251,
        0.01058898027986288,
        -0.02374975197017193,
        0.011570648290216923,
        -0.014191169291734695,
        0.016966162249445915,
        0.008205755613744259,
        0.007015157490968704,
        -0.009336731396615505,
        -0.014458329416811466,
        0.009204532951116562,
        -0.08211761713027954,
        -0.01752680540084839,
        -0.022080132737755775,
        -0.06564735621213913,
        0.039005592465400696,
        -0.012183685787022114,
        0.030850471928715706,
        -0.019202429801225662,
        -0.003431654768064618,
        -0.016219377517700195,
        -0.007022550795227289,
        -0.056105125695466995,
        -0.0019722378347069025,
        0.0007065300014801323,
        0.01796741597354412,
        -0.020654523745179176,
        -0.01491039153188467,
        0.03864704817533493,
        0.007319880183786154,
        0.00965435616672039,
        0.0065537104383111,
        0.00906736496835947,
        -0.03161102160811424,
        -0.002324238885194063,
        -0.009187296964228153,
        -0.016722729429602623,
        0.009357857517898083,
        -0.07828042656183243,
        -0.0008112063515000045,
        0.054492317140102386,
        0.00754321925342083,
        -0.04956071823835373,
        -0.0014630903024226427,
        0.019480712711811066,
        0.021012507379055023,
        -0.005915376357734203,
        -0.026123734191060066,
        -0.04180959612131119,
        -0.03188841789960861,
        -0.02957850880920887,
        -0.019075406715273857,
        -0.01290633250027895,
        -0.0205428097397089,
        0.009260840713977814,
        0.019316334277391434,
        -0.004224024713039398,
        0.02696475200355053,
        -0.0071318140253424644,
        0.04302072525024414,
        0.0013552091550081968,
        0.0011276102159172297,
        -0.01933281123638153,
        0.0021341629326343536,
        -0.00814034417271614,
        0.0045509254559874535,
        -0.02220657281577587,
        -0.028187202289700508,
        -0.0043340097181499004,
        -0.005922921001911163,
        -0.011404811404645443,
        -0.01839706301689148,
        0.006223640870302916,
        0.003959208261221647,
        0.04029880836606026,
        0.03985480219125748,
        0.0008590365177951753,
        -0.029292697086930275,
        -0.005201986990869045,
        -0.006989721674472094,
        0.017375700175762177,
        0.01463597547262907,
        0.022246351465582848,
        -0.015721723437309265,
        0.023863298818469048,
        -0.015970438718795776,
        -0.007585051469504833,
        0.032552801072597504,
        -0.022488344460725784,
        -0.024083880707621574,
        0.030145708471536636,
        0.06511355936527252,
        0.005569203291088343,
        0.0074005997739732265,
        -0.026272254064679146,
        0.01759987697005272,
        0.018145514652132988,
        0.0254738200455904,
        -0.011089341714978218,
        0.013271049596369267,
        0.03603798523545265,
        -0.052583180367946625,
        -0.024869728833436966,
        0.01131834089756012,
        0.0014470173045992851,
        0.03593553602695465,
        -0.026708606630563736,
        0.02021660842001438,
        0.029966721311211586,
        0.026652680709958076,
        -0.0002500591508578509,
        0.015178915113210678,
        -0.04723640903830528,
        0.014403268694877625,
        -0.003098786110058427,
        0.0017395149916410446,
        0.0019945052918046713,
        0.0009913091780617833,
        0.045661669224500656,
        0.021381089463829994,
        0.07291246205568314,
        0.01820097677409649,
        0.004473973531275988,
        -0.05302704498171806,
        0.030227595940232277,
        -0.015978993847966194,
        0.002228876342996955,
        -0.010287536308169365,
        0.08033401519060135,
        -0.04201201722025871,
        0.012107422575354576,
        -0.007462951820343733,
        -0.004031436517834663,
        -0.002340097911655903,
        0.03245571628212929,
        -0.03337615728378296,
        -0.04753397777676582,
        0.007847865112125874,
        0.025508662685751915,
        -0.018024692311882973,
        -0.01784375123679638,
        0.01749170944094658,
        0.021164430305361748,
        -0.023653944954276085,
        0.008210633881390095,
        -0.058564942330121994,
        0.02017994038760662,
        -0.004639378283172846,
        0.03652368113398552,
        -0.003906120313331485,
        -0.04733128845691681,
        0.002004417357966304,
        -0.02307434380054474,
        0.008870314806699753,
        -0.05354948714375496,
        -0.0268549844622612,
        0.003774644574150443,
        -0.05198128893971443,
        0.04191483184695244,
        0.028074802830815315,
        -0.014559578150510788,
        -0.012603150680661201,
        0.046233173459768295,
        0.0458601713180542,
        0.0037638277281075716,
        -0.02604334056377411,
        0.03653009608387947,
        -0.03213294595479965,
        -0.031095677986741066,
        -0.029831234365701675,
        0.032177239656448364,
        0.02378351055085659,
        -0.03939263895153999,
        0.013371956534683704,
        -0.007411412429064512,
        0.02321515791118145,
        0.007126618176698685,
        -0.002834167331457138,
        -0.030474571511149406,
        0.013153987936675549,
        0.009351509623229504,
        0.005842351820319891,
        0.044772807508707047,
        0.02012203261256218,
        0.007077183574438095,
        -0.02864343859255314,
        0.023186486214399338,
        0.013109538704156876,
        0.04937088489532471,
        -0.04146910831332207,
        -0.007272855378687382,
        -0.0023703963961452246,
        0.016945289447903633,
        0.031477924436330795,
        -0.02075185254216194,
        -0.018459226936101913,
        0.02693784050643444,
        -0.02242196723818779,
        0.029029903933405876,
        0.017820442095398903,
        0.004605491645634174,
        0.03479553759098053,
        0.031188061460852623,
        -0.009289924055337906,
        0.029546938836574554,
        -0.019967230036854744,
        0.07624205946922302,
        0.0026208956260234118,
        0.07668537646532059,
        0.04324304684996605,
        0.015126614831387997,
        -0.011919768527150154,
        0.017601434141397476,
        -0.005600211676210165,
        0.009500741958618164,
        -0.017986387014389038,
        0.015170113183557987,
        0.005518728867173195,
        0.01499146781861782,
        -0.013843568041920662,
        -0.01944435015320778,
        -0.0332002192735672,
        0.0101777957752347,
        -0.015128104947507381,
        0.02039368636906147,
        0.009810074232518673,
        0.05226574465632439,
        -0.0537438690662384,
        -0.015750037506222725,
        -0.033545807003974915,
        0.011282620020210743,
        0.018254050984978676,
        -0.00266496604308486,
        -0.0041427044197916985,
        0.018721861764788628,
        0.05860035866498947,
        -0.006359240040183067,
        -0.002842226531356573,
        0.025741366669535637,
        -0.05494053661823273,
        -0.006561269052326679,
        -0.08389753103256226,
        -0.05395315960049629,
        -0.031485654413700104,
        -0.0070317885838449,
        -0.05157623067498207,
        -0.015373652800917625,
        0.0006525645731016994,
        -0.03278714790940285,
        -0.016887998208403587,
        0.016701117157936096,
        -0.011502953246235847,
        -0.03466693311929703,
        0.019588623195886612,
        0.025753570720553398,
        0.013826264068484306,
        -0.008047563023865223,
        -0.013420396484434605,
        0.056666430085897446,
        -0.01779782585799694,
        -0.002300008898600936,
        0.004061103332787752,
        0.014877472072839737,
        0.014109145849943161,
        0.03834851458668709,
        -0.034134216606616974,
        -0.009784406051039696,
        0.022907206788659096,
        -0.0045652384869754314,
        -0.042159631848335266,
        0.03273480758070946,
        -0.026925422251224518,
        0.053127486258745193,
        0.010230086743831635,
        0.01452641375362873,
        -0.005806863307952881,
        0.032764509320259094,
        0.004956681281328201,
        -0.014019548892974854,
        -0.04381117969751358,
        0.015891341492533684,
        -0.012932507321238518,
        -0.020383615046739578,
        -0.010402635671198368,
        0.010332172736525536,
        -0.029521768912672997,
        -0.044909387826919556,
        -0.008908390067517757,
        -0.012286601588129997,
        0.03307729586958885,
        0.016971822828054428,
        0.026569953188300133,
        -0.010500508360564709,
        0.03002784587442875,
        0.009916212409734726,
        -0.010925224050879478,
        0.005723333917558193,
        -0.03943721950054169,
        0.006883259397000074,
        -0.01741374470293522,
        -0.022958043962717056,
        -0.03013603389263153,
        0.01870878040790558,
        -0.011576731689274311,
        0.020334212109446526,
        -0.02830250933766365,
        -0.03822281211614609,
        -0.0068365419283509254,
        -0.021320121362805367,
        0.02149650827050209,
        0.0011583782033994794,
        0.006295245140790939,
        -0.009065782651305199,
        -0.0069087897427380085,
        -0.010857412591576576,
        0.038077134639024734,
        0.0067252302542328835,
        -0.03342454880475998,
        0.003995529375970364,
        0.04116327688097954,
        0.01961236074566841,
        -0.0013091977452859282,
        -0.011217000894248486,
        -0.03102162666618824,
        -0.011810657568275928,
        0.03503794223070145,
        -0.019406186416745186,
        0.027855556458234787,
        -0.010891471058130264,
        -0.03269821032881737,
        0.00046110659604892135,
        0.01761583983898163,
        -0.004153900779783726,
        0.00997803546488285,
        0.0030093505047261715,
        0.018279027193784714,
        0.06315820664167404,
        -0.02701430954039097,
        -0.029784949496388435,
        -0.03509431704878807,
        -0.029609017074108124,
        -0.03201150894165039,
        -0.06491172313690186,
        0.009728597477078438,
        -0.005334286950528622,
        0.022574331611394882,
        0.029238160699605942,
        0.03500532731413841,
        -0.00847566407173872,
        0.005075613968074322,
        -0.04600333049893379,
        -0.01322335284203291,
        0.027478069067001343,
        0.024220982566475868,
        -0.0028676141519099474,
        -0.005744190886616707,
        0.04813343286514282,
        0.0036959804128855467,
        0.01454195473343134,
        -0.041873276233673096,
        -0.0254939217120409,
        0.0013792560203000903,
        0.011842415668070316,
        0.019162669777870178,
        0.03644273430109024,
        -3.131596531602554e-05,
        0.004139889031648636,
        0.0036994621623307467,
        0.03485776111483574,
        0.04375392571091652,
        0.008897737599909306,
        0.026356808841228485,
        -0.00939795933663845,
        0.0028500945772975683,
        0.012806042097508907,
        0.017775211483240128,
        0.004239615518599749,
        0.017389925196766853,
        0.05743296444416046,
        0.012397528626024723,
        0.018160540610551834,
        0.036727841943502426,
        0.017224213108420372,
        -0.008786417543888092,
        0.010543704964220524,
        0.0368482880294323,
        -0.044687557965517044,
        -0.053076185286045074,
        0.021399065852165222,
        -0.02262459695339203,
        0.01143459603190422,
        -0.028353819623589516,
        -0.017919650301337242,
        0.03018859215080738,
        -0.010928982868790627,
        0.0021514901891350746,
        -0.0005781259969808161,
        0.0047353096306324005,
        -0.04183221608400345,
        -0.006653848569840193,
        -0.012599492445588112,
        -0.031802382320165634,
        -0.01899200677871704,
        -0.009563950821757317,
        0.05261663347482681,
        -0.011498114094138145,
        0.014620139263570309,
        0.001863938756287098,
        0.0035730113741010427,
        0.029715580865740776,
        -0.0245733093470335,
        0.0003785407461691648,
        -0.018261997029185295,
        0.011679448187351227,
        0.0018608402460813522,
        -0.04727233201265335,
        -0.0183903556317091,
        0.016268810257315636,
        0.013436711393296719,
        0.021254945546388626,
        0.013622351922094822,
        -0.029943369328975677,
        -0.010553229600191116,
        0.009748399257659912,
        -0.018917134031653404,
        0.008101136423647404,
        -0.01204975601285696,
        -0.008188307285308838,
        -0.020876623690128326,
        -9.10825256141834e-05,
        -0.006763081066310406,
        0.033762961626052856,
        -0.03707052767276764,
        0.00519466120749712,
        0.02318318374454975,
        -0.015847088769078255,
        0.02949642948806286,
        -0.03182773292064667,
        0.0035028860438615084,
        -0.004837154410779476,
        0.003083472838625312,
        -0.021309351548552513,
        -0.03449108451604843,
        -0.007992364466190338,
        0.025971604511141777,
        -0.0043885367922484875,
        -0.011985481716692448,
        0.021171022206544876,
        0.007882906123995781,
        -0.00012986389629077166,
        0.021036401391029358,
        0.006990986410528421,
        -0.031140608713030815,
        0.019061598926782608,
        0.00791199877858162,
        -0.01186539325863123,
        0.055294595658779144,
        -0.024495109915733337,
        -0.011445771902799606,
        -0.021222349256277084,
        0.023257102817296982,
        0.0038638547994196415,
        0.0035345328506082296,
        -0.0007210671319626272,
        -0.005774679593741894,
        -0.031436845660209656,
        -0.004673187620937824,
        0.016075480729341507,
        0.03517809510231018,
        0.015067690052092075,
        -0.026953665539622307,
        0.0076882378198206425,
        -0.02276260033249855,
        0.003425444010645151,
        -0.01438191533088684,
        -0.01536928117275238,
        -0.024057622998952866,
        -0.016857294365763664,
        0.011081067845225334,
        0.019188599660992622,
        -0.011189891025424004,
        -0.04128161817789078,
        0.008128257468342781,
        0.009800300002098083,
        -0.046008650213479996,
        0.053501516580581665,
        -0.018200965598225594,
        -0.018489986658096313,
        -0.012737675569951534,
        0.02680971287190914,
        0.01207180880010128,
        -0.033630046993494034,
        -0.010648833587765694,
        0.05932503193616867,
        -0.02234737016260624,
        -0.010682810097932816,
        -0.0016909989062696695,
        -0.022045059129595757,
        -0.018238339573144913,
        0.0221132580190897,
        0.015992356464266777,
        -0.041233278810977936,
        -0.031634557992219925,
        0.041337721049785614,
        0.013681624084711075,
        0.023111579939723015,
        -0.043377835303545,
        0.010050003416836262,
        0.0009318605298176408,
        -0.003541300306096673,
        0.006320471875369549,
        0.009844603948295116,
        -0.009615154005587101,
        -0.0002930720220319927,
        0.014518500305712223,
        0.008173318579792976,
        0.0391329750418663,
        0.009117872454226017,
        -0.026251988485455513,
        0.0026007427368313074,
        -0.012647686526179314,
        -0.0024559712037444115,
        -0.01843656785786152,
        0.008491164073348045,
        -0.02086794376373291,
        -0.0005092323408462107,
        0.026975929737091064,
        0.04941975697875023,
        -0.00898056197911501,
        -0.012131614610552788,
        -0.013678708113729954,
        -0.0038568899035453796,
        -0.023828843608498573,
        0.0011031916365027428,
        -0.004683005623519421,
        0.01738099195063114,
        -0.052944086492061615,
        0.02015870250761509,
        -0.0413767546415329,
        0.014350108802318573,
        0.02521093189716339,
        0.012241137214004993,
        0.008852817118167877,
        0.0044096484780311584,
        -0.0005594594986177981,
        0.011465943418443203,
        -0.0049908054061234,
        0.015118805691599846,
        0.007292434573173523,
        -0.016056859865784645,
        0.020870009437203407,
        -0.008964573964476585,
        0.007578665856271982,
        0.013307280838489532,
        0.021842436864972115,
        -0.011799642816185951,
        -0.02858460508286953,
        -0.033475276082754135,
        -0.024718819186091423,
        0.004201024305075407,
        0.008101418614387512,
        0.03681587800383568,
        0.0033337322529405355,
        -0.0030164122581481934,
        -0.01266877818852663,
        -0.008190729655325413,
        -0.03795118257403374,
        0.027951953932642937,
        -0.016859835013747215,
        -0.006670352071523666,
        -0.017388304695487022,
        0.014942938461899757,
        -0.006714050658047199,
        0.018168728798627853,
        -0.039670199155807495,
        0.023311909288167953,
        0.010768705978989601,
        -0.013491522520780563,
        -0.029088474810123444,
        0.03309457004070282,
        -0.020900260657072067,
        -0.007303857244551182,
        -0.0034463650081306696,
        0.009349249303340912,
        0.012234446592628956,
        0.013760320842266083,
        -0.031102098524570465,
        0.016624590381979942,
        -0.03951157629489899,
        -0.00577339343726635,
        0.009468233212828636,
        -0.006779459770768881,
        -0.01599982939660549,
        0.005555401556193829,
        0.05848662182688713,
        -0.005631701555103064,
        -0.027531756088137627,
        0.008412289433181286,
        0.026514407247304916,
        0.0036818806547671556,
        0.0005811143200844526,
        -0.009891508147120476,
        -0.007988404482603073,
        0.010335820727050304,
        -0.050348006188869476,
        -0.060915496200323105,
        -0.004317345097661018,
        0.03191370517015457,
        -0.0511111319065094,
        0.027631090953946114,
        0.03327922523021698,
        -0.0063485815189778805,
        0.0009089839295484126,
        0.020021632313728333,
        0.015927249565720558,
        0.013128562830388546,
        -0.035634301602840424,
        -0.04461706429719925,
        -0.0020110122859477997,
        0.02472621016204357,
        -0.00830882042646408,
        -0.012245099060237408,
        0.009111435152590275,
        0.04027188569307327,
        0.0016070696292445064,
        -0.007606383413076401,
        0.01876751519739628,
        -0.0029843845404684544,
        0.03579944372177124,
        -0.015773216262459755,
        0.0012698109494522214,
        -0.0006604900117963552,
        -0.02184896543622017,
        -0.01956309750676155,
        -0.01295322086662054,
        -0.03534621000289917,
        -0.017156796529889107,
        -0.009489950723946095,
        -0.035451993346214294,
        -0.011042424477636814,
        -0.003642591880634427,
        -0.018009275197982788,
        -0.03816388174891472,
        0.03806610777974129,
        -0.031059054657816887,
        0.0076255700550973415,
        -0.02342582866549492,
        0.027598533779382706,
        0.04612649604678154,
        -0.0036792827304452658,
        0.028946129605174065,
        -0.0025751430075615644,
        0.020397812128067017,
        0.014366979710757732,
        0.028841093182563782,
        0.024120431393384933,
        0.004254808649420738,
        0.028848769143223763,
        0.017093978822231293,
        -0.005986358039081097,
        -0.032159481197595596,
        0.00649686437100172,
        -0.03099651075899601,
        0.019703274592757225,
        -0.031128602102398872,
        -0.04224684461951256,
        -0.01829652674496174,
        0.003520757192745805,
        -0.005547941196709871,
        -0.0002656476863194257,
        0.0056245774030685425,
        -0.021220792084932327,
        -0.012249097228050232,
        -0.006146904546767473,
        0.028406523168087006,
        -0.04039015993475914,
        -0.007283652201294899,
        -0.00657349219545722,
        -0.0005680285976268351,
        0.015037029050290585,
        -0.009836247190833092,
        0.01678546518087387,
        -0.012509718537330627,
        0.01218891516327858,
        -0.033431049436330795,
        0.031538672745227814,
        -0.0035580359399318695,
        -0.017836200073361397,
        0.02392783761024475,
        -0.02897813357412815,
        -0.003340872935950756,
        0.017043396830558777,
        -0.012130022048950195,
        -0.005984224379062653,
        0.003509183181449771,
        0.010474054142832756,
        -0.005895515438169241,
        0.009239661507308483,
        0.014550680294632912,
        0.005312885623425245,
        -0.02711861953139305,
        0.006532847881317139,
        -0.029362648725509644,
        0.000180119153810665,
        0.002865622052922845,
        0.010659800842404366,
        -0.025999641045928,
        0.017673926427960396,
        0.017719155177474022,
        0.026857899501919746,
        -0.010454455390572548,
        0.03293493390083313,
        -0.005945932120084763,
        0.011992539279162884,
        0.009921181946992874,
        -0.004008650779724121,
        0.0170486718416214,
        -0.03267165273427963,
        -0.006240256130695343,
        0.011088475584983826,
        0.019525788724422455,
        0.021698303520679474,
        -0.007100921589881182,
        0.0012732676696032286,
        0.026379574090242386,
        -0.04071414843201637,
        0.015349723398685455,
        0.010137889534235,
        -0.007151692174375057,
        0.0018163061467930675,
        0.011821829713881016,
        -0.01178535632789135,
        0.01915721222758293,
        0.010806519538164139,
        -0.034186381846666336,
        -0.004774287808686495,
        -0.009363792836666107,
        -0.013654133304953575,
        0.03397908806800842,
        -0.0011368178529664874,
        0.027538154274225235,
        -0.003705038223415613,
        -0.02706298977136612,
        -0.01239684410393238,
        -0.0037070601247251034,
        0.002800497692078352,
        0.016904624179005623,
        0.012927335686981678,
        0.011808290146291256,
        0.01750645413994789,
        0.008713479153811932,
        6.952004332561046e-05,
        0.038044966757297516,
        0.0050571030005812645,
        -0.002049514325335622,
        0.019522251561284065,
        -0.014596056193113327,
        -0.003671680111438036,
        0.029943209141492844,
        0.0056011187843978405,
        -0.06358540803194046,
        -0.043027378618717194,
        -0.020855704322457314,
        0.02247636578977108,
        -0.026723643764853477,
        -0.015955999493598938
      ],
      "title": "Inteligencia artificial generativa: irrupción y desafíos"
    },
    {
      "id": "gai-esp_corpus-item004",
      "count": 10,
      "created": "2025-07-06T05:58:11.996104",
      "text": "México avanza con su plan nacional para el desarrollo ético de la inteligencia artificial La UNESCO presentó este miércoles, en el Senado de la República, la evaluación del estado de preparación de la inteligencia artificial en México. La Recomendación sobre la Ética de la Inteligencia Artificial (RAM) fue presentada por Gabriela Ramos, Directora General Adjunta para las Ciencias Sociales y Humanas de la UNESCO. México está pisando fuerte para lograr una hoja de ruta nacional para el desarrollo y uso ético de la inteligencia artificial. Este miércoles, la UNESCO presentó la evaluación del estado de preparación de México para la inteligencia artificial, bajo el liderazgo de Gabriela Ramos, Directora General Adjunta para las Ciencias Sociales y Humanas de la UNESCO, con el apoyo de Centro-i para la Sociedad del Futuro y la Alianza Nacional de Inteligencia Artificial (ANIA), que lidera la senadora Alejandra Lagunes. La UNESCO en colaboración con la ANIA desarrolló el reporte del estadío de la preparación de la IA de México. Se trata de un análisis detallado de las fortalezas y oportunidades de México para fomentar un ecosistema de inteligencia artificial responsable. Tras 15 meses de esfuerzo conjunto, 18 mesas de trabajo, 90 eventos y la participación de más de 340 expertos en más de 500 horas de diálogo, esta cooperación entre la ANIA, el Centro-i y la UNESCO ha logrado resultados significativos en el desarrollo de la inteligencia artificial en México. \"Gracias por su tiempo, trabajo y confianza. Por los documentos compartidos, por la investigación, las entrevistas. Ustedes han sido quienes construyeron este legado que está haciendo historia\", dijo Alejandra Lagunes, al inicio del evento en el Senado de la República. Alejandra Lagunes es Secretaria de la Mesa Directiva y de la Comisión de Derechos Digitales, Integrante de la Comisión Ciencia y Tecnología, Salud, Medio Ambiente, Recursos Naturales y Cambio Climático. Además, es fundadora y líder de la Alianza Nacional de Inteligencia Artificial (ANIA), un mecanismo que tiene como misión reconocer y fortalecer el ecosistema de IA en México con una perspectiva integral, plural y multidisciplinaria, con el objetivo de desarrollar recomendaciones de política pública, regulación y modelo de gobernanza. Como líder de la ANIA ha publicado artículos de opinión sobre diversos temas relacionados con la tecnología y las políticas públicas, y ha participado en conferencias, paneles y foros internacionales para compartir sus conocimientos y experiencia. \"La inteligencia artificial traerá un cambio civilizatorio. Un cambio de era. Una transformación del contrato social. Para 2030, 50% de los empleos mundiales se transformarán. Para el 2050, 75% de los empleos estarán relacionados con la IA. La inteligencia artificial generará 4.4 trillones de dólares anuales en productividad, y 13 billones de dólares en valor agregado en la economía mundial. Impactará absolutamente a todos los sectores productivos\", dijo la senadora Lagunes. Según la OCDE, 79 países han presentado más de 1,000 propuestas relacionadas con la inteligencia artificial, que abarcan desde iniciativas de ley y estrategias hasta políticas públicas, agendas y cambios nacionales. En México, se han presentado 43 iniciativas en el Senado y la Cámara de Diputados. \"Así, hace 15 meses, se crea la Alianza Nacional de Inteligencia Artificial (ANIA), un mecanismo abierto y colaborativo. Lo que nos unió fue la visión de recalibrar el debate. Tenemos claro que la discusión no debía ser tecnológica ni económica, sino social y ética, con el ser humano y su bienestar al centro, que encontremos la solución a los problemas locales y globales. Para cerrar las brechas y terminar con las grandes desigualdades y los sesgos; que se utilice para el desarrollo sostenible con respeto a la dignidad, a los derechos humanos y a los valores democráticos, que definamos cuál es la relación que queremos con esta tecnología, que decidamos cuál es nuestra vocación como país, que logremos detonar la innovación y equilibrar el desarrollo tecnológico con la autorregulación\". ¿En qué consiste la Recomendación sobre Ética de Inteligencia Artificial (RAM, por sus siglas en inglés)? La RAM es una herramienta clave para apoyar a los Estados Miembros en la implementación de la Recomendación de la UNESCO sobre la Ética de la IA. Al proporcionar información detallada y completa sobre diferentes dimensiones de la preparación para la IA, ayuda a resaltar cualquier brecha institucional y regulatoria, y permite a la UNESCO ajustar su apoyo a los gobiernos para llenar esas brechas, con el fin de asegurar un ecosistema de IA ético. La Readiness Assessment Methodology (RAM) incluye una variedad de preguntas cuantitativas y cualitativas diseñadas para recopilar información sobre diferentes dimensiones relacionadas con el ecosistema de IA de un país, incluidas las dimensiones legales y regulatorias, sociales y culturales, económicas, científicas y educativas, y tecnológicas e infraestructurales. Cada dimensión presenta una serie de preguntas de evaluación cuantitativas y cualitativas, lo que distingue a la RAM de otras herramientas de evaluación de preparación existentes. \"México, al igual que otras naciones, enfrenta enormes desafíos para lograr el desarrollo ético de la IA. Desde 2018, el gobierno de México ha participado activamente en foros internacionales sobre estos temas, poniendo en marcha una iniciativa para elaborar una estrategia nacional digital que incluyera explícitamente a la IA. México ha formado parte de los grupos de trabajo de la ONU y ha liderado varias iniciativas en la Red de América Latina y el Caribe para el Desarrollo de Gobiernos Digitales. Sin embargo, desde entonces, otros países con niveles de desarrollo similares han logrado avances significativos, mientras que México se ha rezagado en sus posiciones de liderazgo en esta materia\", dijo Gabriela Ramos, Directora General Adjunta para las Ciencias Sociales y Humanas de la UNESCO. La implementación de la RAM se adapta a las circunstancias y características únicas del país, así como al presupuesto disponible para el proyecto. Se espera que la RAM sea llevada a cabo por un consultor independiente u organización de investigación, apoyado por un equipo nacional que comprenda una variedad de partes interesadas, como personal de la Secretaría de la UNESCO y la Comisión Nacional de la UNESCO, así como representantes del gobierno del país, la comunidad académica, la sociedad civil y el sector privado, entre otros. Además de la finalización del cuestionario RAM, el resultado final del ejercicio RAM incluye la creación de un informe nacional que proporciona una visión general completa del estado de preparación para la IA en el país, resumiendo dónde se encuentra el país en cada dimensión, detallando las actividades en curso, resumiendo el estado del arte y proporcionando recomendaciones políticas concretas sobre cómo abordar las brechas de gobernanza. Este informe ayuda a identificar en detalle los cambios institucionales necesarios para elaborar o fortalecer la estrategia nacional de IA y permite a la UNESCO ajustar los esfuerzos de desarrollo de capacidades a las necesidades específicas del país. ¿Qué ha hecho México para el desarrollo, uso y aplicación ética, legal y responsable de la IA? México se ha sumado a más de 60 países que están desarrollando la metodología RAM, de la UNESCO. Con la presentación de hoy de la RAM, y la Propuesta de Agenda Nacional de la Inteligencia Artificial para México 2024-2030, anunciada el pasado 15 de mayo, se cumple con el primer objetivo que se planteó desde la ANIA, que fue generar un diagnóstico y propuestas de regulación, política pública y modelo de gobernanza de la IA para el país. Además, se presentó una iniciativa de Reforma Constitucional al artículo 73 para facultar al Congreso de legislar en inteligencia artificial, ciberseguridad y neuroderecho, que fue firmada por todos los grupos parlamentarios. México ha colaborado con la Embajada de Reino Unido y la Asociación Mexicana de Ciberseguridad para desarrollar un marco regulatorio y ético. También, en colaboración todo el ecosistema relacionado con la IA, se ha desarrollado un sandbox que se presentará en la Comisión Permanente del Senado de la República. Además, han capacitado a miles de personas en IA, y documentando casos de uso. Firmaron una colaboración con la Cámara Nacional de Comercio (CANACO) para capacitar a 10,000 PyMes. \"Hoy, presentaré en la Comisión Permanente dos iniciativas, una que moderniza y dota al Instituto Belisario Domínguez del Senado de la República de facultades para dar asesoramiento técnico en materia de nuevas tecnologías; y otra que busca implementar el parlamento abierto; también, Instituto Belisario Domínguez, estamos creando un acuerdo de colaboración para que la ANIA sea un órgano consultivo en temas de tecnologías emergentes y de futuro\", dijo la senadora Alejandra Lagunes. Mensajes Claves sobre la IA en México Actualmente, el país aún no cuenta con un plan o estrategia nacional de IA. Sin embargo, México tiene importantes fortalezas en su marco jurídico, protección de derechos humanos, privacidad y protección de datos, que pueden servir como base para el desarrollo de una estrategia integral. Según el Índice Latinoamericano de Inteligencia Artificial (ILIA), el uso de IA por parte de empresas privadas en México es bajo en comparación con otros países de América Latina, con una puntuación de 12.5, frente a un promedio de 25 en la región. A pesar de esto, México se destaca en avances públicos, ocupando el tercer lugar en LATAM, después de Argentina y Uruguay. En 2022, México tuvo 2,670 graduados de programas de maestría en ciencias de la computación o equivalentes, el mayor número en Latinoamérica. Además, el país ha logrado avances moderados en la integración de tecnología en la educación. Sin embargo, los niveles de escolaridad siguen siendo bajos y persiste una gran brecha de género en carreras STEM. La producción científica en IA es baja en comparación con los estándares internacionales. Sin embargo, a nivel regional, México y Brasil poseen el 95% de las patentes de IA en Latinoamérica, según el ILIA. México se ubica en sexto lugar en la región en número de investigadores que trabajan específicamente en IA, después de Chile, Ecuador, Brasil, Uruguay y Colombia. Aunque México lidera en inversión pública en I+D en Latinoamérica, su gasto total (público y privado) en I+D fue de 0.28% del PIB en 2021, comparado con un promedio de 0.56% para Latinoamérica y el Caribe, y un promedio de 2.72% en países miembros de la OCDE. Principales Recomendaciones de la UNESCO En primer lugar, la UNESCO sugiere elaborar un mapa funcional del ecosistema de IA. En segundo lugar, integrar un marco jurídico específico para regular la inteligencia artificial. Además, se propone crear un diseño institucional y de gobernanza para la IA. Finalmente, se recomienda emitir la Estrategia Nacional de Inteligencia Artificial. Innovar en el diseño de instrumentos regulatorios ágiles: Crear regulaciones flexibles que se adapten al rápido avance tecnológico e incluyan mecanismos para el aprendizaje y la mejora continua. Definir políticas públicas inclusivas para el desarrollo de IA: Establecer políticas que promuevan el desarrollo de la inteligencia artificial con fines de interés público, garantizando el acceso equitativo a la IA, los datos y el poder de cómputo, evitando así la creación de brechas tecnológicas. Coordinación con otros órganos y poderes del Estado: Colaborar estrechamente con el sector privado, la academia y la sociedad civil para asegurar una efectiva coordinación y cooperación interinstitucional. Identificación de activos y servicios críticos: Desarrollar estrategias específicas para la prevención y detección de amenazas, diferenciando claramente entre la seguridad nacional y la seguridad ciudadana. Incorporación de principios fundamentales: Garantizar que la ciberseguridad, privacidad, transparencia, inclusión, ética y perspectiva de género sean componentes transversales en la estrategia nacional de IA. Figure figure_1: Esta mañana, la UNESCO presentó en el Senado de la República la evaluación del estadío de preparación de la inteligencia artificial en México, de la mano de Gabriela Ramos, Directora Adjunta para las Ciencias Sociales y Humanas de la Unesco y Alejandra Lagunes, líder de la Alianza Nacional de Inteligencia Artificial (ANIA). Figure figure_2: Alejandra Lagunes, líder de la Alianza Nacional de Inteligencia Artificial (ANIA).",
      "word_count": 1944,
      "character_count": 12599,
      "vector": [
        0.1560785323381424,
        -0.18273288011550903,
        0.12562724947929382,
        0.005571688525378704,
        -0.039966948330402374,
        -0.0377468541264534,
        -0.05054284632205963,
        0.02283511497080326,
        -0.07224498689174652,
        0.02541082352399826,
        0.03195454180240631,
        0.1273614913225174,
        0.03438423573970795,
        -0.019507210701704025,
        0.07753240317106247,
        -0.0024585402570664883,
        -0.03647032007575035,
        -0.015170704573392868,
        -0.0072905137203633785,
        -0.0773453563451767,
        -0.047510843724012375,
        -0.06709738075733185,
        0.03657928854227066,
        0.10814617574214935,
        -0.018709562718868256,
        0.09047866612672806,
        -0.09259267151355743,
        0.007207939401268959,
        0.003048092592507601,
        -0.03326757624745369,
        -0.05391860753297806,
        -0.11592508852481842,
        0.014541846700012684,
        -0.02082850970327854,
        -0.0018814001232385635,
        -0.02527735009789467,
        0.055382464081048965,
        -0.05650201067328453,
        -0.00343107501976192,
        0.027591634541749954,
        -0.030962033197283745,
        0.023155776783823967,
        0.03691747039556503,
        -0.06759592145681381,
        0.09799512475728989,
        0.07307553291320801,
        0.04612809047102928,
        0.024315033107995987,
        -0.04232722893357277,
        -0.01333313062787056,
        0.08972887694835663,
        -0.00025115031166933477,
        -0.06189461797475815,
        0.09172741323709488,
        0.04456434026360512,
        -0.01934456080198288,
        -0.00038180785486474633,
        -0.021125202998518944,
        -0.0903765931725502,
        -0.05364008992910385,
        0.008301202207803726,
        0.04987442493438721,
        -0.0040945750661194324,
        -0.07594917714595795,
        -0.05094365030527115,
        0.06072503700852394,
        -0.016601836308836937,
        -0.017065754160284996,
        0.0023352026473730803,
        -0.07604074478149414,
        0.0024261879734694958,
        0.05392615869641304,
        -0.04947280138731003,
        -0.026163659989833832,
        0.02696206048130989,
        0.020522937178611755,
        -0.04481618106365204,
        0.03041662834584713,
        -0.023935461416840553,
        -0.030298588797450066,
        0.10274018347263336,
        0.043995171785354614,
        0.03474022075533867,
        0.03215391933917999,
        -0.004948237910866737,
        0.022540852427482605,
        -0.10036786645650864,
        -0.012716528959572315,
        0.04883849620819092,
        -0.046853601932525635,
        0.005256955046206713,
        0.022468512877821922,
        -0.03008958324790001,
        -0.07252755016088486,
        0.012439286336302757,
        0.011989785358309746,
        -0.01067148707807064,
        0.03063536062836647,
        -0.06398753821849823,
        -0.017483603209257126,
        -0.014587322250008583,
        0.05069532245397568,
        -0.07498571276664734,
        0.022515855729579926,
        0.01191367395222187,
        0.014981113374233246,
        -0.024917328730225563,
        -0.01693943329155445,
        -0.09891584515571594,
        -0.03510434553027153,
        -0.01388612762093544,
        -0.025264032185077667,
        0.016572993248701096,
        -0.007987027056515217,
        0.0006171354907564819,
        0.003087795339524746,
        -0.0187380388379097,
        0.032534848898649216,
        -0.0012071242090314627,
        -0.03337884321808815,
        -0.018234029412269592,
        0.03853019326925278,
        -0.01672995835542679,
        0.012621916830539703,
        -0.020839516073465347,
        -0.026597779244184494,
        -0.05414475128054619,
        0.042533598840236664,
        0.032740283757448196,
        -0.05594906583428383,
        0.04672772064805031,
        0.05560624599456787,
        0.0008155636605806649,
        0.029095448553562164,
        -0.004336999729275703,
        -0.019118666648864746,
        0.0223789494484663,
        -0.07487266510725021,
        -0.056028302758932114,
        0.019074460491538048,
        -0.04322903975844383,
        0.021300436928868294,
        -0.023190053179860115,
        0.03559311479330063,
        -0.005215959157794714,
        -0.012710786424577236,
        0.027516430243849754,
        0.006632179953157902,
        -0.05242383852601051,
        0.026706213131546974,
        0.0034978780895471573,
        0.02332221157848835,
        -0.047067634761333466,
        -0.03238767012953758,
        0.04241432249546051,
        0.0692993625998497,
        -0.004956322722136974,
        -0.012982386164367199,
        -0.01690482720732689,
        -0.007467237301170826,
        -0.010855100117623806,
        0.006119511090219021,
        -0.04098420590162277,
        0.01577923446893692,
        -0.05134361609816551,
        0.023600956425070763,
        -3.759342143894173e-05,
        0.025133203715085983,
        0.048554010689258575,
        0.0039117587730288506,
        -0.03893043473362923,
        0.005618286319077015,
        0.023708410561084747,
        0.03534753993153572,
        -0.004943701904267073,
        -0.0091354725882411,
        0.0791633203625679,
        0.08731383830308914,
        -0.019771693274378777,
        0.083530493080616,
        0.06621093302965164,
        -0.05704880133271217,
        -0.0668700784444809,
        0.04437064751982689,
        -0.03516167774796486,
        -0.02688535489141941,
        0.057861942797899246,
        0.04656747356057167,
        -0.04057848080992699,
        -0.012437892146408558,
        0.011980610899627209,
        0.031930502504110336,
        0.007094721309840679,
        0.008129493333399296,
        0.0058823637664318085,
        -0.019942307844758034,
        0.003550887107849121,
        -0.008712142705917358,
        -0.05319123715162277,
        -0.002603470580652356,
        -0.037957366555929184,
        0.005491325631737709,
        -0.030887294560670853,
        -0.0073699429631233215,
        -0.0282617025077343,
        0.007195622660219669,
        -0.03241419047117233,
        0.032308634370565414,
        -0.02057153731584549,
        0.008372923359274864,
        -0.005344966426491737,
        0.011968321166932583,
        0.051254112273454666,
        -0.00825890339910984,
        -0.05360131338238716,
        -0.0226270891726017,
        0.05253224074840546,
        0.025133993476629257,
        0.03919922560453415,
        -0.006190337706357241,
        -0.031638193875551224,
        0.004301006440073252,
        0.015435144305229187,
        0.00382351316511631,
        -0.031204774975776672,
        -0.033339206129312515,
        -0.003749752650037408,
        -0.0048817237839102745,
        0.01943025551736355,
        0.03709550201892853,
        -0.01757124252617359,
        0.0013288180343806744,
        0.006085688713937998,
        0.018463414162397385,
        0.03521740809082985,
        0.005020144861191511,
        -0.0031677137594670057,
        0.06062810495495796,
        0.02296205423772335,
        -0.008802065625786781,
        -0.048785045742988586,
        0.007798120379447937,
        -0.053940873593091965,
        0.008077580481767654,
        -0.07576623558998108,
        0.021095000207424164,
        -0.015134654007852077,
        0.016070250421762466,
        -0.060416918247938156,
        0.01995532028377056,
        0.021015247330069542,
        0.017823828384280205,
        -0.08850661665201187,
        -0.03660590201616287,
        -0.029730482026934624,
        -0.007914796471595764,
        -0.023554138839244843,
        0.03261176124215126,
        -0.0307695921510458,
        0.02286483533680439,
        -0.03255070000886917,
        0.005048290826380253,
        0.0006058044964447618,
        0.005685603711754084,
        0.03437328338623047,
        -0.006550042424350977,
        0.021587807685136795,
        0.0164183359593153,
        0.004239573609083891,
        -0.02803313545882702,
        -0.006795098539441824,
        -0.011645447462797165,
        -0.03875630721449852,
        0.025386838242411613,
        -0.014391090720891953,
        -0.0020176649559289217,
        -0.01914772018790245,
        0.02249845489859581,
        -0.003941893577575684,
        -0.005983839742839336,
        -0.020336201414465904,
        0.0130821717903018,
        -0.020777758210897446,
        -0.00684213824570179,
        0.0008174707181751728,
        -0.0011573268566280603,
        0.05372591316699982,
        -0.007708681747317314,
        0.05500271916389465,
        0.009805604815483093,
        0.022950494661927223,
        0.014520520344376564,
        0.011561395600438118,
        -0.007420958485454321,
        0.049282122403383255,
        0.017087575048208237,
        -0.07510073482990265,
        -0.00689727533608675,
        -0.00027283807867206633,
        0.021617958322167397,
        -0.0112433647736907,
        0.054320819675922394,
        0.011562362313270569,
        0.03474763408303261,
        -0.006471283733844757,
        0.006662720814347267,
        -0.00307456380687654,
        -0.022834675386548042,
        -0.040326833724975586,
        0.026603329926729202,
        0.01869107037782669,
        0.005246944725513458,
        0.005292308982461691,
        0.021356001496315002,
        -0.026822291314601898,
        -0.00931362435221672,
        0.014622592367231846,
        -0.0064020617865026,
        -0.019519075751304626,
        -0.00011716345034074038,
        0.0021446826867759228,
        -0.01553464774042368,
        -0.010432158596813679,
        0.0017674536211416125,
        -0.01152088399976492,
        0.006130543537437916,
        0.007303551305085421,
        0.017829634249210358,
        0.014259378425776958,
        -0.013979827053844929,
        0.017987197265028954,
        0.01947139762341976,
        0.0324668250977993,
        0.04193192347884178,
        -0.03408109396696091,
        -0.03488718718290329,
        0.02314341627061367,
        -0.004561790265142918,
        0.046041250228881836,
        -0.01281827688217163,
        0.06104162707924843,
        -0.0065423971973359585,
        0.030409539118409157,
        -0.02285098470747471,
        0.014599231071770191,
        0.021493295207619667,
        0.015125304460525513,
        -0.00954966340214014,
        0.03049360401928425,
        0.05068833753466606,
        -0.02540498599410057,
        -0.008385873399674892,
        -0.0192242544144392,
        -0.005578856915235519,
        0.011034413240849972,
        0.03729772940278053,
        0.009195567108690739,
        0.0031121624633669853,
        0.010843275114893913,
        -0.03546232357621193,
        -0.03966085985302925,
        0.014208173379302025,
        0.026288922876119614,
        0.09681381285190582,
        -0.017580613493919373,
        -0.004216672852635384,
        0.03850794956088066,
        -0.01730489544570446,
        -0.02402777411043644,
        -0.011392836458981037,
        0.004526307340711355,
        -0.00846077874302864,
        -0.004244395066052675,
        -0.013314603827893734,
        -0.02964848466217518,
        0.03306102752685547,
        0.01969226263463497,
        0.0024898673873394728,
        0.040356237441301346,
        0.015031266026198864,
        0.005637109279632568,
        -0.059599488973617554,
        -0.025262197479605675,
        -0.002426915103569627,
        -0.020032944157719612,
        -0.03350048512220383,
        0.04926500469446182,
        -0.07888010144233704,
        0.021241357550024986,
        -0.04354512691497803,
        -0.021464630961418152,
        -0.04286489263176918,
        0.04982652887701988,
        -0.0415630042552948,
        -0.0179397352039814,
        0.011356648989021778,
        0.045637793838977814,
        -0.05680996924638748,
        -0.007321575190871954,
        0.011853153817355633,
        -0.012396530248224735,
        -0.028301995247602463,
        0.005067453254014254,
        -0.025164209306240082,
        0.029401594772934914,
        -0.010534914210438728,
        0.0010792859829962254,
        0.007798680569976568,
        -0.03842458501458168,
        0.0021255260799080133,
        -0.025837108492851257,
        0.018599530681967735,
        -0.02018212340772152,
        0.011966604739427567,
        0.009002079255878925,
        -0.05726979300379753,
        0.0330716036260128,
        0.021932503208518028,
        -0.02889155223965645,
        -0.011117958463728428,
        0.03167947754263878,
        -0.009244073182344437,
        0.030866852030158043,
        -0.04233449697494507,
        0.004281532950699329,
        0.005111295264214277,
        -0.01750110276043415,
        -0.017799250781536102,
        0.008016720414161682,
        0.019000990316271782,
        -0.05874960497021675,
        -0.003751736832782626,
        0.02511497586965561,
        0.007717740722000599,
        0.0006357264937832952,
        -0.006727815140038729,
        0.015858691185712814,
        -0.019029108807444572,
        0.002771596657112241,
        -0.024297548457980156,
        0.020073816180229187,
        0.011885128915309906,
        0.007986640557646751,
        0.01863979920744896,
        -0.024487819522619247,
        0.005937926936894655,
        0.030549446120858192,
        -0.03447848930954933,
        -0.00039960205322131515,
        -0.032318536192178726,
        0.0011469849850982428,
        0.058996617794036865,
        -0.037798698991537094,
        -0.05985862761735916,
        0.0420977957546711,
        -0.03294070437550545,
        0.04264221712946892,
        -0.027233963832259178,
        0.03404834866523743,
        0.0014606198528781533,
        0.01849195919930935,
        0.001321321469731629,
        0.015151294879615307,
        0.012254743836820126,
        0.07396335899829865,
        0.054772477596998215,
        0.11086680740118027,
        0.0019197385990992188,
        0.04495231434702873,
        -0.022139081731438637,
        0.026500515639781952,
        0.04491801932454109,
        0.021267330273985863,
        -0.007178151980042458,
        0.0339011624455452,
        0.023845979943871498,
        -0.016294490545988083,
        -0.055518265813589096,
        0.02012288011610508,
        0.008795028552412987,
        -0.02892068587243557,
        -0.007008676417171955,
        -0.010901790112257004,
        0.03221436217427254,
        0.013586631044745445,
        0.009927012957632542,
        -0.07248866558074951,
        -0.042477477341890335,
        0.029177162796258926,
        0.04858316853642464,
        0.01833227463066578,
        0.01826447620987892,
        -0.009029054082930088,
        0.04901368170976639,
        0.017735062167048454,
        -0.0046506598591804504,
        -0.0009291716851294041,
        -0.04400666803121567,
        -0.016247833147644997,
        -0.07680339366197586,
        -0.043741609901189804,
        -0.04188075661659241,
        0.02095477283000946,
        -0.002006271155551076,
        -0.021733248606324196,
        -0.02759014628827572,
        0.008177892304956913,
        -0.010180164128541946,
        -0.010198048315942287,
        0.007387535646557808,
        1.0244009899906814e-05,
        0.027052151039242744,
        0.0052444348111748695,
        -0.029806993901729584,
        0.029243482276797295,
        -0.0032899389043450356,
        0.056951556354761124,
        -0.0006996311713010073,
        -0.014639361761510372,
        -0.0041635911911726,
        -0.011854622513055801,
        0.0012532863765954971,
        0.04038558527827263,
        -0.014488506130874157,
        0.0318630076944828,
        0.014333788305521011,
        -0.020255865529179573,
        0.0010125655680894852,
        0.03604365885257721,
        -0.014094951562583447,
        0.032817911356687546,
        0.012173213064670563,
        -0.00045167774078436196,
        -0.012447426095604897,
        0.023689113557338715,
        0.0023225448094308376,
        -0.03769099339842796,
        0.011561065912246704,
        0.016541413962841034,
        -0.009434400126338005,
        -0.011041305959224701,
        -0.014143811538815498,
        0.01904631219804287,
        -0.03260556980967522,
        0.011455181986093521,
        0.003377162152901292,
        -0.02682674676179886,
        -0.01857513003051281,
        0.04039938375353813,
        0.038414038717746735,
        -0.005156508646905422,
        0.01462217140942812,
        -0.032506003975868225,
        0.012786406092345715,
        -0.013733746483922005,
        -0.05216549336910248,
        0.004586638417094946,
        0.011969529092311859,
        0.0004355838755145669,
        -0.02422782965004444,
        0.01423064898699522,
        0.01593162678182125,
        0.00047202754649333656,
        -0.014025994576513767,
        -0.04882942885160446,
        0.0002316080208402127,
        -0.013524510897696018,
        -0.0010273329680785537,
        -0.007819666527211666,
        0.04178398847579956,
        0.032367490231990814,
        0.023892953991889954,
        -0.013926423154771328,
        0.03232767432928085,
        0.006597159430384636,
        -0.037144072353839874,
        0.034521035850048065,
        0.031343188136816025,
        -0.0026908658910542727,
        0.01027143094688654,
        -0.0036717597395181656,
        -0.04323705658316612,
        -0.006267094518989325,
        0.03203491494059563,
        -0.00044364837231114507,
        -0.0073526594787836075,
        -0.020891588181257248,
        -0.03058513067662716,
        -0.0063162315636873245,
        -0.01874418370425701,
        0.019710462540388107,
        0.00693317037075758,
        -0.0026660580188035965,
        0.011755410581827164,
        -0.0006077760481275618,
        -0.009279501624405384,
        -0.025167301297187805,
        -0.03450842574238777,
        -0.004012946505099535,
        0.026918655261397362,
        -0.05729061737656593,
        0.006837228778749704,
        -0.02983962371945381,
        0.016106560826301575,
        0.027279851958155632,
        0.03147419914603233,
        0.03398873284459114,
        -0.0010408057132735848,
        -0.01698182336986065,
        -0.0097628990188241,
        -0.0038875045720487833,
        0.02672000415623188,
        -0.03230820223689079,
        -0.007722953800112009,
        0.01406836323440075,
        0.026655202731490135,
        0.023332923650741577,
        0.0005529139889404178,
        -0.006073888391256332,
        0.028160521760582924,
        0.008380980230867863,
        -0.034552719444036484,
        0.021419372409582138,
        -0.0032984279096126556,
        -0.020581061020493507,
        -0.034536972641944885,
        0.007484216708689928,
        0.039846550673246384,
        0.0007006180821917951,
        -0.002640022663399577,
        0.010790792293846607,
        0.02704550512135029,
        0.017829179763793945,
        0.0014426391571760178,
        0.03329809755086899,
        0.011462864466011524,
        0.007217670325189829,
        -0.03074183315038681,
        0.008419202640652657,
        0.0701240822672844,
        0.03450874611735344,
        -0.01211693324148655,
        -0.04007069393992424,
        0.027385136112570763,
        -0.02852821722626686,
        -0.039529576897621155,
        0.03437202796339989,
        -0.0034765710588544607,
        0.0018531527603045106,
        -0.019962357357144356,
        0.010717615485191345,
        0.023056134581565857,
        -0.007676566950976849,
        -0.011221201159060001,
        -0.03933289274573326,
        -0.04386978968977928,
        0.006281151901930571,
        0.008419214747846127,
        -0.05579125136137009,
        -0.06649195402860641,
        0.02362000197172165,
        -0.003935996443033218,
        0.056882161647081375,
        -0.01276424527168274,
        0.00983402319252491,
        -0.001575428992509842,
        0.005453757010400295,
        0.01595858484506607,
        -0.03989681228995323,
        0.0029112014453858137,
        -0.004188739228993654,
        -0.028223874047398567,
        -0.0028479183092713356,
        -0.01593387871980667,
        0.003404937218874693,
        0.00037980524939484894,
        0.025987183675169945,
        0.03414621204137802,
        0.0033069634810090065,
        -0.025578944012522697,
        -0.02262495830655098,
        0.014300764538347721,
        -0.016115503385663033,
        0.0054810307919979095,
        0.010755548253655434,
        0.021118147298693657,
        -0.026709740981459618,
        0.021722815930843353,
        0.00787383783608675,
        0.023857934400439262,
        -0.00015967839863151312,
        -0.004788764752447605,
        0.025833530351519585,
        -0.015120779164135456,
        0.017994210124015808,
        0.0013128317659720778,
        0.008485822938382626,
        -0.025107985362410545,
        0.053400468081235886,
        0.003871331224218011,
        -0.03709341213107109,
        -0.017570439726114273,
        0.03788108006119728,
        0.019518449902534485,
        -0.02344931662082672,
        0.023085065186023712,
        0.047572363168001175,
        -0.00249996455386281,
        -0.0030829496681690216,
        -0.011395446956157684,
        -0.01237683929502964,
        0.0355265811085701,
        0.012662765569984913,
        -0.0144724166020751,
        0.028935302048921585,
        0.02550373412668705,
        0.046017877757549286,
        -0.020378435030579567,
        -0.0011279057944193482,
        -0.004059075377881527,
        0.00788402184844017,
        0.006729871034622192,
        -0.003137996420264244,
        -0.014746041037142277,
        0.03499307483434677,
        -0.012218201532959938,
        0.04852569103240967,
        0.008267671801149845,
        -0.02984222210943699,
        0.006263683550059795,
        -0.01382243912667036,
        -0.018049519509077072,
        -0.005450207740068436,
        -1.6417534425272606e-05,
        -0.03244929015636444,
        0.005970662459731102,
        0.038536448031663895,
        0.015711063519120216,
        -0.021827667951583862,
        -0.050206176936626434,
        -0.03523877635598183,
        0.05044101923704147,
        -0.05303525924682617,
        -0.0011443874100223184,
        -0.02020890824496746,
        -0.0236224178224802,
        -0.010592164471745491,
        0.009485634975135326,
        -0.0032019661739468575,
        0.010829344391822815,
        -0.0016092730220407248,
        0.03500139340758324,
        0.005980904679745436,
        -0.02263909950852394,
        -0.004235396161675453,
        -0.0008689237874932587,
        -0.017325155436992645,
        -0.01956276223063469,
        0.044235337525606155,
        -0.04924040287733078,
        -0.012810117565095425,
        0.03842119872570038,
        0.005919074174016714,
        -0.0083309980109334,
        -0.015572960488498211,
        0.011824285611510277,
        0.00925055518746376,
        0.005927355494350195,
        0.004554471001029015,
        -0.008649161085486412,
        -0.030075225979089737,
        -0.02261495031416416,
        -0.0005402107490226626,
        -0.008936189115047455,
        0.006680437363684177,
        0.0030145274940878153,
        -0.016950659453868866,
        0.023038029670715332,
        0.01778741553425789,
        -0.018101131543517113,
        -0.034571971744298935,
        0.018766555935144424,
        -0.0025262609124183655,
        0.022601762786507607,
        0.016994494944810867,
        0.04535742476582527,
        -0.037692248821258545,
        -0.02944575436413288,
        0.0052975439466536045,
        -0.012076962739229202,
        -0.03284387290477753,
        0.004406428895890713,
        -0.0056254081428050995,
        -0.01741388998925686,
        0.005751622375100851,
        -0.012870543636381626,
        -0.05152297392487526,
        0.013101276010274887,
        0.026929067447781563,
        -0.01815582998096943,
        -0.0070707229897379875,
        -0.03248714283108711,
        0.002139636781066656,
        -0.0073013617657125,
        -0.03111153468489647,
        0.0221328716725111,
        0.01944008469581604,
        -0.021996431052684784,
        0.01766357570886612,
        0.015354733914136887,
        0.0135647002607584,
        0.012660512700676918,
        0.033276576548814774,
        -0.002868807874619961,
        0.006015569902956486,
        -0.022486655041575432,
        0.006823894567787647,
        -0.02862231805920601,
        -0.026479844003915787,
        0.07912233471870422,
        -0.011121614836156368,
        0.005894671194255352,
        -0.008526738733053207,
        -0.028403662145137787,
        -0.009329257532954216,
        0.018816396594047546,
        -0.00721054757013917,
        -0.026600824669003487,
        0.01565050333738327,
        0.020700378343462944,
        -0.024046748876571655,
        0.012501123361289501,
        -0.013927415013313293,
        0.04453039914369583,
        0.010852118022739887,
        -0.002934068441390991,
        -0.023834794759750366,
        -0.00041661784052848816,
        -0.021893460303544998,
        0.023189939558506012,
        -0.01862231083214283,
        -0.021290505304932594,
        -0.0022466680966317654,
        -0.008459987118840218,
        -0.03490445390343666,
        0.025567999109625816,
        -0.05739666149020195,
        -0.011751588433980942,
        0.03184425085783005,
        -0.00940248928964138,
        -0.0038476143963634968,
        -0.011188789270818233,
        0.018702615052461624,
        -0.0176096111536026,
        -0.014359865337610245,
        -0.022359998896718025,
        0.0021783981937915087,
        0.01529229898005724,
        0.015526100993156433,
        -0.028652336448431015,
        -0.00334392418153584,
        0.0037926998920738697,
        -0.04234649986028671,
        -0.03622477874159813,
        0.0014082030393183231,
        0.041704680770635605,
        -0.02074289135634899,
        0.01625778153538704,
        -0.0013490035198628902,
        -0.006869973614811897,
        0.008780820295214653,
        0.002269506687298417,
        0.030691465362906456,
        0.022806860506534576,
        -0.02144494093954563,
        -0.0006287104333750904,
        0.017766129225492477,
        0.016418341547250748,
        -0.023231375962495804,
        0.006043672561645508,
        0.002628050511702895,
        0.027414290234446526,
        -0.0017318057361990213,
        -0.014037559740245342,
        0.00012438422709237784,
        0.028773030266165733,
        0.033181481063365936,
        -0.017976345494389534,
        0.02605428732931614,
        0.012084293179214,
        -0.018504781648516655,
        -0.008995122276246548,
        0.02608168125152588,
        -0.02752012386918068,
        -0.043478824198246,
        0.005257089622318745,
        -0.01160014234483242,
        0.007258742582052946,
        0.015051426365971565,
        -0.0031578741036355495,
        -0.04992706701159477,
        0.003520463826134801,
        -0.011628130450844765,
        -0.003084019059315324,
        -0.045208100229501724,
        0.009845214895904064,
        0.04977957159280777,
        -0.00719417491927743,
        0.026447424665093422,
        0.001753654913045466,
        0.03004789911210537,
        0.023229166865348816,
        0.02170073613524437,
        -0.00013037328608334064,
        0.03176013007760048,
        -0.010755198076367378,
        0.023519445210695267,
        0.0033420459367334843,
        -0.042870476841926575,
        0.003690561046823859,
        -0.011715088970959187,
        -0.017839698120951653,
        -0.014800653792917728,
        -0.03197590261697769,
        0.009441877715289593,
        0.018958348780870438,
        -0.0116255609318614,
        -0.014311496168375015,
        0.018561841920018196,
        0.004239128902554512,
        -0.01963604800403118,
        -0.00580966891720891,
        0.03499705344438553,
        -0.015536117367446423,
        -0.005642206408083439,
        -0.015457453206181526,
        0.009377065114676952,
        -0.019031155854463577,
        -0.016132740303874016,
        0.02182035706937313,
        0.0028333186637610197,
        0.004968738183379173,
        -0.008927022106945515,
        0.025466112419962883,
        0.017748557031154633,
        -0.04317862167954445,
        0.051213257014751434,
        -0.02195136807858944,
        -0.008464539423584938,
        -0.0032425294630229473,
        -0.05011814087629318,
        0.03657219186425209,
        0.028432728722691536,
        -0.018890080973505974,
        -0.010822580195963383,
        0.02219470404088497,
        0.026603156700730324,
        0.04503878206014633,
        -0.037318792194128036,
        0.010152422823011875,
        -0.03187083452939987,
        -0.02288738265633583,
        0.007672750391066074,
        0.0037393025122582912,
        -0.025080693885684013,
        0.007729127537459135,
        0.0389595665037632,
        0.03133774921298027,
        0.006728391163051128,
        -0.001316135749220848,
        0.016103101894259453,
        0.011602177284657955,
        -0.0018078071298077703,
        0.0020965593867003918,
        0.026494203135371208,
        0.009038728661835194,
        0.03830217570066452,
        -0.02474597841501236,
        -0.0029649909120053053,
        0.07547157257795334,
        -0.01716158725321293,
        -0.0011524056317284703,
        0.02557770535349846,
        -0.0196895319968462,
        0.013485114090144634,
        -0.01484110951423645,
        0.009442644193768501,
        0.009347003884613514,
        0.0041433535516262054,
        -0.02158929593861103,
        0.005026849918067455,
        0.017307372763752937,
        -0.003620727686211467,
        0.019799649715423584,
        -0.0031126034446060658,
        -0.02562597393989563,
        0.009214567951858044,
        0.029483765363693237,
        0.01656334102153778,
        -0.016336234286427498,
        -0.03171553835272789,
        0.00682534696534276,
        0.013367803767323494,
        -0.018537238240242004,
        -0.008049923926591873,
        -0.015912886708974838,
        0.012093371711671352,
        0.021529769524931908,
        -0.031810320913791656,
        0.012325351126492023,
        0.03524153307080269,
        -0.0028652905020862818,
        -0.019637396559119225,
        0.001042714691720903,
        -0.0209779292345047,
        -0.031015627086162567,
        0.0401269868016243,
        0.03249933570623398,
        -0.03002479486167431,
        0.008378344587981701,
        -0.0027068587951362133,
        0.0329759418964386,
        0.0076207490637898445,
        0.004784267861396074
      ],
      "title": "México avanza con su plan nacional para el desarrollo ético de la inteligencia artificial"
    }
  ]
}